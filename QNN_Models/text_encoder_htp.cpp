/* COPYRIGHT HEADER GOES HERE: No CopyRight Header String Passed During Model Conversion */

/* Command Line used:
qnn-onnx-converter; act_bitwidth=8; act_quantizer=tf; act_quantizer_calibration=min-max; act_quantizer_schema=asymmetric; adjust_nms_features_dims=True; algorithms=[]; align_matmul_ranks=True; apply_masked_softmax=uncompressed; arch_checker=False; backend=None; batch=None; bias_bitwidth=8; calc_static_encodings=False; converter_op_package_lib=; copyright_file=None; custom_io=; custom_op_config_paths=None; debug=-1; defer_loading=False; define_symbol=None; disable_batchnorm_folding=False; disable_defer_loading=False; disable_node_validation=False; disable_qnn_op_config_validation=False; disable_relu_squashing=False; dry_run=None; dumpIR=False; dump_custom_io_config_template=; dump_encoding_json=False; dump_inferred_model=False; dump_qairt_io_config_yaml=; dump_qairt_quantizer_command=None; dump_value_info=False; enable_framework_trace=False; enable_match_gathernd=False; enable_match_topk=False; enable_per_row_quantized_bias=False; exclude_named_tensors=False; expand_gru_op_structure=True; expand_lstm_op_structure=False; expand_sparse_op_structure=False; export_format=cpp; extract_color_transform=True; float_bias_bitwidth=0; float_bias_bw=0; float_bitwidth=32; float_bw=32; float_fallback=False; force_prune_cast_ops=False; handle_gather_negative_indices=True; ignore_encodings=False; include_data_invariant_ops=False; inject_cast_for_gather=True; input_dim=[['text_ids', '1,128'], ['style_ttl', '1,50,256'], ['text_mask', '1,1,128']]; input_dtype=[]; input_encoding=[]; input_layout=[]; input_list=./qnn_calibration/text_encoder/input_list.txt; input_type=[]; keep_disconnected_nodes=False; keep_int64_inputs=False; keep_quant_nodes=False; keep_weights_quantized=False; match_caffe_ssd_to_tf=True; model_version=None; multi_time_steps_gru=False; multi_time_steps_lstm=False; no_simplification=False; op_package_lib=; out_names=['text_emb']; overwrite_model_prefix=False; pack_4_bit_weights=False; package_name=None; packed_masked_softmax_inputs=[]; packed_max_seq=1; param_quantizer=None; param_quantizer_calibration=min-max; param_quantizer_schema=asymmetric; percentile_calibration_value=99.99; perform_axes_to_spatial_first_order=True; perform_layout_transformation=False; prepare_inputs_as_params=False; preprocess_roi_pool_inputs=True; preserve_io=[]; preserve_onnx_output_order=False; quantization_overrides=; quantizer_log=None; restrict_quantization_steps=[]; squash_box_decoder=True; unroll_gru_time_steps=True; unroll_lstm_time_steps=True; use_aimet_quantizer=False; use_convert_quantization_nodes=False; use_dynamic_16_bit_weights=False; use_native_dtype=False; use_native_input_files=False; use_native_output_files=False; use_per_channel_quantization=False; use_per_row_quantization=False; use_quantize_v2=False; validate_models=False; weights_bitwidth=8
*/

#include "QnnOpDef.h"
#include "QnnModel.hpp"

// Flag to determine if Backend should do node validation for each opNode added
#define DO_GRAPH_NODE_VALIDATIONS 1

using namespace qnn_wrapper_api;
const __attribute__((visibility("default"))) char* QNN_SDK_VERSION = "qaisw-v2.37.1.250807093845_124904";
extern "C" {
static ModelError_t addTensor_text_ids(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_text_ids[] = {1, 128};
  VALIDATE(model.addTensor("text_ids", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "text_ids",
                                 .type= QNN_TENSOR_TYPE_APP_WRITE,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_INT_32,
                                 .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                                                    QNN_QUANTIZATION_ENCODING_UNDEFINED,
                                                    {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
                                 .rank= 2,
                                 .dimensions=dimensions_text_ids,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=nullptr,
                                                .dataSize=0}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_style_ttl(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_style_ttl[] = {1, 256, 50};
  VALIDATE(model.addTensor("style_ttl", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "style_ttl",
                                 .type= QNN_TENSOR_TYPE_APP_WRITE,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0054120589047670f, .offset= -172}}},
                                 .rank= 3,
                                 .dimensions=dimensions_style_ttl,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=nullptr,
                                                .dataSize=0}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_text_mask(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_text_mask[] = {1, 128, 1};
  VALIDATE(model.addTensor("text_mask", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "text_mask",
                                 .type= QNN_TENSOR_TYPE_APP_WRITE,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0039215688593686f, .offset= 0}}},
                                 .rank= 3,
                                 .dimensions=dimensions_text_mask,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=nullptr,
                                                .dataSize=0}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode_style_ttl_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR style_ttl_ncf */
  uint32_t dimensions_style_ttl_ncf_perm[] = {3};
  uint32_t style_ttl_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params_style_ttl_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "style_ttl_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions_style_ttl_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)style_ttl_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs_style_ttl_ncf[] = {
    "style_ttl"
  };
  uint32_t dimensions_style_ttl_ncf[] = {1, 50, 256};
  Qnn_Tensor_t outputs_style_ttl_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "style_ttl_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0054120589047670f, .offset= -172}}},
            .rank= 3,
            .dimensions=dimensions_style_ttl_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "style_ttl_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params_style_ttl_ncf, // Node Params
                         1, // Num Node Params
                         inputs_style_ttl_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs_style_ttl_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_W_value_linear_MatMul_pre_reshape(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_W_value_linear_MatMul_pre_reshape */
  const char*  inputs__speech_prompted_text_encoder_attention2_W_value_linear_MatMul_pre_reshape[] = {
    "style_ttl_ncf"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_W_value_linear_MatMul_pre_reshape[] = {50, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_W_value_linear_MatMul_pre_reshape[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_W_value_linear_MatMul_pre_reshape",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0054120589047670f, .offset= -172}}},
            .rank= 2,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_W_value_linear_MatMul_pre_reshape,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_W_value_linear_MatMul_pre_reshape", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_W_value_linear_MatMul_pre_reshape, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_W_value_linear_MatMul_pre_reshape, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_W_value_linear_MatMul_pre_reshape(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_W_value_linear_MatMul_pre_reshape */
  const char*  inputs__speech_prompted_text_encoder_attention1_W_value_linear_MatMul_pre_reshape[] = {
    "style_ttl_ncf"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_W_value_linear_MatMul_pre_reshape[] = {50, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_W_value_linear_MatMul_pre_reshape[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_W_value_linear_MatMul_pre_reshape",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0054120589047670f, .offset= -172}}},
            .rank= 2,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_W_value_linear_MatMul_pre_reshape,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_W_value_linear_MatMul_pre_reshape", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_W_value_linear_MatMul_pre_reshape, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_W_value_linear_MatMul_pre_reshape, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode_text_mask_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR text_mask_ncf */
  uint32_t dimensions_text_mask_ncf_perm[] = {3};
  uint32_t text_mask_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params_text_mask_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "text_mask_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions_text_mask_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)text_mask_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs_text_mask_ncf[] = {
    "text_mask"
  };
  uint32_t dimensions_text_mask_ncf[] = {1, 1, 128};
  Qnn_Tensor_t outputs_text_mask_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "text_mask_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039215688593686f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions_text_mask_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "text_mask_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params_text_mask_ncf, // Node Params
                         1, // Num Node Params
                         inputs_text_mask_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs_text_mask_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_text_embedder_char_embedder_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_text_embedder_char_embedder_weight[] = {82, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_text_embedder_char_embedder_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_text_embedder_char_embedder_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0046814489178360f, .offset= -119}}},
                                 .rank= 2,
                                 .dimensions=dimensions_tts_ttl_text_encoder_text_embedder_char_embedder_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_text_embedder_char_embedder_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_text_embedder_char_embedder_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_text_embedder_char_embedder_Gather(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_text_embedder_char_embedder_Gather */
  Qnn_Param_t params__text_encoder_text_embedder_char_embedder_Gather[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="axis",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_INT_32, {.int32Value = 0}}}}
  };
  const char*  inputs__text_encoder_text_embedder_char_embedder_Gather[] = {
    "tts_ttl_text_encoder_text_embedder_char_embedder_weight",
    "text_ids"
  };
  uint32_t dimensions__text_encoder_text_embedder_char_embedder_Gather_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_text_embedder_char_embedder_Gather[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_text_embedder_char_embedder_Gather_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0046814489178360f, .offset= -119}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_text_embedder_char_embedder_Gather_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_text_embedder_char_embedder_Gather", // Node Name
                         "qti.aisw", // Package Name
                         "Gather", // Qnn Node Type
                         params__text_encoder_text_embedder_char_embedder_Gather, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_text_embedder_char_embedder_Gather, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_text_embedder_char_embedder_Gather, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_Unsqueeze(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_Unsqueeze */
  const char*  inputs__text_encoder_attn_encoder_Unsqueeze[] = {
    "text_mask_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_Unsqueeze_output_0[] = {1, 1, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_Unsqueeze[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_Unsqueeze_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039215688593686f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_Unsqueeze_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_Unsqueeze", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_Unsqueeze, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_Unsqueeze, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_Unsqueeze_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_Unsqueeze_1 */
  const char*  inputs__text_encoder_attn_encoder_Unsqueeze_1[] = {
    "text_mask_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_Unsqueeze_1_output_0[] = {1, 1, 128, 1};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_Unsqueeze_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_Unsqueeze_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039215688593686f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_Unsqueeze_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_Unsqueeze_1", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_Unsqueeze_1, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_Unsqueeze_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_text_embedder_Transpose(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_text_embedder_Transpose */
  uint32_t dimensions__text_encoder_text_embedder_Transpose_perm[] = {3};
  uint32_t _text_encoder_text_embedder_Transpose_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_text_embedder_Transpose[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_text_embedder_Transpose_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_text_embedder_Transpose_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_text_embedder_Transpose_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_text_embedder_Transpose[] = {
    "_text_encoder_text_embedder_char_embedder_Gather_output_0"
  };
  uint32_t dimensions__text_encoder_text_embedder_Transpose_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_text_embedder_Transpose[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_text_embedder_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0046814489178360f, .offset= -119}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_text_embedder_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_text_embedder_Transpose", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_text_embedder_Transpose, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_text_embedder_Transpose, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_text_embedder_Transpose, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_onnx__MatMul_3680(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_onnx__MatMul_3680[] = {256, 256};
  VALIDATE(model.addTensor("onnx__MatMul_3680", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "onnx__MatMul_3680",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0053302468731999f, .offset= -124}}},
                                 .rank= 2,
                                 .dimensions=dimensions_onnx__MatMul_3680,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(onnx__MatMul_3680),
                                                .dataSize=BINLEN(onnx__MatMul_3680)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_speech_prompted_text_encoder_attention1_W_value_linear_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_speech_prompted_text_encoder_attention1_W_value_linear_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_speech_prompted_text_encoder_attention1_W_value_linear_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_speech_prompted_text_encoder_attention1_W_value_linear_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0006640547071584f, .offset= -123}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_speech_prompted_text_encoder_attention1_W_value_linear_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_speech_prompted_text_encoder_attention1_W_value_linear_bias),
                                                .dataSize=BINLEN(tts_ttl_speech_prompted_text_encoder_attention1_W_value_linear_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_W_value_linear_MatMul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_W_value_linear_MatMul */
  const char*  inputs__speech_prompted_text_encoder_attention1_W_value_linear_MatMul[] = {
    "_speech_prompted_text_encoder_attention1_W_value_linear_MatMul_pre_reshape",
    "onnx__MatMul_3680",
    "tts_ttl_speech_prompted_text_encoder_attention1_W_value_linear_bias"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_W_value_linear_Add_output_0_fc[] = {50, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_W_value_linear_MatMul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_W_value_linear_Add_output_0_fc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0057184831239283f, .offset= -140}}},
            .rank= 2,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_W_value_linear_Add_output_0_fc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_W_value_linear_MatMul", // Node Name
                         "qti.aisw", // Package Name
                         "FullyConnected", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_W_value_linear_MatMul, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_W_value_linear_MatMul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_W_value_linear_MatMul_post_reshape(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_W_value_linear_MatMul_post_reshape */
  const char*  inputs__speech_prompted_text_encoder_attention1_W_value_linear_MatMul_post_reshape[] = {
    "_speech_prompted_text_encoder_attention1_W_value_linear_Add_output_0_fc"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_W_value_linear_Add_output_0[] = {1, 50, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_W_value_linear_MatMul_post_reshape[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_W_value_linear_Add_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0057184831239283f, .offset= -140}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_W_value_linear_Add_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_W_value_linear_MatMul_post_reshape", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_W_value_linear_MatMul_post_reshape, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_W_value_linear_MatMul_post_reshape, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_Unsqueeze_6(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_Unsqueeze_6 */
  const char*  inputs__speech_prompted_text_encoder_attention1_Unsqueeze_6[] = {
    "text_mask"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Unsqueeze_6_output_0[] = {1, 1, 128, 1};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_Unsqueeze_6[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Unsqueeze_6_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039215688593686f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Unsqueeze_6_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_Unsqueeze_6", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_Unsqueeze_6, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_Unsqueeze_6, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_onnx__MatMul_3684(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_onnx__MatMul_3684[] = {256, 256};
  VALIDATE(model.addTensor("onnx__MatMul_3684", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "onnx__MatMul_3684",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0068369358778000f, .offset= -123}}},
                                 .rank= 2,
                                 .dimensions=dimensions_onnx__MatMul_3684,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(onnx__MatMul_3684),
                                                .dataSize=BINLEN(onnx__MatMul_3684)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_speech_prompted_text_encoder_attention2_W_value_linear_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_speech_prompted_text_encoder_attention2_W_value_linear_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_speech_prompted_text_encoder_attention2_W_value_linear_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_speech_prompted_text_encoder_attention2_W_value_linear_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0007351297535934f, .offset= -114}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_speech_prompted_text_encoder_attention2_W_value_linear_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_speech_prompted_text_encoder_attention2_W_value_linear_bias),
                                                .dataSize=BINLEN(tts_ttl_speech_prompted_text_encoder_attention2_W_value_linear_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_W_value_linear_MatMul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_W_value_linear_MatMul */
  const char*  inputs__speech_prompted_text_encoder_attention2_W_value_linear_MatMul[] = {
    "_speech_prompted_text_encoder_attention2_W_value_linear_MatMul_pre_reshape",
    "onnx__MatMul_3684",
    "tts_ttl_speech_prompted_text_encoder_attention2_W_value_linear_bias"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_W_value_linear_Add_output_0_fc[] = {50, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_W_value_linear_MatMul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_W_value_linear_Add_output_0_fc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0093958349898458f, .offset= -114}}},
            .rank= 2,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_W_value_linear_Add_output_0_fc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_W_value_linear_MatMul", // Node Name
                         "qti.aisw", // Package Name
                         "FullyConnected", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_W_value_linear_MatMul, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_W_value_linear_MatMul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_W_value_linear_MatMul_post_reshape(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_W_value_linear_MatMul_post_reshape */
  const char*  inputs__speech_prompted_text_encoder_attention2_W_value_linear_MatMul_post_reshape[] = {
    "_speech_prompted_text_encoder_attention2_W_value_linear_Add_output_0_fc"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_W_value_linear_Add_output_0[] = {1, 50, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_W_value_linear_MatMul_post_reshape[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_W_value_linear_Add_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0093958349898458f, .offset= -114}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_W_value_linear_Add_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_W_value_linear_MatMul_post_reshape", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_W_value_linear_MatMul_post_reshape, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_W_value_linear_MatMul_post_reshape, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_Mul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_Mul */
  Qnn_Param_t params__text_encoder_attn_encoder_Mul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_Mul[] = {
    "_text_encoder_attn_encoder_Unsqueeze_output_0",
    "_text_encoder_attn_encoder_Unsqueeze_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_Mul_output_0[] = {1, 1, 128, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_Mul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_Mul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039215688593686f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_Mul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_Mul", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_Mul, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_Mul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_Mul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_text_embedder_Mul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_text_embedder_Mul */
  Qnn_Param_t params__text_encoder_text_embedder_Mul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_text_embedder_Mul[] = {
    "_text_encoder_text_embedder_Transpose_output_0",
    "text_mask_ncf"
  };
  uint32_t dimensions__text_encoder_text_embedder_Mul_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_text_embedder_Mul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_text_embedder_Mul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0018725795671344f, .offset= -158}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_text_embedder_Mul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_text_embedder_Mul", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_text_embedder_Mul, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_text_embedder_Mul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_text_embedder_Mul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_text_embedder_Mul_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_text_embedder_Mul_output_0_nfc */
  uint32_t dimensions__text_encoder_text_embedder_Mul_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_text_embedder_Mul_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_text_embedder_Mul_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_text_embedder_Mul_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_text_embedder_Mul_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_text_embedder_Mul_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_text_embedder_Mul_output_0_nfc[] = {
    "_text_encoder_text_embedder_Mul_output_0"
  };
  uint32_t dimensions__text_encoder_text_embedder_Mul_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_text_embedder_Mul_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_text_embedder_Mul_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0018725795671344f, .offset= -158}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_text_embedder_Mul_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_text_embedder_Mul_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_text_embedder_Mul_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_text_embedder_Mul_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_text_embedder_Mul_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_Split_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_Split_2 */
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Split_2_split_index[] = {1};
  uint32_t _speech_prompted_text_encoder_attention1_Split_2_split_index[] = {128};
  Qnn_Param_t params__speech_prompted_text_encoder_attention1_Split_2[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="split_index",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Split_2_split_index",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Split_2_split_index,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_speech_prompted_text_encoder_attention1_Split_2_split_index,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="axis",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 2}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention1_Split_2[] = {
    "_speech_prompted_text_encoder_attention1_W_value_linear_Add_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Split_2_output_0[] = {1, 50, 128};
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Split_2_output_1[] = {1, 50, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_Split_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Split_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0057184831239283f, .offset= -140}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Split_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}},
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Split_2_output_1",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0057184831239283f, .offset= -140}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Split_2_output_1,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_Split_2", // Node Name
                         "qti.aisw", // Package Name
                         "Split", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention1_Split_2, // Node Params
                         2, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_Split_2, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_Split_2, // Output Tensors 
                         2// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor__speech_prompted_text_encoder_attention1_Constant_11_output_0(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Constant_11_output_0[] = {1};
  VALIDATE(model.addTensor("_speech_prompted_text_encoder_attention1_Constant_11_output_0", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "_speech_prompted_text_encoder_attention1_Constant_11_output_0",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0000003921568634f, .offset= 0}}},
                                 .rank= 1,
                                 .dimensions=dimensions__speech_prompted_text_encoder_attention1_Constant_11_output_0,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(_speech_prompted_text_encoder_attention1_Constant_11_output_0),
                                                .dataSize=BINLEN(_speech_prompted_text_encoder_attention1_Constant_11_output_0)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_Equal(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_Equal */
  Qnn_Param_t params__speech_prompted_text_encoder_attention1_Equal[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 3}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention1_Equal[] = {
    "_speech_prompted_text_encoder_attention1_Unsqueeze_6_output_0",
    "_speech_prompted_text_encoder_attention1_Constant_11_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Cast_output_0[] = {1, 1, 128, 1};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_Equal[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Cast_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_BOOL_8,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Cast_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_Equal", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention1_Equal, // Node Params
                         1, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_Equal, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_Equal, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_Split_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_Split_2 */
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Split_2_split_index[] = {1};
  uint32_t _speech_prompted_text_encoder_attention2_Split_2_split_index[] = {128};
  Qnn_Param_t params__speech_prompted_text_encoder_attention2_Split_2[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="split_index",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Split_2_split_index",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Split_2_split_index,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_speech_prompted_text_encoder_attention2_Split_2_split_index,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="axis",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 2}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention2_Split_2[] = {
    "_speech_prompted_text_encoder_attention2_W_value_linear_Add_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Split_2_output_0[] = {1, 50, 128};
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Split_2_output_1[] = {1, 50, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_Split_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Split_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0093958349898458f, .offset= -114}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Split_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}},
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Split_2_output_1",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0093958349898458f, .offset= -114}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Split_2_output_1,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_Split_2", // Node Name
                         "qti.aisw", // Package Name
                         "Split", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention2_Split_2, // Node Params
                         2, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_Split_2, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_Split_2, // Output Tensors 
                         2// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Equal(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Equal */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Equal[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 3}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Equal[] = {
    "_text_encoder_attn_encoder_Mul_output_0",
    "_speech_prompted_text_encoder_attention1_Constant_11_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Cast_5_output_0[] = {1, 1, 128, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Equal[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Cast_5_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_BOOL_8,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Cast_5_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Equal", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Equal, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Equal, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Equal, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_Mul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_Mul */
  Qnn_Param_t params__text_encoder_convnext_convnext_0_Mul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_Mul[] = {
    "_text_encoder_text_embedder_Mul_output_0_nfc",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_Mul_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_Mul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_Mul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0018725795671344f, .offset= -158}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_Mul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_Mul", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_Mul, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_Mul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_Mul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_Unsqueeze_4(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_Unsqueeze_4 */
  const char*  inputs__speech_prompted_text_encoder_attention1_Unsqueeze_4[] = {
    "_speech_prompted_text_encoder_attention1_Split_2_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Unsqueeze_4_output_0[] = {1, 1, 50, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_Unsqueeze_4[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Unsqueeze_4_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0057184831239283f, .offset= -140}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Unsqueeze_4_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_Unsqueeze_4", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_Unsqueeze_4, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_Unsqueeze_4, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_Unsqueeze_5(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_Unsqueeze_5 */
  const char*  inputs__speech_prompted_text_encoder_attention1_Unsqueeze_5[] = {
    "_speech_prompted_text_encoder_attention1_Split_2_output_1"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Unsqueeze_5_output_0[] = {1, 1, 50, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_Unsqueeze_5[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Unsqueeze_5_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0057184831239283f, .offset= -140}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Unsqueeze_5_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_Unsqueeze_5", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_Unsqueeze_5, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_Unsqueeze_5, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_Unsqueeze_4(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_Unsqueeze_4 */
  const char*  inputs__speech_prompted_text_encoder_attention2_Unsqueeze_4[] = {
    "_speech_prompted_text_encoder_attention2_Split_2_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Unsqueeze_4_output_0[] = {1, 1, 50, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_Unsqueeze_4[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Unsqueeze_4_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0093958349898458f, .offset= -114}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Unsqueeze_4_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_Unsqueeze_4", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_Unsqueeze_4, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_Unsqueeze_4, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_Unsqueeze_5(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_Unsqueeze_5 */
  const char*  inputs__speech_prompted_text_encoder_attention2_Unsqueeze_5[] = {
    "_speech_prompted_text_encoder_attention2_Split_2_output_1"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Unsqueeze_5_output_0[] = {1, 1, 50, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_Unsqueeze_5[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Unsqueeze_5_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0093958349898458f, .offset= -114}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Unsqueeze_5_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_Unsqueeze_5", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_Unsqueeze_5, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_Unsqueeze_5, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_Concat_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_Concat_2 */
  Qnn_Param_t params__speech_prompted_text_encoder_attention1_Concat_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="axis",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention1_Concat_2[] = {
    "_speech_prompted_text_encoder_attention1_Unsqueeze_4_output_0",
    "_speech_prompted_text_encoder_attention1_Unsqueeze_5_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Concat_2_output_0[] = {2, 1, 50, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_Concat_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Concat_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0057184831239283f, .offset= -140}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Concat_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_Concat_2", // Node Name
                         "qti.aisw", // Package Name
                         "Concat", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention1_Concat_2, // Node Params
                         1, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_Concat_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_Concat_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_Concat_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_Concat_2 */
  Qnn_Param_t params__speech_prompted_text_encoder_attention2_Concat_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="axis",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention2_Concat_2[] = {
    "_speech_prompted_text_encoder_attention2_Unsqueeze_4_output_0",
    "_speech_prompted_text_encoder_attention2_Unsqueeze_5_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Concat_2_output_0[] = {2, 1, 50, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_Concat_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Concat_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0093958349898458f, .offset= -114}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Concat_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_Concat_2", // Node Name
                         "qti.aisw", // Package Name
                         "Concat", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention2_Concat_2, // Node Params
                         1, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_Concat_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_Concat_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_dwconv_Pad(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_dwconv_Pad */
  uint32_t dimensions__text_encoder_convnext_convnext_0_dwconv_Pad_pad_amount[] = {3, 2};
  uint32_t _text_encoder_convnext_convnext_0_dwconv_Pad_pad_amount[] = {0, 0, 2, 2, 0, 0};
  Qnn_Param_t params__text_encoder_convnext_convnext_0_dwconv_Pad[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_dwconv_Pad_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_dwconv_Pad_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_dwconv_Pad_pad_amount,
                           .dataSize=24}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 3}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_dwconv_Pad[] = {
    "_text_encoder_convnext_convnext_0_Mul_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_dwconv_Pad_output_0[] = {1, 132, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_dwconv_Pad[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_dwconv_Pad_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0018725795671344f, .offset= -158}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_dwconv_Pad_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_dwconv_Pad", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_dwconv_Pad, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_dwconv_Pad, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_dwconv_Pad, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_dwconv_Pad_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_dwconv_Pad_output_0_ncf */
  uint32_t dimensions__text_encoder_convnext_convnext_0_dwconv_Pad_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_0_dwconv_Pad_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_0_dwconv_Pad_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_dwconv_Pad_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_dwconv_Pad_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_dwconv_Pad_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_dwconv_Pad_output_0_ncf[] = {
    "_text_encoder_convnext_convnext_0_dwconv_Pad_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_dwconv_Pad_output_0_ncf[] = {1, 256, 132};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_dwconv_Pad_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_dwconv_Pad_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0018725795671344f, .offset= -158}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_dwconv_Pad_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_dwconv_Pad_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_dwconv_Pad_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_dwconv_Pad_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_dwconv_Pad_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d[] = {
    "_text_encoder_convnext_convnext_0_dwconv_Pad_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d[] = {1, 256, 1, 132};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0018725795671344f, .offset= -158}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d_nhwc[] = {1, 1, 132, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0018725795671344f, .offset= -158}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_0_dwconv_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_0_dwconv_weight[] = {1, 5, 1, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_0_dwconv_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_0_dwconv_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0057920315302908f, .offset= -155}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_0_dwconv_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_0_dwconv_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_0_dwconv_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_0_dwconv_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_0_dwconv_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_0_dwconv_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_0_dwconv_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0008639367297292f, .offset= -102}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_0_dwconv_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_0_dwconv_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_0_dwconv_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_dwconv_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_dwconv_Conv_2d */
  uint32_t dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_convnext_convnext_0_dwconv_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_convnext_convnext_0_dwconv_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_convnext_convnext_0_dwconv_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_0_dwconv_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_dwconv_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_dwconv_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_dwconv_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_dwconv_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_dwconv_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_dwconv_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_dwconv_Conv_2d[] = {
    "_text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_convnext_convnext_0_dwconv_weight",
    "tts_ttl_text_encoder_convnext_convnext_0_dwconv_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_dwconv_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_dwconv_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0028486642986536f, .offset= -64}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_dwconv_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "DepthWiseConv2d", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_dwconv_Conv_2d, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_dwconv_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_dwconv_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_dwconv_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_0_dwconv_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_dwconv_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_dwconv_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate_nchw[] = {
    "_text_encoder_convnext_convnext_0_dwconv_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_dwconv_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0028486642986536f, .offset= -64}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_dwconv_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_dwconv_Conv_intermediate */
  const char*  inputs__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate[] = {
    "_text_encoder_convnext_convnext_0_dwconv_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_dwconv_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0028486642986536f, .offset= -64}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_dwconv_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_dwconv_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_dwconv_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_0_dwconv_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_0_dwconv_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_dwconv_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_dwconv_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_dwconv_Conv_output_0_nfc[] = {
    "_text_encoder_convnext_convnext_0_dwconv_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_dwconv_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_dwconv_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0028486642986536f, .offset= -64}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_dwconv_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_dwconv_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_dwconv_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_dwconv_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_dwconv_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_Mul_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_Mul_1 */
  Qnn_Param_t params__text_encoder_convnext_convnext_0_Mul_1[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_Mul_1[] = {
    "_text_encoder_convnext_convnext_0_dwconv_Conv_output_0_nfc",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_norm_Transpose_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_Mul_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_norm_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0028486642986536f, .offset= -64}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_norm_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_Mul_1", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_Mul_1, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_Mul_1, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_Mul_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_0_norm_norm_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_0_norm_norm_weight[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_0_norm_norm_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_0_norm_norm_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0026935769710690f, .offset= 0}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_0_norm_norm_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_0_norm_norm_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_0_norm_norm_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_0_norm_norm_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_0_norm_norm_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_0_norm_norm_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_0_norm_norm_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0010016395244747f, .offset= -106}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_0_norm_norm_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_0_norm_norm_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_0_norm_norm_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_norm_norm_LayerNormalization(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_norm_norm_LayerNormalization */
  uint32_t dimensions__text_encoder_convnext_convnext_0_norm_norm_LayerNormalization_axes[] = {1};
  uint32_t _text_encoder_convnext_convnext_0_norm_norm_LayerNormalization_axes[] = {2};
  Qnn_Param_t params__text_encoder_convnext_convnext_0_norm_norm_LayerNormalization[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="axes",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_norm_norm_LayerNormalization_axes",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_norm_norm_LayerNormalization_axes,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_norm_norm_LayerNormalization_axes,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="epsilon",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000001000000f}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_norm_norm_LayerNormalization[] = {
    "_text_encoder_convnext_convnext_0_norm_Transpose_output_0",
    "tts_ttl_text_encoder_convnext_convnext_0_norm_norm_weight",
    "tts_ttl_text_encoder_convnext_convnext_0_norm_norm_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_norm_Transpose_1_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_norm_norm_LayerNormalization[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_norm_Transpose_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0162674132734537f, .offset= -103}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_norm_Transpose_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_norm_norm_LayerNormalization", // Node Name
                         "qti.aisw", // Package Name
                         "LayerNorm", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_norm_norm_LayerNormalization, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_norm_norm_LayerNormalization, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_norm_norm_LayerNormalization, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_norm_Transpose_1_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_norm_Transpose_1_output_0_ncf */
  uint32_t dimensions__text_encoder_convnext_convnext_0_norm_Transpose_1_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_0_norm_Transpose_1_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_0_norm_Transpose_1_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_norm_Transpose_1_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_norm_Transpose_1_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_norm_Transpose_1_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_norm_Transpose_1_output_0_ncf[] = {
    "_text_encoder_convnext_convnext_0_norm_Transpose_1_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_norm_Transpose_1_output_0_ncf[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_norm_Transpose_1_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_norm_Transpose_1_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0162674132734537f, .offset= -103}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_norm_Transpose_1_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_norm_Transpose_1_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_norm_Transpose_1_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_norm_Transpose_1_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_norm_Transpose_1_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d[] = {
    "_text_encoder_convnext_convnext_0_norm_Transpose_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0162674132734537f, .offset= -103}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0162674132734537f, .offset= -103}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_0_pwconv1_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_0_pwconv1_weight[] = {1, 1, 256, 1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_0_pwconv1_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_0_pwconv1_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0057540913112462f, .offset= -108}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_0_pwconv1_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_0_pwconv1_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_0_pwconv1_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_0_pwconv1_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_0_pwconv1_bias[] = {1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_0_pwconv1_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_0_pwconv1_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0010139191290364f, .offset= -248}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_0_pwconv1_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_0_pwconv1_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_0_pwconv1_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_pwconv1_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_pwconv1_Conv_2d */
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_convnext_convnext_0_pwconv1_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_convnext_convnext_0_pwconv1_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_convnext_convnext_0_pwconv1_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_0_pwconv1_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv1_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_pwconv1_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv1_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_pwconv1_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv1_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_pwconv1_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_pwconv1_Conv_2d[] = {
    "_text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_convnext_convnext_0_pwconv1_weight",
    "tts_ttl_text_encoder_convnext_convnext_0_pwconv1_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_pwconv1_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0415934585034847f, .offset= -207}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_pwconv1_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_pwconv1_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_pwconv1_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_pwconv1_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate_nchw[] = {
    "_text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate_nchw[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0415934585034847f, .offset= -207}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate */
  const char*  inputs__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate[] = {
    "_text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv1_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0415934585034847f, .offset= -207}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv1_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__elementwiseneuron_4(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _elementwiseneuron_4 */
  Qnn_Param_t params__elementwiseneuron_4[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}}
  };
  const char*  inputs__elementwiseneuron_4[] = {
    "_text_encoder_convnext_convnext_0_pwconv1_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_act_Mul_1_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__elementwiseneuron_4[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_act_Mul_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0083965724334121f, .offset= -20}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_act_Mul_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_elementwiseneuron_4", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseNeuron", // Qnn Node Type
                         params__elementwiseneuron_4, // Node Params
                         1, // Num Node Params
                         inputs__elementwiseneuron_4, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__elementwiseneuron_4, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d[] = {
    "_text_encoder_convnext_convnext_0_act_Mul_1_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0083965724334121f, .offset= -20}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0083965724334121f, .offset= -20}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_0_pwconv2_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_0_pwconv2_weight[] = {1, 1, 1024, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_0_pwconv2_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_0_pwconv2_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0056046554818749f, .offset= -133}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_0_pwconv2_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_0_pwconv2_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_0_pwconv2_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_0_pwconv2_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_0_pwconv2_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_0_pwconv2_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_0_pwconv2_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0021756479982287f, .offset= -177}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_0_pwconv2_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_0_pwconv2_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_0_pwconv2_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_pwconv2_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_pwconv2_Conv_2d */
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_convnext_convnext_0_pwconv2_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_convnext_convnext_0_pwconv2_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_convnext_convnext_0_pwconv2_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_0_pwconv2_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv2_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_pwconv2_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv2_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_pwconv2_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv2_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_pwconv2_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_pwconv2_Conv_2d[] = {
    "_text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_convnext_convnext_0_pwconv2_weight",
    "tts_ttl_text_encoder_convnext_convnext_0_pwconv2_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_pwconv2_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0223070718348026f, .offset= -152}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_pwconv2_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_pwconv2_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_pwconv2_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_pwconv2_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate_nchw[] = {
    "_text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0223070718348026f, .offset= -152}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate */
  const char*  inputs__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate[] = {
    "_text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv2_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0223070718348026f, .offset= -152}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_pwconv2_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_pwconv2_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_0_pwconv2_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_0_pwconv2_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv2_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_0_pwconv2_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_pwconv2_Conv_output_0_nfc[] = {
    "_text_encoder_convnext_convnext_0_pwconv2_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_pwconv2_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_pwconv2_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0223070718348026f, .offset= -152}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_pwconv2_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_pwconv2_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_pwconv2_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_pwconv2_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_pwconv2_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_0_gamma(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_0_gamma[] = {1, 1, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_0_gamma", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_0_gamma",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0004787787911482f, .offset= 0}}},
                                 .rank= 3,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_0_gamma,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_0_gamma),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_0_gamma)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_Mul_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_Mul_2 */
  Qnn_Param_t params__text_encoder_convnext_convnext_0_Mul_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_Mul_2[] = {
    "tts_ttl_text_encoder_convnext_convnext_0_gamma",
    "_text_encoder_convnext_convnext_0_pwconv2_Conv_output_0_nfc"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_Mul_2_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_Mul_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_Mul_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0017371616559103f, .offset= -150}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_Mul_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_Mul_2", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_Mul_2, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_Mul_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_Mul_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_Add(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_Add */
  Qnn_Param_t params__text_encoder_convnext_convnext_0_Add[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_Add[] = {
    "_text_encoder_convnext_convnext_0_Mul_output_0",
    "_text_encoder_convnext_convnext_0_Mul_2_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_Add_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_Add[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_Add_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0024582569021732f, .offset= -164}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_Add_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_Add", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_Add, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_Add, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_Add, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_0_Mul_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_0_Mul_3 */
  Qnn_Param_t params__text_encoder_convnext_convnext_0_Mul_3[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_0_Mul_3[] = {
    "_text_encoder_convnext_convnext_0_Add_output_0",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_0_Mul_3_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_0_Mul_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_0_Mul_3_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0024582569021732f, .offset= -164}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_0_Mul_3_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_0_Mul_3", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_0_Mul_3, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_0_Mul_3, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_0_Mul_3, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_Mul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_Mul */
  Qnn_Param_t params__text_encoder_convnext_convnext_1_Mul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_Mul[] = {
    "_text_encoder_convnext_convnext_0_Mul_3_output_0",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_Mul_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_Mul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_Mul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0024582569021732f, .offset= -164}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_Mul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_Mul", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_Mul, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_Mul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_Mul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_dwconv_Pad(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_dwconv_Pad */
  uint32_t dimensions__text_encoder_convnext_convnext_1_dwconv_Pad_pad_amount[] = {3, 2};
  uint32_t _text_encoder_convnext_convnext_1_dwconv_Pad_pad_amount[] = {0, 0, 2, 2, 0, 0};
  Qnn_Param_t params__text_encoder_convnext_convnext_1_dwconv_Pad[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_dwconv_Pad_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_dwconv_Pad_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_dwconv_Pad_pad_amount,
                           .dataSize=24}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 3}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_dwconv_Pad[] = {
    "_text_encoder_convnext_convnext_1_Mul_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_dwconv_Pad_output_0[] = {1, 132, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_dwconv_Pad[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_dwconv_Pad_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0024582569021732f, .offset= -164}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_dwconv_Pad_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_dwconv_Pad", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_dwconv_Pad, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_dwconv_Pad, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_dwconv_Pad, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_dwconv_Pad_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_dwconv_Pad_output_0_ncf */
  uint32_t dimensions__text_encoder_convnext_convnext_1_dwconv_Pad_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_1_dwconv_Pad_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_1_dwconv_Pad_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_dwconv_Pad_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_dwconv_Pad_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_dwconv_Pad_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_dwconv_Pad_output_0_ncf[] = {
    "_text_encoder_convnext_convnext_1_dwconv_Pad_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_dwconv_Pad_output_0_ncf[] = {1, 256, 132};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_dwconv_Pad_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_dwconv_Pad_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0024582569021732f, .offset= -164}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_dwconv_Pad_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_dwconv_Pad_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_dwconv_Pad_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_dwconv_Pad_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_dwconv_Pad_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d[] = {
    "_text_encoder_convnext_convnext_1_dwconv_Pad_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d[] = {1, 256, 1, 132};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0024582569021732f, .offset= -164}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d_nhwc[] = {1, 1, 132, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0024582569021732f, .offset= -164}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_1_dwconv_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_1_dwconv_weight[] = {1, 5, 1, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_1_dwconv_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_1_dwconv_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0039119152352214f, .offset= -123}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_1_dwconv_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_1_dwconv_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_1_dwconv_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_1_dwconv_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_1_dwconv_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_1_dwconv_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_1_dwconv_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0006552382837981f, .offset= -116}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_1_dwconv_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_1_dwconv_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_1_dwconv_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_dwconv_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_dwconv_Conv_2d */
  uint32_t dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_convnext_convnext_1_dwconv_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_convnext_convnext_1_dwconv_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_convnext_convnext_1_dwconv_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_1_dwconv_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_dwconv_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_dwconv_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_dwconv_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_dwconv_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_dwconv_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_dwconv_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_dwconv_Conv_2d[] = {
    "_text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_convnext_convnext_1_dwconv_weight",
    "tts_ttl_text_encoder_convnext_convnext_1_dwconv_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_dwconv_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_dwconv_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0020005153492093f, .offset= -142}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_dwconv_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "DepthWiseConv2d", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_dwconv_Conv_2d, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_dwconv_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_dwconv_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_dwconv_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_1_dwconv_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_dwconv_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_dwconv_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate_nchw[] = {
    "_text_encoder_convnext_convnext_1_dwconv_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_dwconv_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0020005153492093f, .offset= -142}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_dwconv_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_dwconv_Conv_intermediate */
  const char*  inputs__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate[] = {
    "_text_encoder_convnext_convnext_1_dwconv_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_dwconv_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0020005153492093f, .offset= -142}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_dwconv_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_dwconv_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_dwconv_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_1_dwconv_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_1_dwconv_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_dwconv_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_dwconv_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_dwconv_Conv_output_0_nfc[] = {
    "_text_encoder_convnext_convnext_1_dwconv_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_dwconv_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_dwconv_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0020005153492093f, .offset= -142}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_dwconv_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_dwconv_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_dwconv_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_dwconv_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_dwconv_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_Mul_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_Mul_1 */
  Qnn_Param_t params__text_encoder_convnext_convnext_1_Mul_1[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_Mul_1[] = {
    "_text_encoder_convnext_convnext_1_dwconv_Conv_output_0_nfc",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_norm_Transpose_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_Mul_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_norm_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0020005153492093f, .offset= -142}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_norm_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_Mul_1", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_Mul_1, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_Mul_1, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_Mul_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_1_norm_norm_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_1_norm_norm_weight[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_1_norm_norm_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_1_norm_norm_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0030765924602747f, .offset= 0}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_1_norm_norm_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_1_norm_norm_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_1_norm_norm_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_1_norm_norm_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_1_norm_norm_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_1_norm_norm_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_1_norm_norm_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0017709474777803f, .offset= -135}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_1_norm_norm_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_1_norm_norm_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_1_norm_norm_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_norm_norm_LayerNormalization(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_norm_norm_LayerNormalization */
  uint32_t dimensions__text_encoder_convnext_convnext_1_norm_norm_LayerNormalization_axes[] = {1};
  uint32_t _text_encoder_convnext_convnext_1_norm_norm_LayerNormalization_axes[] = {2};
  Qnn_Param_t params__text_encoder_convnext_convnext_1_norm_norm_LayerNormalization[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="axes",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_norm_norm_LayerNormalization_axes",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_norm_norm_LayerNormalization_axes,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_norm_norm_LayerNormalization_axes,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="epsilon",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000001000000f}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_norm_norm_LayerNormalization[] = {
    "_text_encoder_convnext_convnext_1_norm_Transpose_output_0",
    "tts_ttl_text_encoder_convnext_convnext_1_norm_norm_weight",
    "tts_ttl_text_encoder_convnext_convnext_1_norm_norm_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_norm_Transpose_1_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_norm_norm_LayerNormalization[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_norm_Transpose_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0198324471712112f, .offset= -147}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_norm_Transpose_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_norm_norm_LayerNormalization", // Node Name
                         "qti.aisw", // Package Name
                         "LayerNorm", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_norm_norm_LayerNormalization, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_norm_norm_LayerNormalization, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_norm_norm_LayerNormalization, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_norm_Transpose_1_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_norm_Transpose_1_output_0_ncf */
  uint32_t dimensions__text_encoder_convnext_convnext_1_norm_Transpose_1_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_1_norm_Transpose_1_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_1_norm_Transpose_1_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_norm_Transpose_1_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_norm_Transpose_1_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_norm_Transpose_1_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_norm_Transpose_1_output_0_ncf[] = {
    "_text_encoder_convnext_convnext_1_norm_Transpose_1_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_norm_Transpose_1_output_0_ncf[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_norm_Transpose_1_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_norm_Transpose_1_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0198324471712112f, .offset= -147}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_norm_Transpose_1_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_norm_Transpose_1_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_norm_Transpose_1_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_norm_Transpose_1_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_norm_Transpose_1_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d[] = {
    "_text_encoder_convnext_convnext_1_norm_Transpose_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0198324471712112f, .offset= -147}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0198324471712112f, .offset= -147}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_1_pwconv1_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_1_pwconv1_weight[] = {1, 1, 256, 1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_1_pwconv1_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_1_pwconv1_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0060440655797720f, .offset= -99}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_1_pwconv1_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_1_pwconv1_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_1_pwconv1_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_1_pwconv1_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_1_pwconv1_bias[] = {1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_1_pwconv1_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_1_pwconv1_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0010064707603306f, .offset= -255}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_1_pwconv1_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_1_pwconv1_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_1_pwconv1_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_pwconv1_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_pwconv1_Conv_2d */
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_convnext_convnext_1_pwconv1_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_convnext_convnext_1_pwconv1_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_convnext_convnext_1_pwconv1_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_1_pwconv1_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv1_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_pwconv1_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv1_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_pwconv1_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv1_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_pwconv1_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_pwconv1_Conv_2d[] = {
    "_text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_convnext_convnext_1_pwconv1_weight",
    "tts_ttl_text_encoder_convnext_convnext_1_pwconv1_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_pwconv1_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0428641960024834f, .offset= -196}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_pwconv1_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_pwconv1_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_pwconv1_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_pwconv1_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate_nchw[] = {
    "_text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate_nchw[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0428641960024834f, .offset= -196}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate */
  const char*  inputs__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate[] = {
    "_text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv1_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0428641960024834f, .offset= -196}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv1_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__elementwiseneuron_6(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _elementwiseneuron_6 */
  Qnn_Param_t params__elementwiseneuron_6[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}}
  };
  const char*  inputs__elementwiseneuron_6[] = {
    "_text_encoder_convnext_convnext_1_pwconv1_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_act_Mul_1_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__elementwiseneuron_6[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_act_Mul_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0105441752821207f, .offset= -16}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_act_Mul_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_elementwiseneuron_6", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseNeuron", // Qnn Node Type
                         params__elementwiseneuron_6, // Node Params
                         1, // Num Node Params
                         inputs__elementwiseneuron_6, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__elementwiseneuron_6, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d[] = {
    "_text_encoder_convnext_convnext_1_act_Mul_1_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0105441752821207f, .offset= -16}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0105441752821207f, .offset= -16}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_1_pwconv2_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_1_pwconv2_weight[] = {1, 1, 1024, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_1_pwconv2_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_1_pwconv2_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0052835852839053f, .offset= -123}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_1_pwconv2_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_1_pwconv2_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_1_pwconv2_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_1_pwconv2_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_1_pwconv2_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_1_pwconv2_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_1_pwconv2_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0016830214299262f, .offset= -158}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_1_pwconv2_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_1_pwconv2_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_1_pwconv2_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_pwconv2_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_pwconv2_Conv_2d */
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_convnext_convnext_1_pwconv2_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_convnext_convnext_1_pwconv2_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_convnext_convnext_1_pwconv2_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_1_pwconv2_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv2_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_pwconv2_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv2_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_pwconv2_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv2_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_pwconv2_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_pwconv2_Conv_2d[] = {
    "_text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_convnext_convnext_1_pwconv2_weight",
    "tts_ttl_text_encoder_convnext_convnext_1_pwconv2_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_pwconv2_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0268429797142744f, .offset= -146}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_pwconv2_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_pwconv2_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_pwconv2_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_pwconv2_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate_nchw[] = {
    "_text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0268429797142744f, .offset= -146}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate */
  const char*  inputs__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate[] = {
    "_text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv2_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0268429797142744f, .offset= -146}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_pwconv2_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_pwconv2_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_1_pwconv2_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_1_pwconv2_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv2_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_1_pwconv2_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_pwconv2_Conv_output_0_nfc[] = {
    "_text_encoder_convnext_convnext_1_pwconv2_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_pwconv2_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_pwconv2_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0268429797142744f, .offset= -146}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_pwconv2_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_pwconv2_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_pwconv2_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_pwconv2_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_pwconv2_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_1_gamma(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_1_gamma[] = {1, 1, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_1_gamma", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_1_gamma",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0006438939017244f, .offset= 0}}},
                                 .rank= 3,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_1_gamma,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_1_gamma),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_1_gamma)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_Mul_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_Mul_2 */
  Qnn_Param_t params__text_encoder_convnext_convnext_1_Mul_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_Mul_2[] = {
    "tts_ttl_text_encoder_convnext_convnext_1_gamma",
    "_text_encoder_convnext_convnext_1_pwconv2_Conv_output_0_nfc"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_Mul_2_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_Mul_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_Mul_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0029156617820263f, .offset= -139}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_Mul_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_Mul_2", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_Mul_2, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_Mul_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_Mul_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_Add(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_Add */
  Qnn_Param_t params__text_encoder_convnext_convnext_1_Add[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_Add[] = {
    "_text_encoder_convnext_convnext_1_Mul_output_0",
    "_text_encoder_convnext_convnext_1_Mul_2_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_Add_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_Add[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_Add_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0036487532779574f, .offset= -147}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_Add_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_Add", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_Add, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_Add, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_Add, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_1_Mul_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_1_Mul_3 */
  Qnn_Param_t params__text_encoder_convnext_convnext_1_Mul_3[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_1_Mul_3[] = {
    "_text_encoder_convnext_convnext_1_Add_output_0",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_1_Mul_3_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_1_Mul_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_1_Mul_3_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0036487532779574f, .offset= -147}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_1_Mul_3_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_1_Mul_3", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_1_Mul_3, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_1_Mul_3, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_1_Mul_3, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_Mul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_Mul */
  Qnn_Param_t params__text_encoder_convnext_convnext_2_Mul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_Mul[] = {
    "_text_encoder_convnext_convnext_1_Mul_3_output_0",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_Mul_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_Mul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_Mul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0036487532779574f, .offset= -147}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_Mul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_Mul", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_Mul, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_Mul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_Mul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_dwconv_Pad(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_dwconv_Pad */
  uint32_t dimensions__text_encoder_convnext_convnext_2_dwconv_Pad_pad_amount[] = {3, 2};
  uint32_t _text_encoder_convnext_convnext_2_dwconv_Pad_pad_amount[] = {0, 0, 2, 2, 0, 0};
  Qnn_Param_t params__text_encoder_convnext_convnext_2_dwconv_Pad[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_dwconv_Pad_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_dwconv_Pad_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_dwconv_Pad_pad_amount,
                           .dataSize=24}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 3}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_dwconv_Pad[] = {
    "_text_encoder_convnext_convnext_2_Mul_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_dwconv_Pad_output_0[] = {1, 132, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_dwconv_Pad[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_dwconv_Pad_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0036487532779574f, .offset= -147}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_dwconv_Pad_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_dwconv_Pad", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_dwconv_Pad, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_dwconv_Pad, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_dwconv_Pad, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_dwconv_Pad_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_dwconv_Pad_output_0_ncf */
  uint32_t dimensions__text_encoder_convnext_convnext_2_dwconv_Pad_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_2_dwconv_Pad_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_2_dwconv_Pad_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_dwconv_Pad_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_dwconv_Pad_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_dwconv_Pad_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_dwconv_Pad_output_0_ncf[] = {
    "_text_encoder_convnext_convnext_2_dwconv_Pad_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_dwconv_Pad_output_0_ncf[] = {1, 256, 132};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_dwconv_Pad_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_dwconv_Pad_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0036487532779574f, .offset= -147}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_dwconv_Pad_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_dwconv_Pad_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_dwconv_Pad_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_dwconv_Pad_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_dwconv_Pad_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d[] = {
    "_text_encoder_convnext_convnext_2_dwconv_Pad_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d[] = {1, 256, 1, 132};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0036487532779574f, .offset= -147}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d_nhwc[] = {1, 1, 132, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0036487532779574f, .offset= -147}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_2_dwconv_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_2_dwconv_weight[] = {1, 5, 1, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_2_dwconv_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_2_dwconv_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0039557907730341f, .offset= -127}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_2_dwconv_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_2_dwconv_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_2_dwconv_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_2_dwconv_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_2_dwconv_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_2_dwconv_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_2_dwconv_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0005496464436874f, .offset= -136}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_2_dwconv_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_2_dwconv_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_2_dwconv_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_dwconv_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_dwconv_Conv_2d */
  uint32_t dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_convnext_convnext_2_dwconv_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_convnext_convnext_2_dwconv_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_convnext_convnext_2_dwconv_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_2_dwconv_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_dwconv_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_dwconv_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_dwconv_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_dwconv_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_dwconv_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_dwconv_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_dwconv_Conv_2d[] = {
    "_text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_convnext_convnext_2_dwconv_weight",
    "tts_ttl_text_encoder_convnext_convnext_2_dwconv_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_dwconv_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_dwconv_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0017358409240842f, .offset= -147}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_dwconv_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "DepthWiseConv2d", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_dwconv_Conv_2d, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_dwconv_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_dwconv_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_dwconv_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_2_dwconv_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_dwconv_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_dwconv_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate_nchw[] = {
    "_text_encoder_convnext_convnext_2_dwconv_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_dwconv_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0017358409240842f, .offset= -147}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_dwconv_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_dwconv_Conv_intermediate */
  const char*  inputs__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate[] = {
    "_text_encoder_convnext_convnext_2_dwconv_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_dwconv_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0017358409240842f, .offset= -147}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_dwconv_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_dwconv_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_dwconv_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_2_dwconv_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_2_dwconv_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_dwconv_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_dwconv_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_dwconv_Conv_output_0_nfc[] = {
    "_text_encoder_convnext_convnext_2_dwconv_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_dwconv_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_dwconv_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0017358409240842f, .offset= -147}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_dwconv_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_dwconv_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_dwconv_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_dwconv_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_dwconv_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_Mul_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_Mul_1 */
  Qnn_Param_t params__text_encoder_convnext_convnext_2_Mul_1[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_Mul_1[] = {
    "_text_encoder_convnext_convnext_2_dwconv_Conv_output_0_nfc",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_norm_Transpose_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_Mul_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_norm_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0017358409240842f, .offset= -147}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_norm_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_Mul_1", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_Mul_1, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_Mul_1, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_Mul_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_2_norm_norm_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_2_norm_norm_weight[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_2_norm_norm_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_2_norm_norm_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0029188406188041f, .offset= 0}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_2_norm_norm_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_2_norm_norm_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_2_norm_norm_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_2_norm_norm_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_2_norm_norm_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_2_norm_norm_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_2_norm_norm_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0018504678737372f, .offset= -163}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_2_norm_norm_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_2_norm_norm_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_2_norm_norm_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_norm_norm_LayerNormalization(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_norm_norm_LayerNormalization */
  uint32_t dimensions__text_encoder_convnext_convnext_2_norm_norm_LayerNormalization_axes[] = {1};
  uint32_t _text_encoder_convnext_convnext_2_norm_norm_LayerNormalization_axes[] = {2};
  Qnn_Param_t params__text_encoder_convnext_convnext_2_norm_norm_LayerNormalization[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="axes",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_norm_norm_LayerNormalization_axes",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_norm_norm_LayerNormalization_axes,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_norm_norm_LayerNormalization_axes,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="epsilon",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000001000000f}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_norm_norm_LayerNormalization[] = {
    "_text_encoder_convnext_convnext_2_norm_Transpose_output_0",
    "tts_ttl_text_encoder_convnext_convnext_2_norm_norm_weight",
    "tts_ttl_text_encoder_convnext_convnext_2_norm_norm_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_norm_Transpose_1_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_norm_norm_LayerNormalization[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_norm_Transpose_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0207992512732744f, .offset= -140}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_norm_Transpose_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_norm_norm_LayerNormalization", // Node Name
                         "qti.aisw", // Package Name
                         "LayerNorm", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_norm_norm_LayerNormalization, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_norm_norm_LayerNormalization, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_norm_norm_LayerNormalization, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_norm_Transpose_1_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_norm_Transpose_1_output_0_ncf */
  uint32_t dimensions__text_encoder_convnext_convnext_2_norm_Transpose_1_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_2_norm_Transpose_1_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_2_norm_Transpose_1_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_norm_Transpose_1_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_norm_Transpose_1_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_norm_Transpose_1_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_norm_Transpose_1_output_0_ncf[] = {
    "_text_encoder_convnext_convnext_2_norm_Transpose_1_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_norm_Transpose_1_output_0_ncf[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_norm_Transpose_1_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_norm_Transpose_1_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0207992512732744f, .offset= -140}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_norm_Transpose_1_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_norm_Transpose_1_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_norm_Transpose_1_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_norm_Transpose_1_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_norm_Transpose_1_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d[] = {
    "_text_encoder_convnext_convnext_2_norm_Transpose_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0207992512732744f, .offset= -140}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0207992512732744f, .offset= -140}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_2_pwconv1_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_2_pwconv1_weight[] = {1, 1, 256, 1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_2_pwconv1_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_2_pwconv1_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0061069116927683f, .offset= -121}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_2_pwconv1_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_2_pwconv1_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_2_pwconv1_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_2_pwconv1_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_2_pwconv1_bias[] = {1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_2_pwconv1_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_2_pwconv1_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0016133331228048f, .offset= -226}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_2_pwconv1_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_2_pwconv1_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_2_pwconv1_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_pwconv1_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_pwconv1_Conv_2d */
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_convnext_convnext_2_pwconv1_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_convnext_convnext_2_pwconv1_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_convnext_convnext_2_pwconv1_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_2_pwconv1_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv1_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_pwconv1_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv1_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_pwconv1_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv1_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_pwconv1_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_pwconv1_Conv_2d[] = {
    "_text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_convnext_convnext_2_pwconv1_weight",
    "tts_ttl_text_encoder_convnext_convnext_2_pwconv1_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_pwconv1_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0455671772360802f, .offset= -180}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_pwconv1_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_pwconv1_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_pwconv1_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_pwconv1_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate_nchw[] = {
    "_text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate_nchw[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0455671772360802f, .offset= -180}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate */
  const char*  inputs__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate[] = {
    "_text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv1_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0455671772360802f, .offset= -180}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv1_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__elementwiseneuron_8(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _elementwiseneuron_8 */
  Qnn_Param_t params__elementwiseneuron_8[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}}
  };
  const char*  inputs__elementwiseneuron_8[] = {
    "_text_encoder_convnext_convnext_2_pwconv1_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_act_Mul_1_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__elementwiseneuron_8[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_act_Mul_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0140139497816563f, .offset= -12}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_act_Mul_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_elementwiseneuron_8", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseNeuron", // Qnn Node Type
                         params__elementwiseneuron_8, // Node Params
                         1, // Num Node Params
                         inputs__elementwiseneuron_8, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__elementwiseneuron_8, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d[] = {
    "_text_encoder_convnext_convnext_2_act_Mul_1_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0140139497816563f, .offset= -12}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0140139497816563f, .offset= -12}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_2_pwconv2_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_2_pwconv2_weight[] = {1, 1, 1024, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_2_pwconv2_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_2_pwconv2_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0064477263949811f, .offset= -130}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_2_pwconv2_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_2_pwconv2_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_2_pwconv2_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_2_pwconv2_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_2_pwconv2_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_2_pwconv2_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_2_pwconv2_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0014820704236627f, .offset= -141}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_2_pwconv2_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_2_pwconv2_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_2_pwconv2_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_pwconv2_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_pwconv2_Conv_2d */
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_convnext_convnext_2_pwconv2_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_convnext_convnext_2_pwconv2_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_convnext_convnext_2_pwconv2_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_2_pwconv2_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv2_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_pwconv2_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv2_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_pwconv2_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv2_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_pwconv2_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_pwconv2_Conv_2d[] = {
    "_text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_convnext_convnext_2_pwconv2_weight",
    "tts_ttl_text_encoder_convnext_convnext_2_pwconv2_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_pwconv2_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0242652911692858f, .offset= -126}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_pwconv2_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_pwconv2_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_pwconv2_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_pwconv2_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate_nchw[] = {
    "_text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0242652911692858f, .offset= -126}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate */
  const char*  inputs__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate[] = {
    "_text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv2_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0242652911692858f, .offset= -126}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_pwconv2_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_pwconv2_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_2_pwconv2_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_2_pwconv2_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv2_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_2_pwconv2_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_pwconv2_Conv_output_0_nfc[] = {
    "_text_encoder_convnext_convnext_2_pwconv2_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_pwconv2_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_pwconv2_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0242652911692858f, .offset= -126}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_pwconv2_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_pwconv2_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_pwconv2_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_pwconv2_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_pwconv2_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_2_gamma(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_2_gamma[] = {1, 1, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_2_gamma", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_2_gamma",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0008621500455774f, .offset= 0}}},
                                 .rank= 3,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_2_gamma,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_2_gamma),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_2_gamma)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_Mul_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_Mul_2 */
  Qnn_Param_t params__text_encoder_convnext_convnext_2_Mul_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_Mul_2[] = {
    "tts_ttl_text_encoder_convnext_convnext_2_gamma",
    "_text_encoder_convnext_convnext_2_pwconv2_Conv_output_0_nfc"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_Mul_2_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_Mul_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_Mul_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0032389697153121f, .offset= -134}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_Mul_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_Mul_2", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_Mul_2, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_Mul_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_Mul_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_Add(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_Add */
  Qnn_Param_t params__text_encoder_convnext_convnext_2_Add[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_Add[] = {
    "_text_encoder_convnext_convnext_2_Mul_output_0",
    "_text_encoder_convnext_convnext_2_Mul_2_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_Add_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_Add[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_Add_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0047915419563651f, .offset= -121}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_Add_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_Add", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_Add, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_Add, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_Add, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_2_Mul_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_2_Mul_3 */
  Qnn_Param_t params__text_encoder_convnext_convnext_2_Mul_3[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_2_Mul_3[] = {
    "_text_encoder_convnext_convnext_2_Add_output_0",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_2_Mul_3_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_2_Mul_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_2_Mul_3_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0047915419563651f, .offset= -121}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_2_Mul_3_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_2_Mul_3", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_2_Mul_3, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_2_Mul_3, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_2_Mul_3, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_Mul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_Mul */
  Qnn_Param_t params__text_encoder_convnext_convnext_3_Mul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_Mul[] = {
    "_text_encoder_convnext_convnext_2_Mul_3_output_0",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_Mul_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_Mul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_Mul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0047915419563651f, .offset= -121}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_Mul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_Mul", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_Mul, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_Mul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_Mul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_dwconv_Pad(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_dwconv_Pad */
  uint32_t dimensions__text_encoder_convnext_convnext_3_dwconv_Pad_pad_amount[] = {3, 2};
  uint32_t _text_encoder_convnext_convnext_3_dwconv_Pad_pad_amount[] = {0, 0, 2, 2, 0, 0};
  Qnn_Param_t params__text_encoder_convnext_convnext_3_dwconv_Pad[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_dwconv_Pad_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_dwconv_Pad_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_dwconv_Pad_pad_amount,
                           .dataSize=24}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 3}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_dwconv_Pad[] = {
    "_text_encoder_convnext_convnext_3_Mul_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_dwconv_Pad_output_0[] = {1, 132, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_dwconv_Pad[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_dwconv_Pad_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0047915419563651f, .offset= -121}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_dwconv_Pad_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_dwconv_Pad", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_dwconv_Pad, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_dwconv_Pad, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_dwconv_Pad, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_dwconv_Pad_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_dwconv_Pad_output_0_ncf */
  uint32_t dimensions__text_encoder_convnext_convnext_3_dwconv_Pad_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_3_dwconv_Pad_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_3_dwconv_Pad_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_dwconv_Pad_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_dwconv_Pad_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_dwconv_Pad_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_dwconv_Pad_output_0_ncf[] = {
    "_text_encoder_convnext_convnext_3_dwconv_Pad_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_dwconv_Pad_output_0_ncf[] = {1, 256, 132};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_dwconv_Pad_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_dwconv_Pad_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0047915419563651f, .offset= -121}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_dwconv_Pad_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_dwconv_Pad_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_dwconv_Pad_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_dwconv_Pad_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_dwconv_Pad_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d[] = {
    "_text_encoder_convnext_convnext_3_dwconv_Pad_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d[] = {1, 256, 1, 132};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0047915419563651f, .offset= -121}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d_nhwc[] = {1, 1, 132, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0047915419563651f, .offset= -121}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_3_dwconv_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_3_dwconv_weight[] = {1, 5, 1, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_3_dwconv_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_3_dwconv_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0037376969121397f, .offset= -129}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_3_dwconv_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_3_dwconv_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_3_dwconv_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_3_dwconv_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_3_dwconv_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_3_dwconv_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_3_dwconv_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0007172069745138f, .offset= -116}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_3_dwconv_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_3_dwconv_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_3_dwconv_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_dwconv_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_dwconv_Conv_2d */
  uint32_t dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_convnext_convnext_3_dwconv_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_convnext_convnext_3_dwconv_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_convnext_convnext_3_dwconv_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_3_dwconv_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_dwconv_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_dwconv_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_dwconv_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_dwconv_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_dwconv_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_dwconv_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_dwconv_Conv_2d[] = {
    "_text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_convnext_convnext_3_dwconv_weight",
    "tts_ttl_text_encoder_convnext_convnext_3_dwconv_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_dwconv_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_dwconv_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0015048831701279f, .offset= -133}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_dwconv_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "DepthWiseConv2d", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_dwconv_Conv_2d, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_dwconv_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_dwconv_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_dwconv_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_3_dwconv_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_dwconv_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_dwconv_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate_nchw[] = {
    "_text_encoder_convnext_convnext_3_dwconv_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_dwconv_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0015048831701279f, .offset= -133}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_dwconv_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_dwconv_Conv_intermediate */
  const char*  inputs__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate[] = {
    "_text_encoder_convnext_convnext_3_dwconv_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_dwconv_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0015048831701279f, .offset= -133}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_dwconv_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_dwconv_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_dwconv_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_3_dwconv_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_3_dwconv_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_dwconv_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_dwconv_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_dwconv_Conv_output_0_nfc[] = {
    "_text_encoder_convnext_convnext_3_dwconv_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_dwconv_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_dwconv_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0015048831701279f, .offset= -133}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_dwconv_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_dwconv_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_dwconv_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_dwconv_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_dwconv_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_Mul_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_Mul_1 */
  Qnn_Param_t params__text_encoder_convnext_convnext_3_Mul_1[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_Mul_1[] = {
    "_text_encoder_convnext_convnext_3_dwconv_Conv_output_0_nfc",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_norm_Transpose_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_Mul_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_norm_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0015048831701279f, .offset= -133}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_norm_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_Mul_1", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_Mul_1, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_Mul_1, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_Mul_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_3_norm_norm_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_3_norm_norm_weight[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_3_norm_norm_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_3_norm_norm_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0026141786947846f, .offset= 0}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_3_norm_norm_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_3_norm_norm_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_3_norm_norm_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_3_norm_norm_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_3_norm_norm_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_3_norm_norm_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_3_norm_norm_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0023385544773191f, .offset= -166}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_3_norm_norm_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_3_norm_norm_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_3_norm_norm_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_norm_norm_LayerNormalization(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_norm_norm_LayerNormalization */
  uint32_t dimensions__text_encoder_convnext_convnext_3_norm_norm_LayerNormalization_axes[] = {1};
  uint32_t _text_encoder_convnext_convnext_3_norm_norm_LayerNormalization_axes[] = {2};
  Qnn_Param_t params__text_encoder_convnext_convnext_3_norm_norm_LayerNormalization[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="axes",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_norm_norm_LayerNormalization_axes",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_norm_norm_LayerNormalization_axes,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_norm_norm_LayerNormalization_axes,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="epsilon",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000001000000f}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_norm_norm_LayerNormalization[] = {
    "_text_encoder_convnext_convnext_3_norm_Transpose_output_0",
    "tts_ttl_text_encoder_convnext_convnext_3_norm_norm_weight",
    "tts_ttl_text_encoder_convnext_convnext_3_norm_norm_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_norm_Transpose_1_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_norm_norm_LayerNormalization[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_norm_Transpose_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0138589376583695f, .offset= -138}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_norm_Transpose_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_norm_norm_LayerNormalization", // Node Name
                         "qti.aisw", // Package Name
                         "LayerNorm", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_norm_norm_LayerNormalization, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_norm_norm_LayerNormalization, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_norm_norm_LayerNormalization, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_norm_Transpose_1_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_norm_Transpose_1_output_0_ncf */
  uint32_t dimensions__text_encoder_convnext_convnext_3_norm_Transpose_1_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_3_norm_Transpose_1_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_3_norm_Transpose_1_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_norm_Transpose_1_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_norm_Transpose_1_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_norm_Transpose_1_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_norm_Transpose_1_output_0_ncf[] = {
    "_text_encoder_convnext_convnext_3_norm_Transpose_1_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_norm_Transpose_1_output_0_ncf[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_norm_Transpose_1_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_norm_Transpose_1_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0138589376583695f, .offset= -138}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_norm_Transpose_1_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_norm_Transpose_1_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_norm_Transpose_1_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_norm_Transpose_1_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_norm_Transpose_1_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d[] = {
    "_text_encoder_convnext_convnext_3_norm_Transpose_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0138589376583695f, .offset= -138}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0138589376583695f, .offset= -138}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_3_pwconv1_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_3_pwconv1_weight[] = {1, 1, 256, 1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_3_pwconv1_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_3_pwconv1_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0085476506501436f, .offset= -157}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_3_pwconv1_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_3_pwconv1_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_3_pwconv1_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_3_pwconv1_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_3_pwconv1_bias[] = {1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_3_pwconv1_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_3_pwconv1_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0017833076417446f, .offset= -241}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_3_pwconv1_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_3_pwconv1_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_3_pwconv1_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_pwconv1_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_pwconv1_Conv_2d */
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_convnext_convnext_3_pwconv1_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_convnext_convnext_3_pwconv1_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_convnext_convnext_3_pwconv1_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_3_pwconv1_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv1_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_pwconv1_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv1_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_pwconv1_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv1_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_pwconv1_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_pwconv1_Conv_2d[] = {
    "_text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_convnext_convnext_3_pwconv1_weight",
    "tts_ttl_text_encoder_convnext_convnext_3_pwconv1_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_pwconv1_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0459975190460682f, .offset= -213}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_pwconv1_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_pwconv1_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_pwconv1_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_pwconv1_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate_nchw[] = {
    "_text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate_nchw[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0459975190460682f, .offset= -213}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate */
  const char*  inputs__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate[] = {
    "_text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv1_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0459975190460682f, .offset= -213}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv1_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__elementwiseneuron_10(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _elementwiseneuron_10 */
  Qnn_Param_t params__elementwiseneuron_10[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}}
  };
  const char*  inputs__elementwiseneuron_10[] = {
    "_text_encoder_convnext_convnext_3_pwconv1_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_act_Mul_1_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__elementwiseneuron_10[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_act_Mul_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0080577526241541f, .offset= -21}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_act_Mul_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_elementwiseneuron_10", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseNeuron", // Qnn Node Type
                         params__elementwiseneuron_10, // Node Params
                         1, // Num Node Params
                         inputs__elementwiseneuron_10, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__elementwiseneuron_10, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d[] = {
    "_text_encoder_convnext_convnext_3_act_Mul_1_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0080577526241541f, .offset= -21}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0080577526241541f, .offset= -21}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_3_pwconv2_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_3_pwconv2_weight[] = {1, 1, 1024, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_3_pwconv2_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_3_pwconv2_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0066233011893928f, .offset= -136}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_3_pwconv2_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_3_pwconv2_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_3_pwconv2_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_3_pwconv2_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_3_pwconv2_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_3_pwconv2_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_3_pwconv2_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0015156446024776f, .offset= -155}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_3_pwconv2_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_3_pwconv2_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_3_pwconv2_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_pwconv2_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_pwconv2_Conv_2d */
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_convnext_convnext_3_pwconv2_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_convnext_convnext_3_pwconv2_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_convnext_convnext_3_pwconv2_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_3_pwconv2_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv2_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_pwconv2_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv2_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_pwconv2_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv2_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_pwconv2_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_pwconv2_Conv_2d[] = {
    "_text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_convnext_convnext_3_pwconv2_weight",
    "tts_ttl_text_encoder_convnext_convnext_3_pwconv2_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_pwconv2_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0255933403968811f, .offset= -107}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_pwconv2_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_pwconv2_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_pwconv2_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_pwconv2_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate_nchw[] = {
    "_text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0255933403968811f, .offset= -107}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate */
  const char*  inputs__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate[] = {
    "_text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv2_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0255933403968811f, .offset= -107}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_pwconv2_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_pwconv2_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_3_pwconv2_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_3_pwconv2_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv2_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_3_pwconv2_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_pwconv2_Conv_output_0_nfc[] = {
    "_text_encoder_convnext_convnext_3_pwconv2_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_pwconv2_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_pwconv2_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0255933403968811f, .offset= -107}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_pwconv2_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_pwconv2_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_pwconv2_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_pwconv2_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_pwconv2_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_3_gamma(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_3_gamma[] = {1, 1, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_3_gamma", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_3_gamma",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0010217961389571f, .offset= 0}}},
                                 .rank= 3,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_3_gamma,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_3_gamma),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_3_gamma)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_Mul_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_Mul_2 */
  Qnn_Param_t params__text_encoder_convnext_convnext_3_Mul_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_Mul_2[] = {
    "tts_ttl_text_encoder_convnext_convnext_3_gamma",
    "_text_encoder_convnext_convnext_3_pwconv2_Conv_output_0_nfc"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_Mul_2_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_Mul_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_Mul_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0059016006998718f, .offset= -97}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_Mul_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_Mul_2", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_Mul_2, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_Mul_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_Mul_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_Add(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_Add */
  Qnn_Param_t params__text_encoder_convnext_convnext_3_Add[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_Add[] = {
    "_text_encoder_convnext_convnext_3_Mul_output_0",
    "_text_encoder_convnext_convnext_3_Mul_2_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_Add_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_Add[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_Add_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0066791884601116f, .offset= -125}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_Add_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_Add", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_Add, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_Add, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_Add, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_3_Mul_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_3_Mul_3 */
  Qnn_Param_t params__text_encoder_convnext_convnext_3_Mul_3[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_3_Mul_3[] = {
    "_text_encoder_convnext_convnext_3_Add_output_0",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_3_Mul_3_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_3_Mul_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_3_Mul_3_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0066791884601116f, .offset= -125}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_3_Mul_3_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_3_Mul_3", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_3_Mul_3, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_3_Mul_3, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_3_Mul_3, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_Mul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_Mul */
  Qnn_Param_t params__text_encoder_convnext_convnext_4_Mul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_Mul[] = {
    "_text_encoder_convnext_convnext_3_Mul_3_output_0",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_Mul_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_Mul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_Mul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0066791884601116f, .offset= -125}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_Mul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_Mul", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_Mul, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_Mul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_Mul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_dwconv_Pad(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_dwconv_Pad */
  uint32_t dimensions__text_encoder_convnext_convnext_4_dwconv_Pad_pad_amount[] = {3, 2};
  uint32_t _text_encoder_convnext_convnext_4_dwconv_Pad_pad_amount[] = {0, 0, 2, 2, 0, 0};
  Qnn_Param_t params__text_encoder_convnext_convnext_4_dwconv_Pad[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_dwconv_Pad_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_dwconv_Pad_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_dwconv_Pad_pad_amount,
                           .dataSize=24}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 3}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_dwconv_Pad[] = {
    "_text_encoder_convnext_convnext_4_Mul_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_dwconv_Pad_output_0[] = {1, 132, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_dwconv_Pad[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_dwconv_Pad_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0066791884601116f, .offset= -125}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_dwconv_Pad_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_dwconv_Pad", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_dwconv_Pad, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_dwconv_Pad, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_dwconv_Pad, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_dwconv_Pad_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_dwconv_Pad_output_0_ncf */
  uint32_t dimensions__text_encoder_convnext_convnext_4_dwconv_Pad_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_4_dwconv_Pad_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_4_dwconv_Pad_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_dwconv_Pad_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_dwconv_Pad_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_dwconv_Pad_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_dwconv_Pad_output_0_ncf[] = {
    "_text_encoder_convnext_convnext_4_dwconv_Pad_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_dwconv_Pad_output_0_ncf[] = {1, 256, 132};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_dwconv_Pad_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_dwconv_Pad_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0066791884601116f, .offset= -125}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_dwconv_Pad_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_dwconv_Pad_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_dwconv_Pad_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_dwconv_Pad_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_dwconv_Pad_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d[] = {
    "_text_encoder_convnext_convnext_4_dwconv_Pad_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d[] = {1, 256, 1, 132};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0066791884601116f, .offset= -125}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d_nhwc[] = {1, 1, 132, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0066791884601116f, .offset= -125}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_4_dwconv_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_4_dwconv_weight[] = {1, 5, 1, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_4_dwconv_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_4_dwconv_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0038689388893545f, .offset= -124}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_4_dwconv_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_4_dwconv_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_4_dwconv_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_4_dwconv_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_4_dwconv_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_4_dwconv_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_4_dwconv_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0011162594892085f, .offset= -153}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_4_dwconv_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_4_dwconv_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_4_dwconv_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_dwconv_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_dwconv_Conv_2d */
  uint32_t dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_convnext_convnext_4_dwconv_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_convnext_convnext_4_dwconv_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_convnext_convnext_4_dwconv_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_4_dwconv_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_dwconv_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_dwconv_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_dwconv_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_dwconv_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_dwconv_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_dwconv_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_dwconv_Conv_2d[] = {
    "_text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_convnext_convnext_4_dwconv_weight",
    "tts_ttl_text_encoder_convnext_convnext_4_dwconv_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_dwconv_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_dwconv_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0025611808523536f, .offset= -110}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_dwconv_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "DepthWiseConv2d", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_dwconv_Conv_2d, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_dwconv_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_dwconv_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_dwconv_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_4_dwconv_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_dwconv_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_dwconv_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate_nchw[] = {
    "_text_encoder_convnext_convnext_4_dwconv_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_dwconv_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0025611808523536f, .offset= -110}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_dwconv_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_dwconv_Conv_intermediate */
  const char*  inputs__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate[] = {
    "_text_encoder_convnext_convnext_4_dwconv_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_dwconv_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0025611808523536f, .offset= -110}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_dwconv_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_dwconv_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_dwconv_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_4_dwconv_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_4_dwconv_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_dwconv_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_dwconv_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_dwconv_Conv_output_0_nfc[] = {
    "_text_encoder_convnext_convnext_4_dwconv_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_dwconv_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_dwconv_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0025611808523536f, .offset= -110}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_dwconv_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_dwconv_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_dwconv_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_dwconv_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_dwconv_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_Mul_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_Mul_1 */
  Qnn_Param_t params__text_encoder_convnext_convnext_4_Mul_1[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_Mul_1[] = {
    "_text_encoder_convnext_convnext_4_dwconv_Conv_output_0_nfc",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_norm_Transpose_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_Mul_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_norm_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0025611808523536f, .offset= -110}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_norm_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_Mul_1", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_Mul_1, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_Mul_1, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_Mul_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_4_norm_norm_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_4_norm_norm_weight[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_4_norm_norm_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_4_norm_norm_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0031459967140108f, .offset= 0}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_4_norm_norm_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_4_norm_norm_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_4_norm_norm_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_4_norm_norm_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_4_norm_norm_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_4_norm_norm_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_4_norm_norm_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0023850249126554f, .offset= -136}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_4_norm_norm_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_4_norm_norm_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_4_norm_norm_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_norm_norm_LayerNormalization(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_norm_norm_LayerNormalization */
  uint32_t dimensions__text_encoder_convnext_convnext_4_norm_norm_LayerNormalization_axes[] = {1};
  uint32_t _text_encoder_convnext_convnext_4_norm_norm_LayerNormalization_axes[] = {2};
  Qnn_Param_t params__text_encoder_convnext_convnext_4_norm_norm_LayerNormalization[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="axes",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_norm_norm_LayerNormalization_axes",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_norm_norm_LayerNormalization_axes,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_norm_norm_LayerNormalization_axes,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="epsilon",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000001000000f}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_norm_norm_LayerNormalization[] = {
    "_text_encoder_convnext_convnext_4_norm_Transpose_output_0",
    "tts_ttl_text_encoder_convnext_convnext_4_norm_norm_weight",
    "tts_ttl_text_encoder_convnext_convnext_4_norm_norm_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_norm_Transpose_1_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_norm_norm_LayerNormalization[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_norm_Transpose_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0171116013079882f, .offset= -103}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_norm_Transpose_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_norm_norm_LayerNormalization", // Node Name
                         "qti.aisw", // Package Name
                         "LayerNorm", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_norm_norm_LayerNormalization, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_norm_norm_LayerNormalization, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_norm_norm_LayerNormalization, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_norm_Transpose_1_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_norm_Transpose_1_output_0_ncf */
  uint32_t dimensions__text_encoder_convnext_convnext_4_norm_Transpose_1_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_4_norm_Transpose_1_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_4_norm_Transpose_1_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_norm_Transpose_1_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_norm_Transpose_1_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_norm_Transpose_1_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_norm_Transpose_1_output_0_ncf[] = {
    "_text_encoder_convnext_convnext_4_norm_Transpose_1_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_norm_Transpose_1_output_0_ncf[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_norm_Transpose_1_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_norm_Transpose_1_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0171116013079882f, .offset= -103}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_norm_Transpose_1_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_norm_Transpose_1_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_norm_Transpose_1_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_norm_Transpose_1_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_norm_Transpose_1_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d[] = {
    "_text_encoder_convnext_convnext_4_norm_Transpose_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0171116013079882f, .offset= -103}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0171116013079882f, .offset= -103}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_4_pwconv1_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_4_pwconv1_weight[] = {1, 1, 256, 1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_4_pwconv1_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_4_pwconv1_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0071788122877479f, .offset= -125}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_4_pwconv1_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_4_pwconv1_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_4_pwconv1_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_4_pwconv1_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_4_pwconv1_bias[] = {1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_4_pwconv1_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_4_pwconv1_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0019815310370177f, .offset= -207}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_4_pwconv1_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_4_pwconv1_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_4_pwconv1_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_pwconv1_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_pwconv1_Conv_2d */
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_convnext_convnext_4_pwconv1_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_convnext_convnext_4_pwconv1_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_convnext_convnext_4_pwconv1_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_4_pwconv1_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv1_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_pwconv1_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv1_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_pwconv1_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv1_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_pwconv1_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_pwconv1_Conv_2d[] = {
    "_text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_convnext_convnext_4_pwconv1_weight",
    "tts_ttl_text_encoder_convnext_convnext_4_pwconv1_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_pwconv1_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0466976389288902f, .offset= -165}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_pwconv1_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_pwconv1_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_pwconv1_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_pwconv1_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate_nchw[] = {
    "_text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate_nchw[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0466976389288902f, .offset= -165}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate */
  const char*  inputs__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate[] = {
    "_text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv1_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0466976389288902f, .offset= -165}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv1_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__elementwiseneuron_12(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _elementwiseneuron_12 */
  Qnn_Param_t params__elementwiseneuron_12[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}}
  };
  const char*  inputs__elementwiseneuron_12[] = {
    "_text_encoder_convnext_convnext_4_pwconv1_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_act_Mul_1_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__elementwiseneuron_12[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_act_Mul_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0171947311609983f, .offset= -10}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_act_Mul_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_elementwiseneuron_12", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseNeuron", // Qnn Node Type
                         params__elementwiseneuron_12, // Node Params
                         1, // Num Node Params
                         inputs__elementwiseneuron_12, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__elementwiseneuron_12, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d[] = {
    "_text_encoder_convnext_convnext_4_act_Mul_1_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0171947311609983f, .offset= -10}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0171947311609983f, .offset= -10}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_4_pwconv2_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_4_pwconv2_weight[] = {1, 1, 1024, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_4_pwconv2_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_4_pwconv2_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0081358654424548f, .offset= -145}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_4_pwconv2_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_4_pwconv2_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_4_pwconv2_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_4_pwconv2_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_4_pwconv2_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_4_pwconv2_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_4_pwconv2_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0017381724901497f, .offset= -143}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_4_pwconv2_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_4_pwconv2_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_4_pwconv2_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_pwconv2_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_pwconv2_Conv_2d */
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_convnext_convnext_4_pwconv2_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_convnext_convnext_4_pwconv2_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_convnext_convnext_4_pwconv2_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_4_pwconv2_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv2_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_pwconv2_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv2_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_pwconv2_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv2_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_pwconv2_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_pwconv2_Conv_2d[] = {
    "_text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_convnext_convnext_4_pwconv2_weight",
    "tts_ttl_text_encoder_convnext_convnext_4_pwconv2_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_pwconv2_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1282655596733093f, .offset= -150}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_pwconv2_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_pwconv2_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_pwconv2_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_pwconv2_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate_nchw[] = {
    "_text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1282655596733093f, .offset= -150}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate */
  const char*  inputs__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate[] = {
    "_text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv2_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1282655596733093f, .offset= -150}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_pwconv2_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_pwconv2_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_4_pwconv2_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_4_pwconv2_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv2_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_4_pwconv2_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_pwconv2_Conv_output_0_nfc[] = {
    "_text_encoder_convnext_convnext_4_pwconv2_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_pwconv2_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_pwconv2_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1282655596733093f, .offset= -150}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_pwconv2_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_pwconv2_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_pwconv2_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_pwconv2_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_pwconv2_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_4_gamma(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_4_gamma[] = {1, 1, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_4_gamma", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_4_gamma",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0014339591143653f, .offset= 0}}},
                                 .rank= 3,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_4_gamma,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_4_gamma),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_4_gamma)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_Mul_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_Mul_2 */
  Qnn_Param_t params__text_encoder_convnext_convnext_4_Mul_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_Mul_2[] = {
    "tts_ttl_text_encoder_convnext_convnext_4_gamma",
    "_text_encoder_convnext_convnext_4_pwconv2_Conv_output_0_nfc"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_Mul_2_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_Mul_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_Mul_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0363092198967934f, .offset= -159}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_Mul_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_Mul_2", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_Mul_2, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_Mul_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_Mul_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_Add(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_Add */
  Qnn_Param_t params__text_encoder_convnext_convnext_4_Add[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_Add[] = {
    "_text_encoder_convnext_convnext_4_Mul_output_0",
    "_text_encoder_convnext_convnext_4_Mul_2_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_Add_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_Add[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_Add_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0415270887315273f, .offset= -150}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_Add_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_Add", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_Add, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_Add, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_Add, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_4_Mul_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_4_Mul_3 */
  Qnn_Param_t params__text_encoder_convnext_convnext_4_Mul_3[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_4_Mul_3[] = {
    "_text_encoder_convnext_convnext_4_Add_output_0",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_4_Mul_3_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_4_Mul_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_4_Mul_3_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0415270887315273f, .offset= -150}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_4_Mul_3_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_4_Mul_3", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_4_Mul_3, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_4_Mul_3, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_4_Mul_3, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_Mul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_Mul */
  Qnn_Param_t params__text_encoder_convnext_convnext_5_Mul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_Mul[] = {
    "_text_encoder_convnext_convnext_4_Mul_3_output_0",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_Mul_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_Mul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_Mul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0415270887315273f, .offset= -150}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_Mul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_Mul", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_Mul, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_Mul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_Mul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_dwconv_Pad(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_dwconv_Pad */
  uint32_t dimensions__text_encoder_convnext_convnext_5_dwconv_Pad_pad_amount[] = {3, 2};
  uint32_t _text_encoder_convnext_convnext_5_dwconv_Pad_pad_amount[] = {0, 0, 2, 2, 0, 0};
  Qnn_Param_t params__text_encoder_convnext_convnext_5_dwconv_Pad[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_dwconv_Pad_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_dwconv_Pad_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_dwconv_Pad_pad_amount,
                           .dataSize=24}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 3}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_dwconv_Pad[] = {
    "_text_encoder_convnext_convnext_5_Mul_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_dwconv_Pad_output_0[] = {1, 132, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_dwconv_Pad[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_dwconv_Pad_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0415270887315273f, .offset= -150}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_dwconv_Pad_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_dwconv_Pad", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_dwconv_Pad, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_dwconv_Pad, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_dwconv_Pad, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_dwconv_Pad_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_dwconv_Pad_output_0_ncf */
  uint32_t dimensions__text_encoder_convnext_convnext_5_dwconv_Pad_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_5_dwconv_Pad_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_5_dwconv_Pad_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_dwconv_Pad_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_dwconv_Pad_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_dwconv_Pad_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_dwconv_Pad_output_0_ncf[] = {
    "_text_encoder_convnext_convnext_5_dwconv_Pad_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_dwconv_Pad_output_0_ncf[] = {1, 256, 132};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_dwconv_Pad_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_dwconv_Pad_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0415270887315273f, .offset= -150}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_dwconv_Pad_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_dwconv_Pad_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_dwconv_Pad_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_dwconv_Pad_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_dwconv_Pad_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d[] = {
    "_text_encoder_convnext_convnext_5_dwconv_Pad_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d[] = {1, 256, 1, 132};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0415270887315273f, .offset= -150}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d_nhwc[] = {1, 1, 132, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0415270887315273f, .offset= -150}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_5_dwconv_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_5_dwconv_weight[] = {1, 5, 1, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_5_dwconv_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_5_dwconv_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0039738528430462f, .offset= -146}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_5_dwconv_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_5_dwconv_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_5_dwconv_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_5_dwconv_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_5_dwconv_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_5_dwconv_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_5_dwconv_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0013378033181652f, .offset= -133}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_5_dwconv_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_5_dwconv_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_5_dwconv_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_dwconv_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_dwconv_Conv_2d */
  uint32_t dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_convnext_convnext_5_dwconv_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_convnext_convnext_5_dwconv_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_convnext_convnext_5_dwconv_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_5_dwconv_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_dwconv_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_dwconv_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_dwconv_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_dwconv_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_dwconv_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_dwconv_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_dwconv_Conv_2d[] = {
    "_text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_convnext_convnext_5_dwconv_weight",
    "tts_ttl_text_encoder_convnext_convnext_5_dwconv_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_dwconv_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_dwconv_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0080757103860378f, .offset= -124}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_dwconv_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "DepthWiseConv2d", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_dwconv_Conv_2d, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_dwconv_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_dwconv_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_dwconv_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_5_dwconv_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_dwconv_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_dwconv_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate_nchw[] = {
    "_text_encoder_convnext_convnext_5_dwconv_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_dwconv_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0080757103860378f, .offset= -124}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_dwconv_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_dwconv_Conv_intermediate */
  const char*  inputs__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate[] = {
    "_text_encoder_convnext_convnext_5_dwconv_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_dwconv_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0080757103860378f, .offset= -124}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_dwconv_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_dwconv_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_dwconv_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_5_dwconv_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_5_dwconv_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_dwconv_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_dwconv_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_dwconv_Conv_output_0_nfc[] = {
    "_text_encoder_convnext_convnext_5_dwconv_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_dwconv_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_dwconv_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0080757103860378f, .offset= -124}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_dwconv_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_dwconv_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_dwconv_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_dwconv_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_dwconv_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_Mul_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_Mul_1 */
  Qnn_Param_t params__text_encoder_convnext_convnext_5_Mul_1[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_Mul_1[] = {
    "_text_encoder_convnext_convnext_5_dwconv_Conv_output_0_nfc",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_norm_Transpose_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_Mul_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_norm_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0070339031517506f, .offset= -111}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_norm_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_Mul_1", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_Mul_1, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_Mul_1, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_Mul_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_5_norm_norm_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_5_norm_norm_weight[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_5_norm_norm_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_5_norm_norm_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0027691177092493f, .offset= 0}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_5_norm_norm_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_5_norm_norm_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_5_norm_norm_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_5_norm_norm_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_5_norm_norm_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_5_norm_norm_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_5_norm_norm_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0024013787042350f, .offset= -114}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_5_norm_norm_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_5_norm_norm_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_5_norm_norm_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_norm_norm_LayerNormalization(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_norm_norm_LayerNormalization */
  uint32_t dimensions__text_encoder_convnext_convnext_5_norm_norm_LayerNormalization_axes[] = {1};
  uint32_t _text_encoder_convnext_convnext_5_norm_norm_LayerNormalization_axes[] = {2};
  Qnn_Param_t params__text_encoder_convnext_convnext_5_norm_norm_LayerNormalization[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="axes",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_norm_norm_LayerNormalization_axes",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_norm_norm_LayerNormalization_axes,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_norm_norm_LayerNormalization_axes,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="epsilon",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000001000000f}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_norm_norm_LayerNormalization[] = {
    "_text_encoder_convnext_convnext_5_norm_Transpose_output_0",
    "tts_ttl_text_encoder_convnext_convnext_5_norm_norm_weight",
    "tts_ttl_text_encoder_convnext_convnext_5_norm_norm_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_norm_Transpose_1_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_norm_norm_LayerNormalization[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_norm_Transpose_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0157615635544062f, .offset= -111}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_norm_Transpose_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_norm_norm_LayerNormalization", // Node Name
                         "qti.aisw", // Package Name
                         "LayerNorm", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_norm_norm_LayerNormalization, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_norm_norm_LayerNormalization, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_norm_norm_LayerNormalization, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_norm_Transpose_1_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_norm_Transpose_1_output_0_ncf */
  uint32_t dimensions__text_encoder_convnext_convnext_5_norm_Transpose_1_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_5_norm_Transpose_1_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_5_norm_Transpose_1_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_norm_Transpose_1_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_norm_Transpose_1_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_norm_Transpose_1_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_norm_Transpose_1_output_0_ncf[] = {
    "_text_encoder_convnext_convnext_5_norm_Transpose_1_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_norm_Transpose_1_output_0_ncf[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_norm_Transpose_1_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_norm_Transpose_1_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0157615635544062f, .offset= -111}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_norm_Transpose_1_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_norm_Transpose_1_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_norm_Transpose_1_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_norm_Transpose_1_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_norm_Transpose_1_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d[] = {
    "_text_encoder_convnext_convnext_5_norm_Transpose_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0157615635544062f, .offset= -111}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0157615635544062f, .offset= -111}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_5_pwconv1_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_5_pwconv1_weight[] = {1, 1, 256, 1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_5_pwconv1_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_5_pwconv1_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0149165717884898f, .offset= -129}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_5_pwconv1_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_5_pwconv1_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_5_pwconv1_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_5_pwconv1_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_5_pwconv1_bias[] = {1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_5_pwconv1_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_5_pwconv1_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0025847905781120f, .offset= -223}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_5_pwconv1_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_5_pwconv1_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_5_pwconv1_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_pwconv1_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_pwconv1_Conv_2d */
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_convnext_convnext_5_pwconv1_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_convnext_convnext_5_pwconv1_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_convnext_convnext_5_pwconv1_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_5_pwconv1_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv1_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_pwconv1_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv1_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_pwconv1_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv1_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_pwconv1_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_pwconv1_Conv_2d[] = {
    "_text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_convnext_convnext_5_pwconv1_weight",
    "tts_ttl_text_encoder_convnext_convnext_5_pwconv1_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_pwconv1_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.2421733289957047f, .offset= -53}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_pwconv1_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_pwconv1_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_pwconv1_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_pwconv1_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate_nchw[] = {
    "_text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate_nchw[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.2421733289957047f, .offset= -53}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate */
  const char*  inputs__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate[] = {
    "_text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv1_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.2421733289957047f, .offset= -53}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv1_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__elementwiseneuron_14(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _elementwiseneuron_14 */
  Qnn_Param_t params__elementwiseneuron_14[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}}
  };
  const char*  inputs__elementwiseneuron_14[] = {
    "_text_encoder_convnext_convnext_5_pwconv1_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_act_Mul_1_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__elementwiseneuron_14[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_act_Mul_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1928729563951492f, .offset= -1}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_act_Mul_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_elementwiseneuron_14", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseNeuron", // Qnn Node Type
                         params__elementwiseneuron_14, // Node Params
                         1, // Num Node Params
                         inputs__elementwiseneuron_14, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__elementwiseneuron_14, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d[] = {
    "_text_encoder_convnext_convnext_5_act_Mul_1_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1928729563951492f, .offset= -1}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1928729563951492f, .offset= -1}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_5_pwconv2_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_5_pwconv2_weight[] = {1, 1, 1024, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_5_pwconv2_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_5_pwconv2_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0079797161743045f, .offset= -120}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_5_pwconv2_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_5_pwconv2_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_5_pwconv2_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_5_pwconv2_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_5_pwconv2_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_5_pwconv2_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_5_pwconv2_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0016541060758755f, .offset= -145}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_5_pwconv2_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_5_pwconv2_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_5_pwconv2_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_pwconv2_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_pwconv2_Conv_2d */
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_convnext_convnext_5_pwconv2_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_convnext_convnext_5_pwconv2_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_convnext_convnext_5_pwconv2_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_5_pwconv2_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv2_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_pwconv2_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv2_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_pwconv2_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv2_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_pwconv2_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_pwconv2_Conv_2d[] = {
    "_text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_convnext_convnext_5_pwconv2_weight",
    "tts_ttl_text_encoder_convnext_convnext_5_pwconv2_bias"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_pwconv2_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 2.4838392734527588f, .offset= -105}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_pwconv2_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_pwconv2_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_pwconv2_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_pwconv2_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate_nchw[] = {
    "_text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 2.4838392734527588f, .offset= -105}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate */
  const char*  inputs__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate[] = {
    "_text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv2_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 2.4838392734527588f, .offset= -105}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_pwconv2_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_pwconv2_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_convnext_convnext_5_pwconv2_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_convnext_convnext_5_pwconv2_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv2_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_convnext_convnext_5_pwconv2_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_pwconv2_Conv_output_0_nfc[] = {
    "_text_encoder_convnext_convnext_5_pwconv2_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_pwconv2_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_pwconv2_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 2.4838392734527588f, .offset= -105}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_pwconv2_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_pwconv2_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_pwconv2_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_pwconv2_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_pwconv2_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_convnext_convnext_5_gamma(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_convnext_convnext_5_gamma[] = {1, 1, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_convnext_convnext_5_gamma", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_convnext_convnext_5_gamma",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0026447337586433f, .offset= 0}}},
                                 .rank= 3,
                                 .dimensions=dimensions_tts_ttl_text_encoder_convnext_convnext_5_gamma,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_convnext_convnext_5_gamma),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_convnext_convnext_5_gamma)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_Mul_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_Mul_2 */
  Qnn_Param_t params__text_encoder_convnext_convnext_5_Mul_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_Mul_2[] = {
    "tts_ttl_text_encoder_convnext_convnext_5_gamma",
    "_text_encoder_convnext_convnext_5_pwconv2_Conv_output_0_nfc"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_Mul_2_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_Mul_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_Mul_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.4839824438095093f, .offset= -85}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_Mul_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_Mul_2", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_Mul_2, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_Mul_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_Mul_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_Add(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_Add */
  Qnn_Param_t params__text_encoder_convnext_convnext_5_Add[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_Add[] = {
    "_text_encoder_convnext_convnext_5_Mul_output_0",
    "_text_encoder_convnext_convnext_5_Mul_2_output_0"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_Add_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_Add[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_Add_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.4885945320129395f, .offset= -85}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_Add_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_Add", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_Add, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_Add, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_Add, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_convnext_convnext_5_Mul_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_convnext_convnext_5_Mul_3 */
  Qnn_Param_t params__text_encoder_convnext_convnext_5_Mul_3[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_convnext_convnext_5_Mul_3[] = {
    "_text_encoder_convnext_convnext_5_Add_output_0",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_convnext_convnext_5_Mul_3_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_convnext_convnext_5_Mul_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_convnext_convnext_5_Mul_3_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.4885945320129395f, .offset= -85}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_convnext_convnext_5_Mul_3_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_convnext_convnext_5_Mul_3", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_convnext_convnext_5_Mul_3, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_convnext_convnext_5_Mul_3, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_convnext_convnext_5_Mul_3, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_Mul_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_Mul_1 */
  Qnn_Param_t params__text_encoder_attn_encoder_Mul_1[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_Mul_1[] = {
    "_text_encoder_convnext_convnext_5_Mul_3_output_0",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_attn_encoder_Mul_1_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_Mul_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_Mul_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.4885945320129395f, .offset= -85}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_Mul_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_Mul_1", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_Mul_1, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_Mul_1, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_Mul_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_Mul_1_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_Mul_1_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_Mul_1_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_Mul_1_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_Mul_1_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_Mul_1_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_Mul_1_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_Mul_1_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_Mul_1_output_0_ncf[] = {
    "_text_encoder_attn_encoder_Mul_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_Mul_1_output_0_ncf[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_Mul_1_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_Mul_1_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.4885945320129395f, .offset= -85}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_Mul_1_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_Mul_1_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_Mul_1_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_Mul_1_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_Mul_1_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_Mul_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.4885945320129395f, .offset= -85}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.4885945320129395f, .offset= -85}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_q_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_q_weight[] = {1, 1, 256, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_q_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_q_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0037896966096014f, .offset= -142}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_q_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_q_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_q_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_q_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_q_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_q_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_q_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0063734771683812f, .offset= -114}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_q_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_q_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_q_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d[] = {
    "_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_q_weight",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_q_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.6571501493453979f, .offset= -127}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.6571501493453979f, .offset= -127}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_output_0[] = {1, 4, 64, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Reshape_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.6571501493453979f, .offset= -127}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_Mul_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.4885945320129395f, .offset= -85}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.4885945320129395f, .offset= -85}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_k_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_k_weight[] = {1, 1, 256, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_k_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_k_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0040110773406923f, .offset= -136}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_k_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_k_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_k_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_k_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_k_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_k_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_k_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0001722603337839f, .offset= -130}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_k_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_k_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_k_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d[] = {
    "_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_k_weight",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_k_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.4845225811004639f, .offset= -124}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.4845225811004639f, .offset= -124}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_1_output_0[] = {1, 4, 64, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Reshape_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.4845225811004639f, .offset= -124}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_Mul_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.4885945320129395f, .offset= -85}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.4885945320129395f, .offset= -85}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_v_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_v_weight[] = {1, 1, 256, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_v_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_v_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0032119075767696f, .offset= -126}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_v_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_v_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_v_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_v_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_v_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_v_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_v_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0004737195558846f, .offset= -113}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_v_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_v_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_v_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d[] = {
    "_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_v_weight",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_v_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1023301258683205f, .offset= -131}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1023301258683205f, .offset= -131}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_2_output_0[] = {1, 4, 64, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Reshape_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1023301258683205f, .offset= -131}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Transpose(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Transpose */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Transpose_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_Transpose_perm[] = {0, 1, 3, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Transpose[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Transpose_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Transpose_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_Transpose_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Transpose[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Reshape_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Transpose_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Transpose[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.6571501493453979f, .offset= -127}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Transpose", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Transpose, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Transpose, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Transpose, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Transpose_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Transpose_1 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Transpose_1_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_Transpose_1_perm[] = {0, 1, 3, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Transpose_1[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Transpose_1_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Transpose_1_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_Transpose_1_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Transpose_1[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Reshape_2_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Transpose_1_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Transpose_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Transpose_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1023301258683205f, .offset= -131}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Transpose_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Transpose_1", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Transpose_1, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Transpose_1, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Transpose_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor__text_encoder_attn_encoder_attn_layers_0_Constant_10_output_0(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Constant_10_output_0[] = {1};
  VALIDATE(model.addTensor("_text_encoder_attn_encoder_attn_layers_0_Constant_10_output_0", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "_text_encoder_attn_encoder_attn_layers_0_Constant_10_output_0",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0313725508749485f, .offset= 0}}},
                                 .rank= 1,
                                 .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Constant_10_output_0,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(_text_encoder_attn_encoder_attn_layers_0_Constant_10_output_0),
                                                .dataSize=BINLEN(_text_encoder_attn_encoder_attn_layers_0_Constant_10_output_0)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Div(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Div */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Div[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 2}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Div[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Transpose_output_0",
    "_text_encoder_attn_encoder_attn_layers_0_Constant_10_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Div_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Div[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Div_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0821437686681747f, .offset= -127}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Div_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Div", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Div, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Div, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Div, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_MatMul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_MatMul */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_MatMul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_MatMul[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Div_output_0",
    "_text_encoder_attn_encoder_attn_layers_0_Reshape_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_MatMul_output_0[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_MatMul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_MatMul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 29.6471920013427734f, .offset= -248}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_MatMul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_MatMul", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_MatMul, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_MatMul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_MatMul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor__text_encoder_attn_encoder_attn_layers_0_Transpose_3_output_0_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Transpose_3_output_0_nchw[] = {1, 1, 64, 255};
  VALIDATE(model.addTensor("_text_encoder_attn_encoder_attn_layers_0_Transpose_3_output_0_nchw", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "_text_encoder_attn_encoder_attn_layers_0_Transpose_3_output_0_nchw",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0105202281847596f, .offset= -120}}},
                                 .rank= 4,
                                 .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Transpose_3_output_0_nchw,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(_text_encoder_attn_encoder_attn_layers_0_Transpose_3_output_0_nchw),
                                                .dataSize=BINLEN(_text_encoder_attn_encoder_attn_layers_0_Transpose_3_output_0_nchw)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_MatMul_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_MatMul_1 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_MatMul_1[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_MatMul_1[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Div_output_0",
    "_text_encoder_attn_encoder_attn_layers_0_Transpose_3_output_0_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0[] = {1, 4, 128, 255};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_MatMul_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1942665427923203f, .offset= -154}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_MatMul_1", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_MatMul_1, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_MatMul_1, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_MatMul_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0_nhwc[] = {1, 128, 255, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1942665427923203f, .offset= -154}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Pad_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Pad_1 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_1_pad_amount[] = {4, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_Pad_1_pad_amount[] = {0, 0, 0, 0, 0, 1, 0, 0};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Pad_1[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Pad_1_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_1_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_Pad_1_pad_amount,
                           .dataSize=32}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="pad_constant_value",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000000000000f}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Pad_1[] = {
    "_text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0_nhwc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0[] = {1, 128, 256, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Pad_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1942665427923203f, .offset= -154}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Pad_1", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Pad_1, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Pad_1, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Pad_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0_nchw[] = {1, 4, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1942665427923203f, .offset= -154}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Reshape_7(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Reshape_7 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Reshape_7[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0[] = {1, 4, 32768};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Reshape_7[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1942665427923203f, .offset= -154}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Reshape_7", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Reshape_7, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Reshape_7, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0_nfc[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0_nfc[] = {1, 32768, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1942665427923203f, .offset= -154}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Pad_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Pad_2 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_2_pad_amount[] = {3, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_Pad_2_pad_amount[] = {0, 0, 0, 127, 0, 0};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Pad_2[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Pad_2_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_2_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_Pad_2_pad_amount,
                           .dataSize=24}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="pad_constant_value",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000000000000f}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Pad_2[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0_nfc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0[] = {1, 32895, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Pad_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1942665427923203f, .offset= -154}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Pad_2", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Pad_2, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Pad_2, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Pad_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0_ncf[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0_ncf[] = {1, 4, 32895};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1942665427923203f, .offset= -154}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Reshape_10(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Reshape_10 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Reshape_10[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_10_output_0[] = {1, 4, 129, 255};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Reshape_10[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Reshape_10_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1942665427923203f, .offset= -154}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_10_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Reshape_10", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Reshape_10, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Reshape_10, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode_Slice_0(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR Slice_0 */
  uint32_t dimensions_Slice_0_ranges[] = {4, 3};
  int32_t Slice_0_ranges[] = {0, 1, 1, 0, 4, 1, 0, 128, 1, 127, 255, 1};
  Qnn_Param_t params_Slice_0[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="ranges",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "Slice_0_ranges",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_INT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions_Slice_0_ranges,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)Slice_0_ranges,
                           .dataSize=48}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="begin_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="end_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="new_axes_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="shrink_axes",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs_Slice_0[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Reshape_10_output_0"
  };
  uint32_t dimensions__v_890[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs_Slice_0[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_v_890",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1942665427923203f, .offset= -154}}},
            .rank= 4,
            .dimensions=dimensions__v_890,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "Slice_0", // Node Name
                         "qti.aisw", // Package Name
                         "StridedSlice", // Qnn Node Type
                         params_Slice_0, // Node Params
                         5, // Num Node Params
                         inputs_Slice_0, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs_Slice_0, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Add_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Add_2 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Add_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Add_2[] = {
    "_text_encoder_attn_encoder_attn_layers_0_MatMul_output_0",
    "_v_890"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Add_2_output_0[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Add_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Add_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 29.6172027587890625f, .offset= -248}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Add_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Add_2", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Add_2, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Add_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Add_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor__text_encoder_attn_encoder_attn_layers_0_Constant_88_output_0(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Constant_88_output_0[] = {1};
  VALIDATE(model.addTensor("_text_encoder_attn_encoder_attn_layers_0_Constant_88_output_0", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "_text_encoder_attn_encoder_attn_layers_0_Constant_88_output_0",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 39.2156867980957031f, .offset= -255}}},
                                 .rank= 1,
                                 .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Constant_88_output_0,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(_text_encoder_attn_encoder_attn_layers_0_Constant_88_output_0),
                                                .dataSize=BINLEN(_text_encoder_attn_encoder_attn_layers_0_Constant_88_output_0)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Where(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Where */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Where[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Cast_5_output_0",
    "_text_encoder_attn_encoder_attn_layers_0_Constant_88_output_0",
    "_text_encoder_attn_encoder_attn_layers_0_Add_2_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Where_output_0[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Where[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Where_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 40.0662994384765625f, .offset= -250}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Where_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Where", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseSelect", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Where, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Where, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Softmax(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Softmax */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Softmax[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="axis",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 3}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="beta",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 1.000000000000f}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Softmax[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Where_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Softmax_output_0[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Softmax[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Softmax_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Softmax_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Softmax", // Node Name
                         "qti.aisw", // Package Name
                         "Softmax", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Softmax, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Softmax, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Softmax, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Softmax_output_0_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Softmax_output_0_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Softmax_output_0_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_Softmax_output_0_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Softmax_output_0_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Softmax_output_0_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Softmax_output_0_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_Softmax_output_0_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Softmax_output_0_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Softmax_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Softmax_output_0_nhwc[] = {1, 128, 128, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Softmax_output_0_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Softmax_output_0_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Softmax_output_0_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Softmax_output_0_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Softmax_output_0_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Softmax_output_0_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Softmax_output_0_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_MatMul_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_MatMul_2 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_MatMul_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_MatMul_2[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Softmax_output_0",
    "_text_encoder_attn_encoder_attn_layers_0_Transpose_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_MatMul_2_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_MatMul_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_MatMul_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0352233462035656f, .offset= -165}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_MatMul_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_MatMul_2", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_MatMul_2, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_MatMul_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_MatMul_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Pad_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Pad_3 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_3_pad_amount[] = {4, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_Pad_3_pad_amount[] = {0, 0, 0, 0, 0, 127, 0, 0};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Pad_3[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Pad_3_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_3_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_Pad_3_pad_amount,
                           .dataSize=32}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="pad_constant_value",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000000000000f}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Pad_3[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Softmax_output_0_nhwc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0[] = {1, 128, 255, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Pad_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Pad_3", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Pad_3, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Pad_3, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Pad_3, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0_nchw[] = {1, 4, 128, 255};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Reshape_13(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Reshape_13 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Reshape_13[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0[] = {1, 4, 32640};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Reshape_13[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Reshape_13", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Reshape_13, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Reshape_13, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0_nfc[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0_nfc[] = {1, 32640, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Pad_4(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Pad_4 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_4_pad_amount[] = {3, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_Pad_4_pad_amount[] = {0, 0, 128, 0, 0, 0};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Pad_4[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Pad_4_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_4_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_Pad_4_pad_amount,
                           .dataSize=24}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="pad_constant_value",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000000000000f}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Pad_4[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0_nfc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0[] = {1, 32768, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Pad_4[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Pad_4", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Pad_4, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Pad_4, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Pad_4, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0_ncf[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0_ncf[] = {1, 4, 32768};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Reshape_16(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Reshape_16 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Reshape_16[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_16_output_0[] = {1, 4, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Reshape_16[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Reshape_16_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Reshape_16_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Reshape_16", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Reshape_16, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Reshape_16, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Slice_8(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Slice_8 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Slice_8_ranges[] = {4, 3};
  int32_t _text_encoder_attn_encoder_attn_layers_0_Slice_8_ranges[] = {0, 1, 1, 0, 4, 1, 0, 128, 1, 1, 256, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Slice_8[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="ranges",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Slice_8_ranges",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_INT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Slice_8_ranges,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_Slice_8_ranges,
                           .dataSize=48}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="begin_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="end_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="new_axes_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="shrink_axes",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Slice_8[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Reshape_16_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Slice_8_output_0[] = {1, 4, 128, 255};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Slice_8[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Slice_8_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Slice_8_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Slice_8", // Node Name
                         "qti.aisw", // Package Name
                         "StridedSlice", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Slice_8, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Slice_8, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Slice_8, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor__text_encoder_attn_encoder_attn_layers_0_Unsqueeze_41_output_0_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Unsqueeze_41_output_0_nchw[] = {1, 1, 255, 64};
  VALIDATE(model.addTensor("_text_encoder_attn_encoder_attn_layers_0_Unsqueeze_41_output_0_nchw", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "_text_encoder_attn_encoder_attn_layers_0_Unsqueeze_41_output_0_nchw",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0051373876631260f, .offset= -122}}},
                                 .rank= 4,
                                 .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Unsqueeze_41_output_0_nchw,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(_text_encoder_attn_encoder_attn_layers_0_Unsqueeze_41_output_0_nchw),
                                                .dataSize=BINLEN(_text_encoder_attn_encoder_attn_layers_0_Unsqueeze_41_output_0_nchw)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_MatMul_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_MatMul_3 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_MatMul_3[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_MatMul_3[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Slice_8_output_0",
    "_text_encoder_attn_encoder_attn_layers_0_Unsqueeze_41_output_0_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_MatMul_3_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_MatMul_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_MatMul_3_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0043315226212144f, .offset= -136}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_MatMul_3_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_MatMul_3", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_MatMul_3, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_MatMul_3, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_MatMul_3, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Add_4(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Add_4 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Add_4[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Add_4[] = {
    "_text_encoder_attn_encoder_attn_layers_0_MatMul_2_output_0",
    "_text_encoder_attn_encoder_attn_layers_0_MatMul_3_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Add_4_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Add_4[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Add_4_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0368753671646118f, .offset= -158}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Add_4_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Add_4", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Add_4, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Add_4, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Add_4, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Transpose_9(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Transpose_9 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Transpose_9_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_Transpose_9_perm[] = {0, 1, 3, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_Transpose_9[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Transpose_9_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Transpose_9_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_Transpose_9_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Transpose_9[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Add_4_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_Transpose_9_output_0[] = {1, 4, 64, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Transpose_9[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_Transpose_9_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0368753671646118f, .offset= -158}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_Transpose_9_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Transpose_9", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_Transpose_9, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Transpose_9, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Transpose_9, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_Reshape_19(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_Reshape_19 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_Reshape_19[] = {
    "_text_encoder_attn_encoder_attn_layers_0_Transpose_9_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_Reshape_19[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0368753671646118f, .offset= -158}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_Reshape_19", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_Reshape_19, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_Reshape_19, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0368753671646118f, .offset= -158}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_o_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_o_weight[] = {1, 1, 256, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_o_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_o_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0030498073901981f, .offset= -125}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_o_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_o_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_o_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_o_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_o_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_o_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_o_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0024935114197433f, .offset= -144}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_o_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_o_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_o_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d[] = {
    "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_o_weight",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_o_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0327426157891750f, .offset= -107}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0327426157891750f, .offset= -107}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0327426157891750f, .offset= -107}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0_nfc[] = {
    "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0327426157891750f, .offset= -107}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_Add(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_Add */
  Qnn_Param_t params__text_encoder_attn_encoder_Add[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_Add[] = {
    "_text_encoder_attn_encoder_Mul_1_output_0",
    "_text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0_nfc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_1_0_Transpose_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_Add[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_1_0_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.4914520978927612f, .offset= -85}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_1_0_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_Add", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_Add, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_Add, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_Add, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_1_0_norm_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_1_0_norm_weight[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_norm_layers_1_0_norm_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_norm_layers_1_0_norm_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0027162004262209f, .offset= 0}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_1_0_norm_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_norm_layers_1_0_norm_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_norm_layers_1_0_norm_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_1_0_norm_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_1_0_norm_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_norm_layers_1_0_norm_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_norm_layers_1_0_norm_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0020035363268107f, .offset= -157}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_1_0_norm_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_norm_layers_1_0_norm_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_norm_layers_1_0_norm_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_norm_layers_1_0_norm_LayerNormalization(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_norm_layers_1_0_norm_LayerNormalization */
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_1_0_norm_LayerNormalization_axes[] = {1};
  uint32_t _text_encoder_attn_encoder_norm_layers_1_0_norm_LayerNormalization_axes[] = {2};
  Qnn_Param_t params__text_encoder_attn_encoder_norm_layers_1_0_norm_LayerNormalization[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="axes",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_1_0_norm_LayerNormalization_axes",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_1_0_norm_LayerNormalization_axes,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_norm_layers_1_0_norm_LayerNormalization_axes,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="epsilon",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000001000000f}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_norm_layers_1_0_norm_LayerNormalization[] = {
    "_text_encoder_attn_encoder_norm_layers_1_0_Transpose_output_0",
    "tts_ttl_text_encoder_attn_encoder_norm_layers_1_0_norm_weight",
    "tts_ttl_text_encoder_attn_encoder_norm_layers_1_0_norm_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_1_0_Transpose_1_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_norm_layers_1_0_norm_LayerNormalization[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_1_0_Transpose_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0346683412790298f, .offset= -95}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_1_0_Transpose_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_norm_layers_1_0_norm_LayerNormalization", // Node Name
                         "qti.aisw", // Package Name
                         "LayerNorm", // Qnn Node Type
                         params__text_encoder_attn_encoder_norm_layers_1_0_norm_LayerNormalization, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_norm_layers_1_0_norm_LayerNormalization, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_norm_layers_1_0_norm_LayerNormalization, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_0_Mul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_0_Mul */
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_0_Mul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_0_Mul[] = {
    "_text_encoder_attn_encoder_norm_layers_1_0_Transpose_1_output_0",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_Mul_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_0_Mul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_Mul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0346683412790298f, .offset= -95}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_Mul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_0_Mul", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_0_Mul, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_0_Mul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_0_Mul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_0_Mul_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_0_Mul_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_Mul_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_ffn_layers_0_Mul_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_0_Mul_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_Mul_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_Mul_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_0_Mul_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_0_Mul_output_0_ncf[] = {
    "_text_encoder_attn_encoder_ffn_layers_0_Mul_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_Mul_output_0_ncf[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_0_Mul_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_Mul_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0346683412790298f, .offset= -95}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_Mul_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_0_Mul_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_0_Mul_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_0_Mul_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_0_Mul_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_ffn_layers_0_Mul_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0346683412790298f, .offset= -95}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0346683412790298f, .offset= -95}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_1_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_1_weight[] = {1, 1, 256, 1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_1_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_1_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0042936527170241f, .offset= -134}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_1_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_1_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_1_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_1_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_1_bias[] = {1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_1_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_1_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0009362160344608f, .offset= -212}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_1_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_1_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_1_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d[] = {
    "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_1_weight",
    "tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_1_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0208301581442356f, .offset= -173}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate_nchw[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0208301581442356f, .offset= -173}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0208301581442356f, .offset= -173}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_0_Relu(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_0_Relu */
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_0_Relu[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 4}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_0_Relu[] = {
    "_text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_Relu_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_0_Relu[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_Relu_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0067204432561994f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_Relu_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_0_Relu", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseNeuron", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_0_Relu, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_0_Relu, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_0_Relu, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_0_Relu_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_0_Relu_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_Relu_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_ffn_layers_0_Relu_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_0_Relu_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_Relu_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_Relu_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_0_Relu_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_0_Relu_output_0_nfc[] = {
    "_text_encoder_attn_encoder_ffn_layers_0_Relu_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_Relu_output_0_nfc[] = {1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_0_Relu_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_Relu_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0067204432561994f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_Relu_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_0_Relu_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_0_Relu_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_0_Relu_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_0_Relu_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_0_Mul_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_0_Mul_1 */
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_0_Mul_1[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_0_Mul_1[] = {
    "_text_encoder_attn_encoder_ffn_layers_0_Relu_output_0_nfc",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0[] = {1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_0_Mul_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0067204432561994f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_0_Mul_1", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_0_Mul_1, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_0_Mul_1, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_0_Mul_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0_ncf[] = {
    "_text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0_ncf[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0067204432561994f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0067204432561994f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0067204432561994f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_2_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_2_weight[] = {1, 1, 1024, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_2_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_2_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0051403907127678f, .offset= -121}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_2_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_2_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_2_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_2_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_2_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_2_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_2_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0010891674319282f, .offset= -136}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_2_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_2_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_2_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d[] = {
    "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_2_weight",
    "tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_2_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0275221839547157f, .offset= -126}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0275221839547157f, .offset= -126}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0275221839547157f, .offset= -126}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0_nfc[] = {
    "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0275221839547157f, .offset= -126}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_0_Mul_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_0_Mul_2 */
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_0_Mul_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_0_Mul_2[] = {
    "_text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0_nfc",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_0_Mul_2_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_0_Mul_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_0_Mul_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0275221839547157f, .offset= -126}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_0_Mul_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_0_Mul_2", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_0_Mul_2, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_0_Mul_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_0_Mul_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_Add_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_Add_1 */
  Qnn_Param_t params__text_encoder_attn_encoder_Add_1[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_Add_1[] = {
    "_text_encoder_attn_encoder_norm_layers_1_0_Transpose_1_output_0",
    "_text_encoder_attn_encoder_ffn_layers_0_Mul_2_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_2_0_Transpose_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_Add_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_2_0_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0474918857216835f, .offset= -128}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_2_0_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_Add_1", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_Add_1, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_Add_1, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_Add_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_2_0_norm_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_2_0_norm_weight[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_norm_layers_2_0_norm_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_norm_layers_2_0_norm_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0018965101335198f, .offset= 0}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_2_0_norm_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_norm_layers_2_0_norm_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_norm_layers_2_0_norm_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_2_0_norm_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_2_0_norm_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_norm_layers_2_0_norm_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_norm_layers_2_0_norm_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0011463570408523f, .offset= -145}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_2_0_norm_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_norm_layers_2_0_norm_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_norm_layers_2_0_norm_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_norm_layers_2_0_norm_LayerNormalization(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_norm_layers_2_0_norm_LayerNormalization */
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_2_0_norm_LayerNormalization_axes[] = {1};
  uint32_t _text_encoder_attn_encoder_norm_layers_2_0_norm_LayerNormalization_axes[] = {2};
  Qnn_Param_t params__text_encoder_attn_encoder_norm_layers_2_0_norm_LayerNormalization[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="axes",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_2_0_norm_LayerNormalization_axes",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_2_0_norm_LayerNormalization_axes,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_norm_layers_2_0_norm_LayerNormalization_axes,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="epsilon",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000001000000f}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_norm_layers_2_0_norm_LayerNormalization[] = {
    "_text_encoder_attn_encoder_norm_layers_2_0_Transpose_output_0",
    "tts_ttl_text_encoder_attn_encoder_norm_layers_2_0_norm_weight",
    "tts_ttl_text_encoder_attn_encoder_norm_layers_2_0_norm_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_norm_layers_2_0_norm_LayerNormalization[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0161419492214918f, .offset= -109}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_norm_layers_2_0_norm_LayerNormalization", // Node Name
                         "qti.aisw", // Package Name
                         "LayerNorm", // Qnn Node Type
                         params__text_encoder_attn_encoder_norm_layers_2_0_norm_LayerNormalization, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_norm_layers_2_0_norm_LayerNormalization, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_norm_layers_2_0_norm_LayerNormalization, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf[] = {
    "_text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0161419492214918f, .offset= -109}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0161419492214918f, .offset= -109}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0161419492214918f, .offset= -109}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_q_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_q_weight[] = {1, 1, 256, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_q_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_q_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0064331237226725f, .offset= -144}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_q_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_q_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_q_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_q_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_q_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_q_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_q_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0054327971301973f, .offset= -149}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_q_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_q_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_q_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d[] = {
    "_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_q_weight",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_q_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0325384698808193f, .offset= -148}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0325384698808193f, .offset= -148}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_output_0[] = {1, 4, 64, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Reshape_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0325384698808193f, .offset= -148}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0161419492214918f, .offset= -109}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0161419492214918f, .offset= -109}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_k_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_k_weight[] = {1, 1, 256, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_k_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_k_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0066999117843807f, .offset= -127}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_k_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_k_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_k_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_k_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_k_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_k_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_k_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0001779289741535f, .offset= -128}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_k_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_k_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_k_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d[] = {
    "_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_k_weight",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_k_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0253899227827787f, .offset= -142}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0253899227827787f, .offset= -142}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_1_output_0[] = {1, 4, 64, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Reshape_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0253899227827787f, .offset= -142}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0161419492214918f, .offset= -109}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0161419492214918f, .offset= -109}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_v_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_v_weight[] = {1, 1, 256, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_v_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_v_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0030791494064033f, .offset= -120}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_v_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_v_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_v_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_v_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_v_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_v_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_v_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0003327641461510f, .offset= -126}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_v_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_v_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_v_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d[] = {
    "_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_v_weight",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_v_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0161571167409420f, .offset= -141}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0161571167409420f, .offset= -141}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_2_output_0[] = {1, 4, 64, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Reshape_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0161571167409420f, .offset= -141}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Transpose(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Transpose */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Transpose_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_Transpose_perm[] = {0, 1, 3, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_Transpose[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Transpose_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Transpose_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_Transpose_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Transpose[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Reshape_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Transpose_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Transpose[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0325384698808193f, .offset= -148}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Transpose", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_Transpose, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Transpose, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Transpose, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Transpose_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Transpose_1 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Transpose_1_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_Transpose_1_perm[] = {0, 1, 3, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_Transpose_1[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Transpose_1_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Transpose_1_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_Transpose_1_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Transpose_1[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Reshape_2_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Transpose_1_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Transpose_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Transpose_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0161571167409420f, .offset= -141}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Transpose_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Transpose_1", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_Transpose_1, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Transpose_1, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Transpose_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Div(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Div */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_Div[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 2}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Div[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Transpose_output_0",
    "_text_encoder_attn_encoder_attn_layers_0_Constant_10_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Div_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Div[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Div_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0040673087351024f, .offset= -148}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Div_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Div", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_Div, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Div, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Div, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_MatMul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_MatMul */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_MatMul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_MatMul[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Div_output_0",
    "_text_encoder_attn_encoder_attn_layers_1_Reshape_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_MatMul_output_0[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_MatMul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_MatMul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1000187993049622f, .offset= -88}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_MatMul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_MatMul", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_MatMul, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_MatMul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_MatMul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor__text_encoder_attn_encoder_attn_layers_1_Transpose_3_output_0_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Transpose_3_output_0_nchw[] = {1, 1, 64, 255};
  VALIDATE(model.addTensor("_text_encoder_attn_encoder_attn_layers_1_Transpose_3_output_0_nchw", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "_text_encoder_attn_encoder_attn_layers_1_Transpose_3_output_0_nchw",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0192992202937603f, .offset= -120}}},
                                 .rank= 4,
                                 .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Transpose_3_output_0_nchw,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(_text_encoder_attn_encoder_attn_layers_1_Transpose_3_output_0_nchw),
                                                .dataSize=BINLEN(_text_encoder_attn_encoder_attn_layers_1_Transpose_3_output_0_nchw)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_MatMul_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_MatMul_1 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_MatMul_1[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_MatMul_1[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Div_output_0",
    "_text_encoder_attn_encoder_attn_layers_1_Transpose_3_output_0_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0[] = {1, 4, 128, 255};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_MatMul_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0398247092962265f, .offset= -125}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_MatMul_1", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_MatMul_1, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_MatMul_1, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_MatMul_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0_nhwc[] = {1, 128, 255, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0398247092962265f, .offset= -125}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Pad_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Pad_1 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_1_pad_amount[] = {4, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_Pad_1_pad_amount[] = {0, 0, 0, 0, 0, 1, 0, 0};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_Pad_1[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Pad_1_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_1_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_Pad_1_pad_amount,
                           .dataSize=32}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="pad_constant_value",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000000000000f}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Pad_1[] = {
    "_text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0_nhwc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0[] = {1, 128, 256, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Pad_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0398247092962265f, .offset= -125}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Pad_1", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_Pad_1, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Pad_1, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Pad_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0_nchw[] = {1, 4, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0398247092962265f, .offset= -125}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Reshape_7(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Reshape_7 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Reshape_7[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0[] = {1, 4, 32768};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Reshape_7[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0398247092962265f, .offset= -125}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Reshape_7", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Reshape_7, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Reshape_7, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0_nfc[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0_nfc[] = {1, 32768, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0398247092962265f, .offset= -125}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Pad_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Pad_2 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_2_pad_amount[] = {3, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_Pad_2_pad_amount[] = {0, 0, 0, 127, 0, 0};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_Pad_2[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Pad_2_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_2_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_Pad_2_pad_amount,
                           .dataSize=24}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="pad_constant_value",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000000000000f}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Pad_2[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0_nfc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0[] = {1, 32895, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Pad_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0398247092962265f, .offset= -125}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Pad_2", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_Pad_2, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Pad_2, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Pad_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0_ncf[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0_ncf[] = {1, 4, 32895};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0398247092962265f, .offset= -125}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Reshape_10(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Reshape_10 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Reshape_10[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_10_output_0[] = {1, 4, 129, 255};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Reshape_10[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Reshape_10_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0398247092962265f, .offset= -125}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_10_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Reshape_10", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Reshape_10, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Reshape_10, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode_Slice_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR Slice_1 */
  uint32_t dimensions_Slice_1_ranges[] = {4, 3};
  int32_t Slice_1_ranges[] = {0, 1, 1, 0, 4, 1, 0, 128, 1, 127, 255, 1};
  Qnn_Param_t params_Slice_1[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="ranges",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "Slice_1_ranges",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_INT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions_Slice_1_ranges,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)Slice_1_ranges,
                           .dataSize=48}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="begin_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="end_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="new_axes_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="shrink_axes",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs_Slice_1[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Reshape_10_output_0"
  };
  uint32_t dimensions__v_895[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs_Slice_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_v_895",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0398247092962265f, .offset= -125}}},
            .rank= 4,
            .dimensions=dimensions__v_895,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "Slice_1", // Node Name
                         "qti.aisw", // Package Name
                         "StridedSlice", // Qnn Node Type
                         params_Slice_1, // Node Params
                         5, // Num Node Params
                         inputs_Slice_1, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs_Slice_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Add_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Add_2 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_Add_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Add_2[] = {
    "_text_encoder_attn_encoder_attn_layers_1_MatMul_output_0",
    "_v_895"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Add_2_output_0[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Add_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Add_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.1103713437914848f, .offset= -80}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Add_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Add_2", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_Add_2, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Add_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Add_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Where(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Where */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Where[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Cast_5_output_0",
    "_text_encoder_attn_encoder_attn_layers_0_Constant_88_output_0",
    "_text_encoder_attn_encoder_attn_layers_1_Add_2_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Where_output_0[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Where[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Where_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 39.2914543151855469f, .offset= -255}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Where_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Where", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseSelect", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Where, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Where, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Softmax(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Softmax */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_Softmax[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="axis",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 3}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="beta",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 1.000000000000f}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Softmax[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Where_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Softmax_output_0[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Softmax[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Softmax_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Softmax_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Softmax", // Node Name
                         "qti.aisw", // Package Name
                         "Softmax", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_Softmax, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Softmax, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Softmax, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Softmax_output_0_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Softmax_output_0_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Softmax_output_0_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_Softmax_output_0_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_Softmax_output_0_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Softmax_output_0_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Softmax_output_0_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_Softmax_output_0_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Softmax_output_0_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Softmax_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Softmax_output_0_nhwc[] = {1, 128, 128, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Softmax_output_0_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Softmax_output_0_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Softmax_output_0_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Softmax_output_0_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_Softmax_output_0_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Softmax_output_0_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Softmax_output_0_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_MatMul_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_MatMul_2 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_MatMul_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_MatMul_2[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Softmax_output_0",
    "_text_encoder_attn_encoder_attn_layers_1_Transpose_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_MatMul_2_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_MatMul_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_MatMul_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0106335561722517f, .offset= -147}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_MatMul_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_MatMul_2", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_MatMul_2, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_MatMul_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_MatMul_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Pad_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Pad_3 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_3_pad_amount[] = {4, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_Pad_3_pad_amount[] = {0, 0, 0, 0, 0, 127, 0, 0};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_Pad_3[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Pad_3_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_3_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_Pad_3_pad_amount,
                           .dataSize=32}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="pad_constant_value",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000000000000f}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Pad_3[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Softmax_output_0_nhwc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0[] = {1, 128, 255, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Pad_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Pad_3", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_Pad_3, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Pad_3, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Pad_3, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0_nchw[] = {1, 4, 128, 255};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Reshape_13(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Reshape_13 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Reshape_13[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0[] = {1, 4, 32640};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Reshape_13[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Reshape_13", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Reshape_13, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Reshape_13, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0_nfc[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0_nfc[] = {1, 32640, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Pad_4(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Pad_4 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_4_pad_amount[] = {3, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_Pad_4_pad_amount[] = {0, 0, 128, 0, 0, 0};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_Pad_4[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Pad_4_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_4_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_Pad_4_pad_amount,
                           .dataSize=24}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="pad_constant_value",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000000000000f}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Pad_4[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0_nfc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0[] = {1, 32768, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Pad_4[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Pad_4", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_Pad_4, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Pad_4, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Pad_4, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0_ncf[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0_ncf[] = {1, 4, 32768};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Reshape_16(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Reshape_16 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Reshape_16[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_16_output_0[] = {1, 4, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Reshape_16[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Reshape_16_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Reshape_16_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Reshape_16", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Reshape_16, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Reshape_16, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Slice_8(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Slice_8 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Slice_8_ranges[] = {4, 3};
  int32_t _text_encoder_attn_encoder_attn_layers_1_Slice_8_ranges[] = {0, 1, 1, 0, 4, 1, 0, 128, 1, 1, 256, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_Slice_8[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="ranges",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Slice_8_ranges",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_INT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Slice_8_ranges,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_Slice_8_ranges,
                           .dataSize=48}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="begin_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="end_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="new_axes_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="shrink_axes",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Slice_8[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Reshape_16_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Slice_8_output_0[] = {1, 4, 128, 255};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Slice_8[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Slice_8_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Slice_8_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Slice_8", // Node Name
                         "qti.aisw", // Package Name
                         "StridedSlice", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_Slice_8, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Slice_8, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Slice_8, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor__text_encoder_attn_encoder_attn_layers_1_Unsqueeze_41_output_0_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Unsqueeze_41_output_0_nchw[] = {1, 1, 255, 64};
  VALIDATE(model.addTensor("_text_encoder_attn_encoder_attn_layers_1_Unsqueeze_41_output_0_nchw", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "_text_encoder_attn_encoder_attn_layers_1_Unsqueeze_41_output_0_nchw",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0048790834844112f, .offset= -146}}},
                                 .rank= 4,
                                 .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Unsqueeze_41_output_0_nchw,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(_text_encoder_attn_encoder_attn_layers_1_Unsqueeze_41_output_0_nchw),
                                                .dataSize=BINLEN(_text_encoder_attn_encoder_attn_layers_1_Unsqueeze_41_output_0_nchw)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_MatMul_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_MatMul_3 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_MatMul_3[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_MatMul_3[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Slice_8_output_0",
    "_text_encoder_attn_encoder_attn_layers_1_Unsqueeze_41_output_0_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_MatMul_3_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_MatMul_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_MatMul_3_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0045992401428521f, .offset= -143}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_MatMul_3_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_MatMul_3", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_MatMul_3, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_MatMul_3, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_MatMul_3, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Add_4(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Add_4 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_Add_4[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Add_4[] = {
    "_text_encoder_attn_encoder_attn_layers_1_MatMul_2_output_0",
    "_text_encoder_attn_encoder_attn_layers_1_MatMul_3_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Add_4_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Add_4[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Add_4_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0112579036504030f, .offset= -152}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Add_4_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Add_4", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_Add_4, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Add_4, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Add_4, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Transpose_9(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Transpose_9 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Transpose_9_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_Transpose_9_perm[] = {0, 1, 3, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_Transpose_9[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Transpose_9_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Transpose_9_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_Transpose_9_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Transpose_9[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Add_4_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_Transpose_9_output_0[] = {1, 4, 64, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Transpose_9[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_Transpose_9_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0112579036504030f, .offset= -152}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_Transpose_9_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Transpose_9", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_Transpose_9, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Transpose_9, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Transpose_9, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_Reshape_19(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_Reshape_19 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_Reshape_19[] = {
    "_text_encoder_attn_encoder_attn_layers_1_Transpose_9_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_Reshape_19[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0112579036504030f, .offset= -152}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_Reshape_19", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_Reshape_19, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_Reshape_19, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0112579036504030f, .offset= -152}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_o_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_o_weight[] = {1, 1, 256, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_o_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_o_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0030178597662598f, .offset= -134}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_o_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_o_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_o_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_o_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_o_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_o_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_o_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0016316267428920f, .offset= -93}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_o_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_o_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_o_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d[] = {
    "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_o_weight",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_o_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0135417822748423f, .offset= -118}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0135417822748423f, .offset= -118}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0135417822748423f, .offset= -118}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0_nfc[] = {
    "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0135417822748423f, .offset= -118}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_Add_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_Add_2 */
  Qnn_Param_t params__text_encoder_attn_encoder_Add_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_Add_2[] = {
    "_text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0",
    "_text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0_nfc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_1_1_Transpose_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_Add_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_1_1_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0157100856304169f, .offset= -137}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_1_1_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_Add_2", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_Add_2, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_Add_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_Add_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_1_1_norm_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_1_1_norm_weight[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_norm_layers_1_1_norm_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_norm_layers_1_1_norm_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0027437740936875f, .offset= 0}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_1_1_norm_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_norm_layers_1_1_norm_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_norm_layers_1_1_norm_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_1_1_norm_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_1_1_norm_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_norm_layers_1_1_norm_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_norm_layers_1_1_norm_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0020493962801993f, .offset= -115}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_1_1_norm_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_norm_layers_1_1_norm_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_norm_layers_1_1_norm_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_norm_layers_1_1_norm_LayerNormalization(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_norm_layers_1_1_norm_LayerNormalization */
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_1_1_norm_LayerNormalization_axes[] = {1};
  uint32_t _text_encoder_attn_encoder_norm_layers_1_1_norm_LayerNormalization_axes[] = {2};
  Qnn_Param_t params__text_encoder_attn_encoder_norm_layers_1_1_norm_LayerNormalization[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="axes",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_1_1_norm_LayerNormalization_axes",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_1_1_norm_LayerNormalization_axes,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_norm_layers_1_1_norm_LayerNormalization_axes,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="epsilon",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000001000000f}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_norm_layers_1_1_norm_LayerNormalization[] = {
    "_text_encoder_attn_encoder_norm_layers_1_1_Transpose_output_0",
    "tts_ttl_text_encoder_attn_encoder_norm_layers_1_1_norm_weight",
    "tts_ttl_text_encoder_attn_encoder_norm_layers_1_1_norm_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_1_1_Transpose_1_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_norm_layers_1_1_norm_LayerNormalization[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_1_1_Transpose_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0160997323691845f, .offset= -95}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_1_1_Transpose_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_norm_layers_1_1_norm_LayerNormalization", // Node Name
                         "qti.aisw", // Package Name
                         "LayerNorm", // Qnn Node Type
                         params__text_encoder_attn_encoder_norm_layers_1_1_norm_LayerNormalization, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_norm_layers_1_1_norm_LayerNormalization, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_norm_layers_1_1_norm_LayerNormalization, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_1_Mul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_1_Mul */
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_1_Mul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_1_Mul[] = {
    "_text_encoder_attn_encoder_norm_layers_1_1_Transpose_1_output_0",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_Mul_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_1_Mul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_Mul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0160997323691845f, .offset= -95}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_Mul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_1_Mul", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_1_Mul, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_1_Mul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_1_Mul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_1_Mul_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_1_Mul_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_Mul_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_ffn_layers_1_Mul_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_1_Mul_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_Mul_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_Mul_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_1_Mul_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_1_Mul_output_0_ncf[] = {
    "_text_encoder_attn_encoder_ffn_layers_1_Mul_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_Mul_output_0_ncf[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_1_Mul_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_Mul_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0160997323691845f, .offset= -95}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_Mul_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_1_Mul_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_1_Mul_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_1_Mul_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_1_Mul_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_ffn_layers_1_Mul_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0160997323691845f, .offset= -95}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0160997323691845f, .offset= -95}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_1_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_1_weight[] = {1, 1, 256, 1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_1_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_1_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0042087011970580f, .offset= -130}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_1_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_1_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_1_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_1_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_1_bias[] = {1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_1_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_1_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0010519772768021f, .offset= -233}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_1_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_1_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_1_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d[] = {
    "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_1_weight",
    "tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_1_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0336605086922646f, .offset= -125}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate_nchw[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0336605086922646f, .offset= -125}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0336605086922646f, .offset= -125}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_1_Relu(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_1_Relu */
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_1_Relu[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 4}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_1_Relu[] = {
    "_text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_Relu_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_1_Relu[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_Relu_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0171024203300476f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_Relu_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_1_Relu", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseNeuron", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_1_Relu, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_1_Relu, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_1_Relu, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_1_Relu_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_1_Relu_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_Relu_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_ffn_layers_1_Relu_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_1_Relu_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_Relu_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_Relu_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_1_Relu_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_1_Relu_output_0_nfc[] = {
    "_text_encoder_attn_encoder_ffn_layers_1_Relu_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_Relu_output_0_nfc[] = {1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_1_Relu_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_Relu_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0171024203300476f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_Relu_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_1_Relu_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_1_Relu_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_1_Relu_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_1_Relu_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_1_Mul_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_1_Mul_1 */
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_1_Mul_1[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_1_Mul_1[] = {
    "_text_encoder_attn_encoder_ffn_layers_1_Relu_output_0_nfc",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0[] = {1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_1_Mul_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0171024203300476f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_1_Mul_1", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_1_Mul_1, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_1_Mul_1, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_1_Mul_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0_ncf[] = {
    "_text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0_ncf[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0171024203300476f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0171024203300476f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0171024203300476f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_2_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_2_weight[] = {1, 1, 1024, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_2_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_2_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0048660100437701f, .offset= -129}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_2_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_2_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_2_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_2_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_2_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_2_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_2_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0014377457555383f, .offset= -164}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_2_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_2_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_2_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d[] = {
    "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_2_weight",
    "tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_2_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0355979837477207f, .offset= -128}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0355979837477207f, .offset= -128}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0355979837477207f, .offset= -128}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0_nfc[] = {
    "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0355979837477207f, .offset= -128}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_1_Mul_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_1_Mul_2 */
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_1_Mul_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_1_Mul_2[] = {
    "_text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0_nfc",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_1_Mul_2_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_1_Mul_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_1_Mul_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0355979837477207f, .offset= -128}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_1_Mul_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_1_Mul_2", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_1_Mul_2, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_1_Mul_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_1_Mul_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_Add_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_Add_3 */
  Qnn_Param_t params__text_encoder_attn_encoder_Add_3[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_Add_3[] = {
    "_text_encoder_attn_encoder_norm_layers_1_1_Transpose_1_output_0",
    "_text_encoder_attn_encoder_ffn_layers_1_Mul_2_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_2_1_Transpose_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_Add_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_2_1_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0371336527168751f, .offset= -133}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_2_1_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_Add_3", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_Add_3, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_Add_3, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_Add_3, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_2_1_norm_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_2_1_norm_weight[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_norm_layers_2_1_norm_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_norm_layers_2_1_norm_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0019406405044720f, .offset= 0}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_2_1_norm_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_norm_layers_2_1_norm_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_norm_layers_2_1_norm_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_2_1_norm_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_2_1_norm_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_norm_layers_2_1_norm_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_norm_layers_2_1_norm_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0005669858073816f, .offset= -176}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_2_1_norm_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_norm_layers_2_1_norm_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_norm_layers_2_1_norm_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_norm_layers_2_1_norm_LayerNormalization(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_norm_layers_2_1_norm_LayerNormalization */
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_2_1_norm_LayerNormalization_axes[] = {1};
  uint32_t _text_encoder_attn_encoder_norm_layers_2_1_norm_LayerNormalization_axes[] = {2};
  Qnn_Param_t params__text_encoder_attn_encoder_norm_layers_2_1_norm_LayerNormalization[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="axes",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_2_1_norm_LayerNormalization_axes",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_2_1_norm_LayerNormalization_axes,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_norm_layers_2_1_norm_LayerNormalization_axes,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="epsilon",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000001000000f}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_norm_layers_2_1_norm_LayerNormalization[] = {
    "_text_encoder_attn_encoder_norm_layers_2_1_Transpose_output_0",
    "tts_ttl_text_encoder_attn_encoder_norm_layers_2_1_norm_weight",
    "tts_ttl_text_encoder_attn_encoder_norm_layers_2_1_norm_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_norm_layers_2_1_norm_LayerNormalization[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0126875070855021f, .offset= -135}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_norm_layers_2_1_norm_LayerNormalization", // Node Name
                         "qti.aisw", // Package Name
                         "LayerNorm", // Qnn Node Type
                         params__text_encoder_attn_encoder_norm_layers_2_1_norm_LayerNormalization, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_norm_layers_2_1_norm_LayerNormalization, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_norm_layers_2_1_norm_LayerNormalization, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf[] = {
    "_text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0126875070855021f, .offset= -135}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0126875070855021f, .offset= -135}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0126875070855021f, .offset= -135}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_q_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_q_weight[] = {1, 1, 256, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_q_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_q_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0048754797317088f, .offset= -135}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_q_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_q_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_q_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_q_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_q_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_q_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_q_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0041120192036033f, .offset= -136}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_q_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_q_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_q_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d[] = {
    "_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_q_weight",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_q_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0387699119746685f, .offset= -130}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0387699119746685f, .offset= -130}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_output_0[] = {1, 4, 64, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Reshape_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0387699119746685f, .offset= -130}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0126875070855021f, .offset= -135}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0126875070855021f, .offset= -135}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_k_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_k_weight[] = {1, 1, 256, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_k_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_k_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0040139411576092f, .offset= -131}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_k_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_k_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_k_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_k_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_k_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_k_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_k_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0001727917988319f, .offset= -127}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_k_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_k_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_k_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d[] = {
    "_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_k_weight",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_k_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0368400998413563f, .offset= -189}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0368400998413563f, .offset= -189}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_1_output_0[] = {1, 4, 64, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Reshape_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0368400998413563f, .offset= -189}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0126875070855021f, .offset= -135}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0126875070855021f, .offset= -135}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_v_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_v_weight[] = {1, 1, 256, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_v_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_v_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0039736330509186f, .offset= -136}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_v_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_v_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_v_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_v_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_v_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_v_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_v_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0005270699621178f, .offset= -113}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_v_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_v_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_v_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d[] = {
    "_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_v_weight",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_v_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0392994768917561f, .offset= -134}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0392994768917561f, .offset= -134}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_2_output_0[] = {1, 4, 64, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Reshape_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0392994768917561f, .offset= -134}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Transpose(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Transpose */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Transpose_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_Transpose_perm[] = {0, 1, 3, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_Transpose[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Transpose_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Transpose_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_Transpose_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Transpose[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Reshape_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Transpose_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Transpose[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0387699119746685f, .offset= -130}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Transpose", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_Transpose, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Transpose, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Transpose, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Transpose_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Transpose_1 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Transpose_1_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_Transpose_1_perm[] = {0, 1, 3, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_Transpose_1[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Transpose_1_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Transpose_1_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_Transpose_1_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Transpose_1[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Reshape_2_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Transpose_1_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Transpose_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Transpose_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0392994768917561f, .offset= -134}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Transpose_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Transpose_1", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_Transpose_1, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Transpose_1, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Transpose_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Div(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Div */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_Div[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 2}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Div[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Transpose_output_0",
    "_text_encoder_attn_encoder_attn_layers_0_Constant_10_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Div_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Div[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Div_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0048462389968336f, .offset= -130}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Div_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Div", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_Div, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Div, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Div, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_MatMul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_MatMul */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_MatMul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_MatMul[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Div_output_0",
    "_text_encoder_attn_encoder_attn_layers_2_Reshape_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_MatMul_output_0[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_MatMul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_MatMul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0252329930663109f, .offset= -130}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_MatMul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_MatMul", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_MatMul, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_MatMul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_MatMul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor__text_encoder_attn_encoder_attn_layers_2_Transpose_3_output_0_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Transpose_3_output_0_nchw[] = {1, 1, 64, 255};
  VALIDATE(model.addTensor("_text_encoder_attn_encoder_attn_layers_2_Transpose_3_output_0_nchw", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "_text_encoder_attn_encoder_attn_layers_2_Transpose_3_output_0_nchw",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0097710574045777f, .offset= -137}}},
                                 .rank= 4,
                                 .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Transpose_3_output_0_nchw,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(_text_encoder_attn_encoder_attn_layers_2_Transpose_3_output_0_nchw),
                                                .dataSize=BINLEN(_text_encoder_attn_encoder_attn_layers_2_Transpose_3_output_0_nchw)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_MatMul_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_MatMul_1 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_MatMul_1[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_MatMul_1[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Div_output_0",
    "_text_encoder_attn_encoder_attn_layers_2_Transpose_3_output_0_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0[] = {1, 4, 128, 255};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_MatMul_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0357847958803177f, .offset= -66}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_MatMul_1", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_MatMul_1, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_MatMul_1, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_MatMul_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0_nhwc[] = {1, 128, 255, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0357847958803177f, .offset= -66}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Pad_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Pad_1 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_1_pad_amount[] = {4, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_Pad_1_pad_amount[] = {0, 0, 0, 0, 0, 1, 0, 0};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_Pad_1[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Pad_1_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_1_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_Pad_1_pad_amount,
                           .dataSize=32}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="pad_constant_value",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000000000000f}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Pad_1[] = {
    "_text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0_nhwc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0[] = {1, 128, 256, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Pad_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0357847958803177f, .offset= -66}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Pad_1", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_Pad_1, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Pad_1, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Pad_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0_nchw[] = {1, 4, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0357847958803177f, .offset= -66}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Reshape_7(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Reshape_7 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Reshape_7[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0[] = {1, 4, 32768};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Reshape_7[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0357847958803177f, .offset= -66}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Reshape_7", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Reshape_7, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Reshape_7, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0_nfc[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0_nfc[] = {1, 32768, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0357847958803177f, .offset= -66}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Pad_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Pad_2 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_2_pad_amount[] = {3, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_Pad_2_pad_amount[] = {0, 0, 0, 127, 0, 0};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_Pad_2[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Pad_2_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_2_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_Pad_2_pad_amount,
                           .dataSize=24}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="pad_constant_value",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000000000000f}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Pad_2[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0_nfc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0[] = {1, 32895, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Pad_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0357847958803177f, .offset= -66}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Pad_2", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_Pad_2, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Pad_2, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Pad_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0_ncf[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0_ncf[] = {1, 4, 32895};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0357847958803177f, .offset= -66}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Reshape_10(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Reshape_10 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Reshape_10[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_10_output_0[] = {1, 4, 129, 255};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Reshape_10[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Reshape_10_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0357847958803177f, .offset= -66}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_10_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Reshape_10", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Reshape_10, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Reshape_10, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode_Slice_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR Slice_2 */
  uint32_t dimensions_Slice_2_ranges[] = {4, 3};
  int32_t Slice_2_ranges[] = {0, 1, 1, 0, 4, 1, 0, 128, 1, 127, 255, 1};
  Qnn_Param_t params_Slice_2[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="ranges",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "Slice_2_ranges",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_INT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions_Slice_2_ranges,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)Slice_2_ranges,
                           .dataSize=48}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="begin_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="end_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="new_axes_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="shrink_axes",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs_Slice_2[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Reshape_10_output_0"
  };
  uint32_t dimensions__v_900[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs_Slice_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_v_900",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0357847958803177f, .offset= -66}}},
            .rank= 4,
            .dimensions=dimensions__v_900,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "Slice_2", // Node Name
                         "qti.aisw", // Package Name
                         "StridedSlice", // Qnn Node Type
                         params_Slice_2, // Node Params
                         5, // Num Node Params
                         inputs_Slice_2, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs_Slice_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Add_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Add_2 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_Add_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Add_2[] = {
    "_text_encoder_attn_encoder_attn_layers_2_MatMul_output_0",
    "_v_900"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Add_2_output_0[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Add_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Add_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0368641167879105f, .offset= -101}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Add_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Add_2", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_Add_2, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Add_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Add_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Where(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Where */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Where[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Cast_5_output_0",
    "_text_encoder_attn_encoder_attn_layers_0_Constant_88_output_0",
    "_text_encoder_attn_encoder_attn_layers_2_Add_2_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Where_output_0[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Where[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Where_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 39.2379379272460938f, .offset= -255}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Where_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Where", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseSelect", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Where, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Where, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Softmax(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Softmax */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_Softmax[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="axis",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 3}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="beta",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 1.000000000000f}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Softmax[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Where_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Softmax_output_0[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Softmax[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Softmax_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Softmax_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Softmax", // Node Name
                         "qti.aisw", // Package Name
                         "Softmax", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_Softmax, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Softmax, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Softmax, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Softmax_output_0_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Softmax_output_0_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Softmax_output_0_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_Softmax_output_0_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_Softmax_output_0_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Softmax_output_0_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Softmax_output_0_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_Softmax_output_0_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Softmax_output_0_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Softmax_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Softmax_output_0_nhwc[] = {1, 128, 128, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Softmax_output_0_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Softmax_output_0_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Softmax_output_0_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Softmax_output_0_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_Softmax_output_0_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Softmax_output_0_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Softmax_output_0_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_MatMul_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_MatMul_2 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_MatMul_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_MatMul_2[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Softmax_output_0",
    "_text_encoder_attn_encoder_attn_layers_2_Transpose_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_MatMul_2_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_MatMul_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_MatMul_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0172664560377598f, .offset= -119}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_MatMul_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_MatMul_2", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_MatMul_2, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_MatMul_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_MatMul_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Pad_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Pad_3 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_3_pad_amount[] = {4, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_Pad_3_pad_amount[] = {0, 0, 0, 0, 0, 127, 0, 0};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_Pad_3[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Pad_3_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_3_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_Pad_3_pad_amount,
                           .dataSize=32}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="pad_constant_value",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000000000000f}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Pad_3[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Softmax_output_0_nhwc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0[] = {1, 128, 255, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Pad_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Pad_3", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_Pad_3, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Pad_3, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Pad_3, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0_nchw[] = {1, 4, 128, 255};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Reshape_13(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Reshape_13 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Reshape_13[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0[] = {1, 4, 32640};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Reshape_13[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Reshape_13", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Reshape_13, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Reshape_13, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0_nfc[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0_nfc[] = {1, 32640, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Pad_4(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Pad_4 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_4_pad_amount[] = {3, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_Pad_4_pad_amount[] = {0, 0, 128, 0, 0, 0};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_Pad_4[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Pad_4_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_4_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_Pad_4_pad_amount,
                           .dataSize=24}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="pad_constant_value",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000000000000f}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Pad_4[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0_nfc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0[] = {1, 32768, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Pad_4[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Pad_4", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_Pad_4, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Pad_4, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Pad_4, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0_ncf[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0_ncf[] = {1, 4, 32768};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Reshape_16(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Reshape_16 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Reshape_16[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_16_output_0[] = {1, 4, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Reshape_16[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Reshape_16_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Reshape_16_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Reshape_16", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Reshape_16, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Reshape_16, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Slice_8(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Slice_8 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Slice_8_ranges[] = {4, 3};
  int32_t _text_encoder_attn_encoder_attn_layers_2_Slice_8_ranges[] = {0, 1, 1, 0, 4, 1, 0, 128, 1, 1, 256, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_Slice_8[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="ranges",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Slice_8_ranges",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_INT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Slice_8_ranges,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_Slice_8_ranges,
                           .dataSize=48}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="begin_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="end_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="new_axes_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="shrink_axes",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Slice_8[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Reshape_16_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Slice_8_output_0[] = {1, 4, 128, 255};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Slice_8[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Slice_8_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Slice_8_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Slice_8", // Node Name
                         "qti.aisw", // Package Name
                         "StridedSlice", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_Slice_8, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Slice_8, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Slice_8, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor__text_encoder_attn_encoder_attn_layers_2_Unsqueeze_41_output_0_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Unsqueeze_41_output_0_nchw[] = {1, 1, 255, 64};
  VALIDATE(model.addTensor("_text_encoder_attn_encoder_attn_layers_2_Unsqueeze_41_output_0_nchw", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "_text_encoder_attn_encoder_attn_layers_2_Unsqueeze_41_output_0_nchw",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0042457645758986f, .offset= -133}}},
                                 .rank= 4,
                                 .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Unsqueeze_41_output_0_nchw,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(_text_encoder_attn_encoder_attn_layers_2_Unsqueeze_41_output_0_nchw),
                                                .dataSize=BINLEN(_text_encoder_attn_encoder_attn_layers_2_Unsqueeze_41_output_0_nchw)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_MatMul_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_MatMul_3 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_MatMul_3[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_MatMul_3[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Slice_8_output_0",
    "_text_encoder_attn_encoder_attn_layers_2_Unsqueeze_41_output_0_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_MatMul_3_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_MatMul_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_MatMul_3_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0035321377217770f, .offset= -133}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_MatMul_3_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_MatMul_3", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_MatMul_3, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_MatMul_3, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_MatMul_3, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Add_4(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Add_4 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_Add_4[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Add_4[] = {
    "_text_encoder_attn_encoder_attn_layers_2_MatMul_2_output_0",
    "_text_encoder_attn_encoder_attn_layers_2_MatMul_3_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Add_4_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Add_4[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Add_4_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0175298005342484f, .offset= -119}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Add_4_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Add_4", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_Add_4, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Add_4, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Add_4, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Transpose_9(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Transpose_9 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Transpose_9_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_Transpose_9_perm[] = {0, 1, 3, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_Transpose_9[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Transpose_9_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Transpose_9_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_Transpose_9_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Transpose_9[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Add_4_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_Transpose_9_output_0[] = {1, 4, 64, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Transpose_9[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_Transpose_9_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0175298005342484f, .offset= -119}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_Transpose_9_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Transpose_9", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_Transpose_9, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Transpose_9, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Transpose_9, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_Reshape_19(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_Reshape_19 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_Reshape_19[] = {
    "_text_encoder_attn_encoder_attn_layers_2_Transpose_9_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_Reshape_19[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0175298005342484f, .offset= -119}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_Reshape_19", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_Reshape_19, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_Reshape_19, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0175298005342484f, .offset= -119}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_o_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_o_weight[] = {1, 1, 256, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_o_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_o_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0034867553040385f, .offset= -125}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_o_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_o_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_o_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_o_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_o_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_o_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_o_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0023337549064308f, .offset= -46}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_o_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_o_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_o_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d[] = {
    "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_o_weight",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_o_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0224784761667252f, .offset= -121}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0224784761667252f, .offset= -121}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0224784761667252f, .offset= -121}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0_nfc[] = {
    "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0224784761667252f, .offset= -121}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_Add_4(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_Add_4 */
  Qnn_Param_t params__text_encoder_attn_encoder_Add_4[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_Add_4[] = {
    "_text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0",
    "_text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0_nfc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_1_2_Transpose_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_Add_4[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_1_2_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0288309771567583f, .offset= -128}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_1_2_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_Add_4", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_Add_4, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_Add_4, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_Add_4, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_1_2_norm_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_1_2_norm_weight[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_norm_layers_1_2_norm_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_norm_layers_1_2_norm_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0028002397157252f, .offset= 0}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_1_2_norm_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_norm_layers_1_2_norm_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_norm_layers_1_2_norm_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_1_2_norm_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_1_2_norm_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_norm_layers_1_2_norm_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_norm_layers_1_2_norm_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0022414983250201f, .offset= -54}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_1_2_norm_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_norm_layers_1_2_norm_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_norm_layers_1_2_norm_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_norm_layers_1_2_norm_LayerNormalization(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_norm_layers_1_2_norm_LayerNormalization */
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_1_2_norm_LayerNormalization_axes[] = {1};
  uint32_t _text_encoder_attn_encoder_norm_layers_1_2_norm_LayerNormalization_axes[] = {2};
  Qnn_Param_t params__text_encoder_attn_encoder_norm_layers_1_2_norm_LayerNormalization[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="axes",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_1_2_norm_LayerNormalization_axes",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_1_2_norm_LayerNormalization_axes,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_norm_layers_1_2_norm_LayerNormalization_axes,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="epsilon",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000001000000f}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_norm_layers_1_2_norm_LayerNormalization[] = {
    "_text_encoder_attn_encoder_norm_layers_1_2_Transpose_output_0",
    "tts_ttl_text_encoder_attn_encoder_norm_layers_1_2_norm_weight",
    "tts_ttl_text_encoder_attn_encoder_norm_layers_1_2_norm_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_1_2_Transpose_1_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_norm_layers_1_2_norm_LayerNormalization[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_1_2_Transpose_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0185746252536774f, .offset= -106}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_1_2_Transpose_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_norm_layers_1_2_norm_LayerNormalization", // Node Name
                         "qti.aisw", // Package Name
                         "LayerNorm", // Qnn Node Type
                         params__text_encoder_attn_encoder_norm_layers_1_2_norm_LayerNormalization, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_norm_layers_1_2_norm_LayerNormalization, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_norm_layers_1_2_norm_LayerNormalization, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_2_Mul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_2_Mul */
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_2_Mul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_2_Mul[] = {
    "_text_encoder_attn_encoder_norm_layers_1_2_Transpose_1_output_0",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_Mul_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_2_Mul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_Mul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0185746252536774f, .offset= -106}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_Mul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_2_Mul", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_2_Mul, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_2_Mul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_2_Mul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_2_Mul_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_2_Mul_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_Mul_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_ffn_layers_2_Mul_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_2_Mul_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_Mul_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_Mul_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_2_Mul_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_2_Mul_output_0_ncf[] = {
    "_text_encoder_attn_encoder_ffn_layers_2_Mul_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_Mul_output_0_ncf[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_2_Mul_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_Mul_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0185746252536774f, .offset= -106}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_Mul_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_2_Mul_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_2_Mul_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_2_Mul_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_2_Mul_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_ffn_layers_2_Mul_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0185746252536774f, .offset= -106}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0185746252536774f, .offset= -106}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_1_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_1_weight[] = {1, 1, 256, 1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_1_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_1_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0043693627230823f, .offset= -126}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_1_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_1_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_1_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_1_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_1_bias[] = {1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_1_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_1_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0008930204785429f, .offset= -226}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_1_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_1_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_1_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d[] = {
    "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_1_weight",
    "tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_1_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0252027846872807f, .offset= -189}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate_nchw[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0252027846872807f, .offset= -189}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0252027846872807f, .offset= -189}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_2_Relu(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_2_Relu */
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_2_Relu[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 4}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_2_Relu[] = {
    "_text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_Relu_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_2_Relu[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_Relu_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0065446719527245f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_Relu_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_2_Relu", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseNeuron", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_2_Relu, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_2_Relu, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_2_Relu, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_2_Relu_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_2_Relu_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_Relu_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_ffn_layers_2_Relu_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_2_Relu_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_Relu_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_Relu_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_2_Relu_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_2_Relu_output_0_nfc[] = {
    "_text_encoder_attn_encoder_ffn_layers_2_Relu_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_Relu_output_0_nfc[] = {1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_2_Relu_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_Relu_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0065446719527245f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_Relu_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_2_Relu_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_2_Relu_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_2_Relu_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_2_Relu_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_2_Mul_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_2_Mul_1 */
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_2_Mul_1[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_2_Mul_1[] = {
    "_text_encoder_attn_encoder_ffn_layers_2_Relu_output_0_nfc",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0[] = {1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_2_Mul_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0065446719527245f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_2_Mul_1", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_2_Mul_1, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_2_Mul_1, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_2_Mul_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0_ncf[] = {
    "_text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0_ncf[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0065446719527245f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0065446719527245f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0065446719527245f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_2_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_2_weight[] = {1, 1, 1024, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_2_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_2_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0053570051677525f, .offset= -115}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_2_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_2_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_2_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_2_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_2_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_2_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_2_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0025660027749836f, .offset= -57}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_2_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_2_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_2_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d[] = {
    "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_2_weight",
    "tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_2_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0135021395981312f, .offset= -78}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0135021395981312f, .offset= -78}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0135021395981312f, .offset= -78}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0_nfc[] = {
    "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0135021395981312f, .offset= -78}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_2_Mul_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_2_Mul_2 */
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_2_Mul_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_2_Mul_2[] = {
    "_text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0_nfc",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_2_Mul_2_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_2_Mul_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_2_Mul_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0135021395981312f, .offset= -78}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_2_Mul_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_2_Mul_2", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_2_Mul_2, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_2_Mul_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_2_Mul_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_Add_5(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_Add_5 */
  Qnn_Param_t params__text_encoder_attn_encoder_Add_5[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_Add_5[] = {
    "_text_encoder_attn_encoder_norm_layers_1_2_Transpose_1_output_0",
    "_text_encoder_attn_encoder_ffn_layers_2_Mul_2_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_2_2_Transpose_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_Add_5[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_2_2_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0253867246210575f, .offset= -94}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_2_2_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_Add_5", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_Add_5, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_Add_5, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_Add_5, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_2_2_norm_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_2_2_norm_weight[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_norm_layers_2_2_norm_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_norm_layers_2_2_norm_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0017360139172524f, .offset= 0}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_2_2_norm_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_norm_layers_2_2_norm_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_norm_layers_2_2_norm_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_2_2_norm_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_2_2_norm_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_norm_layers_2_2_norm_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_norm_layers_2_2_norm_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0013368730433285f, .offset= -141}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_2_2_norm_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_norm_layers_2_2_norm_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_norm_layers_2_2_norm_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_norm_layers_2_2_norm_LayerNormalization(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_norm_layers_2_2_norm_LayerNormalization */
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_2_2_norm_LayerNormalization_axes[] = {1};
  uint32_t _text_encoder_attn_encoder_norm_layers_2_2_norm_LayerNormalization_axes[] = {2};
  Qnn_Param_t params__text_encoder_attn_encoder_norm_layers_2_2_norm_LayerNormalization[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="axes",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_2_2_norm_LayerNormalization_axes",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_2_2_norm_LayerNormalization_axes,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_norm_layers_2_2_norm_LayerNormalization_axes,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="epsilon",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000001000000f}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_norm_layers_2_2_norm_LayerNormalization[] = {
    "_text_encoder_attn_encoder_norm_layers_2_2_Transpose_output_0",
    "tts_ttl_text_encoder_attn_encoder_norm_layers_2_2_norm_weight",
    "tts_ttl_text_encoder_attn_encoder_norm_layers_2_2_norm_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_norm_layers_2_2_norm_LayerNormalization[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0173346213996410f, .offset= -135}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_norm_layers_2_2_norm_LayerNormalization", // Node Name
                         "qti.aisw", // Package Name
                         "LayerNorm", // Qnn Node Type
                         params__text_encoder_attn_encoder_norm_layers_2_2_norm_LayerNormalization, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_norm_layers_2_2_norm_LayerNormalization, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_norm_layers_2_2_norm_LayerNormalization, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf[] = {
    "_text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0173346213996410f, .offset= -135}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0173346213996410f, .offset= -135}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0173346213996410f, .offset= -135}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_q_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_q_weight[] = {1, 1, 256, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_q_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_q_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0061746207065880f, .offset= -115}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_q_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_q_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_q_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_q_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_q_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_q_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_q_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0041565699502826f, .offset= -125}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_q_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_q_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_q_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d[] = {
    "_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_q_weight",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_q_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0306774340569973f, .offset= -115}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0306774340569973f, .offset= -115}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_output_0[] = {1, 4, 64, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Reshape_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0306774340569973f, .offset= -115}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0173346213996410f, .offset= -135}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0173346213996410f, .offset= -135}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_k_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_k_weight[] = {1, 1, 256, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_k_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_k_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0040585468523204f, .offset= -130}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_k_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_k_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_k_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_k_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_k_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_k_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_k_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0001801223988878f, .offset= -128}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_k_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_k_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_k_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d[] = {
    "_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_k_weight",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_k_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0138312568888068f, .offset= -132}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0138312568888068f, .offset= -132}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_1_output_0[] = {1, 4, 64, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Reshape_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0138312568888068f, .offset= -132}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0173346213996410f, .offset= -135}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0173346213996410f, .offset= -135}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_v_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_v_weight[] = {1, 1, 256, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_v_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_v_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0037634058389813f, .offset= -132}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_v_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_v_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_v_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_v_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_v_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_v_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_v_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0006837570690550f, .offset= -138}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_v_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_v_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_v_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d[] = {
    "_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_v_weight",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_v_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0128599144518375f, .offset= -137}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0128599144518375f, .offset= -137}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_2_output_0[] = {1, 4, 64, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Reshape_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0128599144518375f, .offset= -137}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Transpose(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Transpose */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Transpose_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_Transpose_perm[] = {0, 1, 3, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_Transpose[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Transpose_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Transpose_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_Transpose_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Transpose[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Reshape_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Transpose_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Transpose[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0306774340569973f, .offset= -115}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Transpose", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_Transpose, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Transpose, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Transpose, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Transpose_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Transpose_1 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Transpose_1_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_Transpose_1_perm[] = {0, 1, 3, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_Transpose_1[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Transpose_1_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Transpose_1_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_Transpose_1_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Transpose_1[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Reshape_2_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Transpose_1_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Transpose_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Transpose_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0128599144518375f, .offset= -137}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Transpose_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Transpose_1", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_Transpose_1, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Transpose_1, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Transpose_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Div(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Div */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_Div[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 2}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Div[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Transpose_output_0",
    "_text_encoder_attn_encoder_attn_layers_0_Constant_10_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Div_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Div[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Div_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0038346792571247f, .offset= -115}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Div_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Div", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_Div, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Div, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Div, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_MatMul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_MatMul */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_MatMul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_MatMul[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Div_output_0",
    "_text_encoder_attn_encoder_attn_layers_3_Reshape_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_MatMul_output_0[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_MatMul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_MatMul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0118477465584874f, .offset= -117}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_MatMul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_MatMul", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_MatMul, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_MatMul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_MatMul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor__text_encoder_attn_encoder_attn_layers_3_Transpose_3_output_0_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Transpose_3_output_0_nchw[] = {1, 1, 64, 255};
  VALIDATE(model.addTensor("_text_encoder_attn_encoder_attn_layers_3_Transpose_3_output_0_nchw", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "_text_encoder_attn_encoder_attn_layers_3_Transpose_3_output_0_nchw",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0064808367751539f, .offset= -119}}},
                                 .rank= 4,
                                 .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Transpose_3_output_0_nchw,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(_text_encoder_attn_encoder_attn_layers_3_Transpose_3_output_0_nchw),
                                                .dataSize=BINLEN(_text_encoder_attn_encoder_attn_layers_3_Transpose_3_output_0_nchw)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_MatMul_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_MatMul_1 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_MatMul_1[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_MatMul_1[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Div_output_0",
    "_text_encoder_attn_encoder_attn_layers_3_Transpose_3_output_0_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0[] = {1, 4, 128, 255};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_MatMul_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0328583866357803f, .offset= -72}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_MatMul_1", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_MatMul_1, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_MatMul_1, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_MatMul_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0_nhwc[] = {1, 128, 255, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0328583866357803f, .offset= -72}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Pad_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Pad_1 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_1_pad_amount[] = {4, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_Pad_1_pad_amount[] = {0, 0, 0, 0, 0, 1, 0, 0};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_Pad_1[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Pad_1_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_1_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_Pad_1_pad_amount,
                           .dataSize=32}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="pad_constant_value",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000000000000f}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Pad_1[] = {
    "_text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0_nhwc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0[] = {1, 128, 256, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Pad_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0328583866357803f, .offset= -72}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Pad_1", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_Pad_1, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Pad_1, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Pad_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0_nchw[] = {1, 4, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0328583866357803f, .offset= -72}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Reshape_7(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Reshape_7 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Reshape_7[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0[] = {1, 4, 32768};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Reshape_7[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0328583866357803f, .offset= -72}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Reshape_7", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Reshape_7, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Reshape_7, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0_nfc[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0_nfc[] = {1, 32768, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0328583866357803f, .offset= -72}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Pad_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Pad_2 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_2_pad_amount[] = {3, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_Pad_2_pad_amount[] = {0, 0, 0, 127, 0, 0};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_Pad_2[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Pad_2_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_2_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_Pad_2_pad_amount,
                           .dataSize=24}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="pad_constant_value",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000000000000f}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Pad_2[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0_nfc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0[] = {1, 32895, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Pad_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0328583866357803f, .offset= -72}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Pad_2", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_Pad_2, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Pad_2, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Pad_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0_ncf[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0_ncf[] = {1, 4, 32895};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0328583866357803f, .offset= -72}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Reshape_10(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Reshape_10 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Reshape_10[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_10_output_0[] = {1, 4, 129, 255};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Reshape_10[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Reshape_10_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0328583866357803f, .offset= -72}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_10_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Reshape_10", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Reshape_10, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Reshape_10, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode_Slice_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR Slice_3 */
  uint32_t dimensions_Slice_3_ranges[] = {4, 3};
  int32_t Slice_3_ranges[] = {0, 1, 1, 0, 4, 1, 0, 128, 1, 127, 255, 1};
  Qnn_Param_t params_Slice_3[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="ranges",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "Slice_3_ranges",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_INT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions_Slice_3_ranges,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)Slice_3_ranges,
                           .dataSize=48}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="begin_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="end_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="new_axes_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="shrink_axes",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs_Slice_3[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Reshape_10_output_0"
  };
  uint32_t dimensions__v_905[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs_Slice_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_v_905",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0328583866357803f, .offset= -72}}},
            .rank= 4,
            .dimensions=dimensions__v_905,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "Slice_3", // Node Name
                         "qti.aisw", // Package Name
                         "StridedSlice", // Qnn Node Type
                         params_Slice_3, // Node Params
                         5, // Num Node Params
                         inputs_Slice_3, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs_Slice_3, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Add_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Add_2 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_Add_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Add_2[] = {
    "_text_encoder_attn_encoder_attn_layers_3_MatMul_output_0",
    "_v_905"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Add_2_output_0[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Add_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Add_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0351072736084461f, .offset= -93}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Add_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Add_2", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_Add_2, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Add_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Add_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Where(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Where */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Where[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Cast_5_output_0",
    "_text_encoder_attn_encoder_attn_layers_0_Constant_88_output_0",
    "_text_encoder_attn_encoder_attn_layers_3_Add_2_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Where_output_0[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Where[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Where_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 39.2379989624023438f, .offset= -255}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Where_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Where", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseSelect", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Where, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Where, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Softmax(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Softmax */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_Softmax[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="axis",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 3}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="beta",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 1.000000000000f}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Softmax[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Where_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Softmax_output_0[] = {1, 4, 128, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Softmax[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Softmax_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Softmax_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Softmax", // Node Name
                         "qti.aisw", // Package Name
                         "Softmax", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_Softmax, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Softmax, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Softmax, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Softmax_output_0_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Softmax_output_0_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Softmax_output_0_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_Softmax_output_0_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_Softmax_output_0_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Softmax_output_0_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Softmax_output_0_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_Softmax_output_0_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Softmax_output_0_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Softmax_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Softmax_output_0_nhwc[] = {1, 128, 128, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Softmax_output_0_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Softmax_output_0_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Softmax_output_0_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Softmax_output_0_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_Softmax_output_0_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Softmax_output_0_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Softmax_output_0_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_MatMul_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_MatMul_2 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_MatMul_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_MatMul_2[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Softmax_output_0",
    "_text_encoder_attn_encoder_attn_layers_3_Transpose_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_MatMul_2_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_MatMul_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_MatMul_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0097448294982314f, .offset= -116}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_MatMul_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_MatMul_2", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_MatMul_2, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_MatMul_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_MatMul_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Pad_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Pad_3 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_3_pad_amount[] = {4, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_Pad_3_pad_amount[] = {0, 0, 0, 0, 0, 127, 0, 0};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_Pad_3[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Pad_3_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_3_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_Pad_3_pad_amount,
                           .dataSize=32}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="pad_constant_value",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000000000000f}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Pad_3[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Softmax_output_0_nhwc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0[] = {1, 128, 255, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Pad_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Pad_3", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_Pad_3, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Pad_3, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Pad_3, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0_nchw[] = {1, 4, 128, 255};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Reshape_13(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Reshape_13 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Reshape_13[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0[] = {1, 4, 32640};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Reshape_13[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Reshape_13", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Reshape_13, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Reshape_13, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0_nfc[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0_nfc[] = {1, 32640, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Pad_4(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Pad_4 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_4_pad_amount[] = {3, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_Pad_4_pad_amount[] = {0, 0, 128, 0, 0, 0};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_Pad_4[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Pad_4_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_4_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_Pad_4_pad_amount,
                           .dataSize=24}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="pad_constant_value",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000000000000f}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="scheme",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Pad_4[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0_nfc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0[] = {1, 32768, 4};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Pad_4[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Pad_4", // Node Name
                         "qti.aisw", // Package Name
                         "Pad", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_Pad_4, // Node Params
                         3, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Pad_4, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Pad_4, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0_ncf[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0_ncf[] = {1, 4, 32768};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Reshape_16(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Reshape_16 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Reshape_16[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_16_output_0[] = {1, 4, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Reshape_16[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Reshape_16_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Reshape_16_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Reshape_16", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Reshape_16, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Reshape_16, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Slice_8(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Slice_8 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Slice_8_ranges[] = {4, 3};
  int32_t _text_encoder_attn_encoder_attn_layers_3_Slice_8_ranges[] = {0, 1, 1, 0, 4, 1, 0, 128, 1, 1, 256, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_Slice_8[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="ranges",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Slice_8_ranges",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_INT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Slice_8_ranges,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_Slice_8_ranges,
                           .dataSize=48}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="begin_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="end_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="new_axes_mask",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="shrink_axes",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Slice_8[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Reshape_16_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Slice_8_output_0[] = {1, 4, 128, 255};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Slice_8[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Slice_8_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Slice_8_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Slice_8", // Node Name
                         "qti.aisw", // Package Name
                         "StridedSlice", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_Slice_8, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Slice_8, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Slice_8, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor__text_encoder_attn_encoder_attn_layers_3_Unsqueeze_41_output_0_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Unsqueeze_41_output_0_nchw[] = {1, 1, 255, 64};
  VALIDATE(model.addTensor("_text_encoder_attn_encoder_attn_layers_3_Unsqueeze_41_output_0_nchw", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "_text_encoder_attn_encoder_attn_layers_3_Unsqueeze_41_output_0_nchw",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0047492808662355f, .offset= -120}}},
                                 .rank= 4,
                                 .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Unsqueeze_41_output_0_nchw,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(_text_encoder_attn_encoder_attn_layers_3_Unsqueeze_41_output_0_nchw),
                                                .dataSize=BINLEN(_text_encoder_attn_encoder_attn_layers_3_Unsqueeze_41_output_0_nchw)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_MatMul_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_MatMul_3 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_MatMul_3[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_MatMul_3[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Slice_8_output_0",
    "_text_encoder_attn_encoder_attn_layers_3_Unsqueeze_41_output_0_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_MatMul_3_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_MatMul_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_MatMul_3_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0029824515804648f, .offset= -121}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_MatMul_3_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_MatMul_3", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_MatMul_3, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_MatMul_3, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_MatMul_3, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Add_4(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Add_4 */
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_Add_4[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Add_4[] = {
    "_text_encoder_attn_encoder_attn_layers_3_MatMul_2_output_0",
    "_text_encoder_attn_encoder_attn_layers_3_MatMul_3_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Add_4_output_0[] = {1, 4, 128, 64};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Add_4[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Add_4_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0102169392630458f, .offset= -112}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Add_4_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Add_4", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_Add_4, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Add_4, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Add_4, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Transpose_9(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Transpose_9 */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Transpose_9_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_Transpose_9_perm[] = {0, 1, 3, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_Transpose_9[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Transpose_9_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Transpose_9_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_Transpose_9_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Transpose_9[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Add_4_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_Transpose_9_output_0[] = {1, 4, 64, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Transpose_9[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_Transpose_9_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0102169392630458f, .offset= -112}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_Transpose_9_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Transpose_9", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_Transpose_9, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Transpose_9, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Transpose_9, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_Reshape_19(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_Reshape_19 */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_Reshape_19[] = {
    "_text_encoder_attn_encoder_attn_layers_3_Transpose_9_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_Reshape_19[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0102169392630458f, .offset= -112}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_Reshape_19", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_Reshape_19, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_Reshape_19, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0102169392630458f, .offset= -112}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_o_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_o_weight[] = {1, 1, 256, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_o_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_o_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0031041223555803f, .offset= -130}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_o_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_o_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_o_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_o_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_o_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_o_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_o_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0018874258967116f, .offset= -121}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_o_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_o_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_o_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d[] = {
    "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_o_weight",
    "tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_o_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0166237726807594f, .offset= -133}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0166237726807594f, .offset= -133}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0166237726807594f, .offset= -133}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0_nfc[] = {
    "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0166237726807594f, .offset= -133}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_Add_6(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_Add_6 */
  Qnn_Param_t params__text_encoder_attn_encoder_Add_6[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_Add_6[] = {
    "_text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0",
    "_text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0_nfc"
  };
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_1_3_Transpose_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_Add_6[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_1_3_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0233110655099154f, .offset= -154}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_1_3_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_Add_6", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_Add_6, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_Add_6, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_Add_6, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_1_3_norm_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_1_3_norm_weight[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_norm_layers_1_3_norm_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_norm_layers_1_3_norm_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0024243684019893f, .offset= 0}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_1_3_norm_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_norm_layers_1_3_norm_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_norm_layers_1_3_norm_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_1_3_norm_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_1_3_norm_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_norm_layers_1_3_norm_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_norm_layers_1_3_norm_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0012694986071438f, .offset= -122}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_1_3_norm_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_norm_layers_1_3_norm_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_norm_layers_1_3_norm_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_norm_layers_1_3_norm_LayerNormalization(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_norm_layers_1_3_norm_LayerNormalization */
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_1_3_norm_LayerNormalization_axes[] = {1};
  uint32_t _text_encoder_attn_encoder_norm_layers_1_3_norm_LayerNormalization_axes[] = {2};
  Qnn_Param_t params__text_encoder_attn_encoder_norm_layers_1_3_norm_LayerNormalization[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="axes",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_1_3_norm_LayerNormalization_axes",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_1_3_norm_LayerNormalization_axes,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_norm_layers_1_3_norm_LayerNormalization_axes,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="epsilon",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000001000000f}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_norm_layers_1_3_norm_LayerNormalization[] = {
    "_text_encoder_attn_encoder_norm_layers_1_3_Transpose_output_0",
    "tts_ttl_text_encoder_attn_encoder_norm_layers_1_3_norm_weight",
    "tts_ttl_text_encoder_attn_encoder_norm_layers_1_3_norm_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_1_3_Transpose_1_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_norm_layers_1_3_norm_LayerNormalization[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_1_3_Transpose_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0208389088511467f, .offset= -163}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_1_3_Transpose_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_norm_layers_1_3_norm_LayerNormalization", // Node Name
                         "qti.aisw", // Package Name
                         "LayerNorm", // Qnn Node Type
                         params__text_encoder_attn_encoder_norm_layers_1_3_norm_LayerNormalization, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_norm_layers_1_3_norm_LayerNormalization, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_norm_layers_1_3_norm_LayerNormalization, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_3_Mul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_3_Mul */
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_3_Mul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_3_Mul[] = {
    "_text_encoder_attn_encoder_norm_layers_1_3_Transpose_1_output_0",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_Mul_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_3_Mul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_Mul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0208389088511467f, .offset= -163}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_Mul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_3_Mul", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_3_Mul, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_3_Mul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_3_Mul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_3_Mul_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_3_Mul_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_Mul_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_ffn_layers_3_Mul_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_3_Mul_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_Mul_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_Mul_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_3_Mul_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_3_Mul_output_0_ncf[] = {
    "_text_encoder_attn_encoder_ffn_layers_3_Mul_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_Mul_output_0_ncf[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_3_Mul_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_Mul_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0208389088511467f, .offset= -163}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_Mul_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_3_Mul_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_3_Mul_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_3_Mul_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_3_Mul_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_ffn_layers_3_Mul_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0208389088511467f, .offset= -163}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0208389088511467f, .offset= -163}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_1_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_1_weight[] = {1, 1, 256, 1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_1_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_1_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0057301558554173f, .offset= -121}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_1_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_1_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_1_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_1_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_1_bias[] = {1024};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_1_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_1_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0015135122230276f, .offset= -215}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_1_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_1_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_1_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d[] = {
    "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_1_weight",
    "tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_1_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0307069290429354f, .offset= -185}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate_nchw[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0307069290429354f, .offset= -185}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0307069290429354f, .offset= -185}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_3_Relu(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_3_Relu */
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_3_Relu[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 4}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_3_Relu[] = {
    "_text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_Relu_output_0[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_3_Relu[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_Relu_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0083860857412219f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_Relu_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_3_Relu", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseNeuron", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_3_Relu, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_3_Relu, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_3_Relu, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_3_Relu_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_3_Relu_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_Relu_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_ffn_layers_3_Relu_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_3_Relu_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_Relu_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_Relu_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_3_Relu_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_3_Relu_output_0_nfc[] = {
    "_text_encoder_attn_encoder_ffn_layers_3_Relu_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_Relu_output_0_nfc[] = {1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_3_Relu_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_Relu_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0083860857412219f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_Relu_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_3_Relu_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_3_Relu_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_3_Relu_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_3_Relu_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_3_Mul_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_3_Mul_1 */
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_3_Mul_1[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_3_Mul_1[] = {
    "_text_encoder_attn_encoder_ffn_layers_3_Relu_output_0_nfc",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0[] = {1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_3_Mul_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0083860857412219f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_3_Mul_1", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_3_Mul_1, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_3_Mul_1, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_3_Mul_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0_ncf(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0_ncf */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0_ncf_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0_ncf_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0_ncf[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0_ncf_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0_ncf_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0_ncf_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0_ncf[] = {
    "_text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0_ncf[] = {1, 1024, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0_ncf[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0_ncf",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0083860857412219f, .offset= 0}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0_ncf,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0_ncf", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0_ncf, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0_ncf, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0_ncf, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d */
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d[] = {
    "_text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0_ncf"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d[] = {1, 1024, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0083860857412219f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d_nhwc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d_nhwc */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d_nhwc_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d_nhwc_perm[] = {0, 2, 3, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d_nhwc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d_nhwc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d_nhwc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d_nhwc_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d_nhwc[] = {
    "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d_nhwc[] = {1, 1, 128, 1024};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d_nhwc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d_nhwc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0083860857412219f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d_nhwc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d_nhwc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d_nhwc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d_nhwc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d_nhwc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_2_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_2_weight[] = {1, 1, 1024, 256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_2_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_2_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0104512181133032f, .offset= -126}}},
                                 .rank= 4,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_2_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_2_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_2_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_2_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_2_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_2_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_2_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0012941496679559f, .offset= -124}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_2_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_2_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_2_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d_dilation[] = {2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d_dilation[] = {1, 1};
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d_pad_amount[] = {2, 2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d_pad_amount[] = {0, 0, 0, 0};
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d_stride[] = {2};
  uint32_t _text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d_stride[] = {1, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="dilation",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d_dilation",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d_dilation,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d_dilation,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="pad_amount",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d_pad_amount",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 2,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d_pad_amount,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d_pad_amount,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="stride",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d_stride",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d_stride,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d_stride,
                           .dataSize=8}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="group",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 1}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="reuse_sparse_indices",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d[] = {
    "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d_nhwc",
    "tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_2_weight",
    "tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_2_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0180430263280869f, .offset= -95}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d", // Node Name
                         "qti.aisw", // Package Name
                         "Conv2d", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d, // Node Params
                         5, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate_nchw */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate_nchw_perm[] = {4};
  uint32_t _text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate_nchw_perm[] = {0, 3, 1, 2};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate_nchw[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate_nchw_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate_nchw_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate_nchw_perm,
                           .dataSize=16}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate_nchw[] = {
    "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate_nchw[] = {1, 256, 1, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate_nchw[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate_nchw",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0180430263280869f, .offset= -95}}},
            .rank= 4,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate_nchw,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate_nchw", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate_nchw, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate_nchw, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate_nchw, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate */
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate[] = {
    "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate_nchw"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0[] = {1, 256, 128};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0180430263280869f, .offset= -95}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0_nfc(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0_nfc */
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0_nfc_perm[] = {3};
  uint32_t _text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0_nfc_perm[] = {0, 2, 1};
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0_nfc[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="perm",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0_nfc_perm",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0_nfc_perm,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0_nfc_perm,
                           .dataSize=12}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0_nfc[] = {
    "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0_nfc[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0_nfc[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0_nfc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0180430263280869f, .offset= -95}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0_nfc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0_nfc", // Node Name
                         "qti.aisw", // Package Name
                         "Transpose", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0_nfc, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0_nfc, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0_nfc, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_ffn_layers_3_Mul_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_ffn_layers_3_Mul_2 */
  Qnn_Param_t params__text_encoder_attn_encoder_ffn_layers_3_Mul_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_ffn_layers_3_Mul_2[] = {
    "_text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0_nfc",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_attn_encoder_ffn_layers_3_Mul_2_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_ffn_layers_3_Mul_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_ffn_layers_3_Mul_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0180430263280869f, .offset= -95}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_ffn_layers_3_Mul_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_ffn_layers_3_Mul_2", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_ffn_layers_3_Mul_2, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_ffn_layers_3_Mul_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_ffn_layers_3_Mul_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_Add_7(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_Add_7 */
  Qnn_Param_t params__text_encoder_attn_encoder_Add_7[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_Add_7[] = {
    "_text_encoder_attn_encoder_norm_layers_1_3_Transpose_1_output_0",
    "_text_encoder_attn_encoder_ffn_layers_3_Mul_2_output_0"
  };
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_2_3_Transpose_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_Add_7[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_2_3_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0345091931521893f, .offset= -145}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_2_3_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_Add_7", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_Add_7, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_Add_7, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_Add_7, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_2_3_norm_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_2_3_norm_weight[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_norm_layers_2_3_norm_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_norm_layers_2_3_norm_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0040285619907081f, .offset= 0}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_2_3_norm_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_norm_layers_2_3_norm_weight),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_norm_layers_2_3_norm_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_2_3_norm_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_2_3_norm_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_text_encoder_attn_encoder_norm_layers_2_3_norm_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_text_encoder_attn_encoder_norm_layers_2_3_norm_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0023058135993779f, .offset= -109}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_text_encoder_attn_encoder_norm_layers_2_3_norm_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_text_encoder_attn_encoder_norm_layers_2_3_norm_bias),
                                                .dataSize=BINLEN(tts_ttl_text_encoder_attn_encoder_norm_layers_2_3_norm_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_norm_layers_2_3_norm_LayerNormalization(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_norm_layers_2_3_norm_LayerNormalization */
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_2_3_norm_LayerNormalization_axes[] = {1};
  uint32_t _text_encoder_attn_encoder_norm_layers_2_3_norm_LayerNormalization_axes[] = {2};
  Qnn_Param_t params__text_encoder_attn_encoder_norm_layers_2_3_norm_LayerNormalization[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="axes",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_2_3_norm_LayerNormalization_axes",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_2_3_norm_LayerNormalization_axes,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_text_encoder_attn_encoder_norm_layers_2_3_norm_LayerNormalization_axes,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="epsilon",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000001000000f}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_norm_layers_2_3_norm_LayerNormalization[] = {
    "_text_encoder_attn_encoder_norm_layers_2_3_Transpose_output_0",
    "tts_ttl_text_encoder_attn_encoder_norm_layers_2_3_norm_weight",
    "tts_ttl_text_encoder_attn_encoder_norm_layers_2_3_norm_bias"
  };
  uint32_t dimensions__text_encoder_attn_encoder_norm_layers_2_3_Transpose_1_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_norm_layers_2_3_norm_LayerNormalization[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_norm_layers_2_3_Transpose_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0422594100236893f, .offset= -155}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_norm_layers_2_3_Transpose_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_norm_layers_2_3_norm_LayerNormalization", // Node Name
                         "qti.aisw", // Package Name
                         "LayerNorm", // Qnn Node Type
                         params__text_encoder_attn_encoder_norm_layers_2_3_norm_LayerNormalization, // Node Params
                         2, // Num Node Params
                         inputs__text_encoder_attn_encoder_norm_layers_2_3_norm_LayerNormalization, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_norm_layers_2_3_norm_LayerNormalization, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_attn_encoder_Mul_2(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_attn_encoder_Mul_2 */
  Qnn_Param_t params__text_encoder_attn_encoder_Mul_2[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_attn_encoder_Mul_2[] = {
    "_text_encoder_attn_encoder_norm_layers_2_3_Transpose_1_output_0",
    "text_mask"
  };
  uint32_t dimensions__text_encoder_attn_encoder_Mul_2_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_attn_encoder_Mul_2[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_attn_encoder_Mul_2_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0422594100236893f, .offset= -155}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_attn_encoder_Mul_2_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_attn_encoder_Mul_2", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_attn_encoder_Mul_2, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_attn_encoder_Mul_2, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_attn_encoder_Mul_2, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_Add(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_Add */
  Qnn_Param_t params__text_encoder_Add[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__text_encoder_Add[] = {
    "_text_encoder_attn_encoder_Mul_2_output_0",
    "_text_encoder_convnext_convnext_5_Mul_3_output_0"
  };
  uint32_t dimensions__text_encoder_Add_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_Add[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_text_encoder_Add_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.5100963115692139f, .offset= -85}}},
            .rank= 3,
            .dimensions=dimensions__text_encoder_Add_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_Add", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_Add, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_Add, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_Add, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__text_encoder_proj_out_Mul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _text_encoder_proj_out_Mul */
  Qnn_Param_t params__text_encoder_proj_out_Mul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__text_encoder_proj_out_Mul[] = {
    "_text_encoder_Add_output_0",
    "text_mask"
  };
  uint32_t dimensions__speech_prompted_text_encoder_Transpose_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__text_encoder_proj_out_Mul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.5100963115692139f, .offset= -85}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_text_encoder_proj_out_Mul", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__text_encoder_proj_out_Mul, // Node Params
                         1, // Num Node Params
                         inputs__text_encoder_proj_out_Mul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__text_encoder_proj_out_Mul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_W_query_linear_MatMul_pre_reshape(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_W_query_linear_MatMul_pre_reshape */
  const char*  inputs__speech_prompted_text_encoder_attention1_W_query_linear_MatMul_pre_reshape[] = {
    "_speech_prompted_text_encoder_Transpose_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_W_query_linear_MatMul_pre_reshape[] = {128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_W_query_linear_MatMul_pre_reshape[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_W_query_linear_MatMul_pre_reshape",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.5100963115692139f, .offset= -85}}},
            .rank= 2,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_W_query_linear_MatMul_pre_reshape,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_W_query_linear_MatMul_pre_reshape", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_W_query_linear_MatMul_pre_reshape, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_W_query_linear_MatMul_pre_reshape, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_onnx__MatMul_3678(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_onnx__MatMul_3678[] = {256, 256};
  VALIDATE(model.addTensor("onnx__MatMul_3678", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "onnx__MatMul_3678",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0042698653414845f, .offset= -126}}},
                                 .rank= 2,
                                 .dimensions=dimensions_onnx__MatMul_3678,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(onnx__MatMul_3678),
                                                .dataSize=BINLEN(onnx__MatMul_3678)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_speech_prompted_text_encoder_attention1_W_query_linear_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_speech_prompted_text_encoder_attention1_W_query_linear_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_speech_prompted_text_encoder_attention1_W_query_linear_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_speech_prompted_text_encoder_attention1_W_query_linear_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0025970973074436f, .offset= -117}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_speech_prompted_text_encoder_attention1_W_query_linear_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_speech_prompted_text_encoder_attention1_W_query_linear_bias),
                                                .dataSize=BINLEN(tts_ttl_speech_prompted_text_encoder_attention1_W_query_linear_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_W_query_linear_MatMul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_W_query_linear_MatMul */
  const char*  inputs__speech_prompted_text_encoder_attention1_W_query_linear_MatMul[] = {
    "_speech_prompted_text_encoder_attention1_W_query_linear_MatMul_pre_reshape",
    "onnx__MatMul_3678",
    "tts_ttl_speech_prompted_text_encoder_attention1_W_query_linear_bias"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_W_query_linear_Add_output_0_fc[] = {128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_W_query_linear_MatMul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_W_query_linear_Add_output_0_fc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.3847892284393311f, .offset= -136}}},
            .rank= 2,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_W_query_linear_Add_output_0_fc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_W_query_linear_MatMul", // Node Name
                         "qti.aisw", // Package Name
                         "FullyConnected", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_W_query_linear_MatMul, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_W_query_linear_MatMul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_W_query_linear_MatMul_post_reshape(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_W_query_linear_MatMul_post_reshape */
  const char*  inputs__speech_prompted_text_encoder_attention1_W_query_linear_MatMul_post_reshape[] = {
    "_speech_prompted_text_encoder_attention1_W_query_linear_Add_output_0_fc"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_W_query_linear_Add_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_W_query_linear_MatMul_post_reshape[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_W_query_linear_Add_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.3847892284393311f, .offset= -136}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_W_query_linear_Add_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_W_query_linear_MatMul_post_reshape", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_W_query_linear_MatMul_post_reshape, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_W_query_linear_MatMul_post_reshape, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_Split(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_Split */
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Split_split_index[] = {1};
  uint32_t _speech_prompted_text_encoder_attention1_Split_split_index[] = {128};
  Qnn_Param_t params__speech_prompted_text_encoder_attention1_Split[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="split_index",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Split_split_index",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Split_split_index,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_speech_prompted_text_encoder_attention1_Split_split_index,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="axis",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 2}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention1_Split[] = {
    "_speech_prompted_text_encoder_attention1_W_query_linear_Add_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Split_output_0[] = {1, 128, 128};
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Split_output_1[] = {1, 128, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_Split[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Split_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.3847892284393311f, .offset= -136}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Split_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}},
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Split_output_1",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.3847892284393311f, .offset= -136}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Split_output_1,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_Split", // Node Name
                         "qti.aisw", // Package Name
                         "Split", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention1_Split, // Node Params
                         2, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_Split, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_Split, // Output Tensors 
                         2// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_Unsqueeze(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_Unsqueeze */
  const char*  inputs__speech_prompted_text_encoder_attention1_Unsqueeze[] = {
    "_speech_prompted_text_encoder_attention1_Split_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Unsqueeze_output_0[] = {1, 1, 128, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_Unsqueeze[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Unsqueeze_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.3847892284393311f, .offset= -136}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Unsqueeze_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_Unsqueeze", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_Unsqueeze, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_Unsqueeze, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_Unsqueeze_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_Unsqueeze_1 */
  const char*  inputs__speech_prompted_text_encoder_attention1_Unsqueeze_1[] = {
    "_speech_prompted_text_encoder_attention1_Split_output_1"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Unsqueeze_1_output_0[] = {1, 1, 128, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_Unsqueeze_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Unsqueeze_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.3847892284393311f, .offset= -136}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Unsqueeze_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_Unsqueeze_1", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_Unsqueeze_1, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_Unsqueeze_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_Concat(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_Concat */
  Qnn_Param_t params__speech_prompted_text_encoder_attention1_Concat[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="axis",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention1_Concat[] = {
    "_speech_prompted_text_encoder_attention1_Unsqueeze_output_0",
    "_speech_prompted_text_encoder_attention1_Unsqueeze_1_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Concat_output_0[] = {2, 1, 128, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_Concat[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Concat_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.3847892284393311f, .offset= -136}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Concat_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_Concat", // Node Name
                         "qti.aisw", // Package Name
                         "Concat", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention1_Concat, // Node Params
                         1, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_Concat, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_Concat, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor__speech_prompted_text_encoder_attention1_tanh_Tanh_output_0_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions__speech_prompted_text_encoder_attention1_tanh_Tanh_output_0_nchw[] = {2, 1, 128, 50};
  VALIDATE(model.addTensor("_speech_prompted_text_encoder_attention1_tanh_Tanh_output_0_nchw", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "_speech_prompted_text_encoder_attention1_tanh_Tanh_output_0_nchw",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0078425118699670f, .offset= -127}}},
                                 .rank= 4,
                                 .dimensions=dimensions__speech_prompted_text_encoder_attention1_tanh_Tanh_output_0_nchw,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(_speech_prompted_text_encoder_attention1_tanh_Tanh_output_0_nchw),
                                                .dataSize=BINLEN(_speech_prompted_text_encoder_attention1_tanh_Tanh_output_0_nchw)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_MatMul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_MatMul */
  Qnn_Param_t params__speech_prompted_text_encoder_attention1_MatMul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention1_MatMul[] = {
    "_speech_prompted_text_encoder_attention1_Concat_output_0",
    "_speech_prompted_text_encoder_attention1_tanh_Tanh_output_0_nchw"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_MatMul_output_0[] = {2, 1, 128, 50};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_MatMul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_MatMul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 5.0843553543090820f, .offset= -31}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_MatMul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_MatMul", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention1_MatMul, // Node Params
                         2, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_MatMul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_MatMul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor__speech_prompted_text_encoder_attention1_Constant_9_output_0(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Constant_9_output_0[] = {1};
  VALIDATE(model.addTensor("_speech_prompted_text_encoder_attention1_Constant_9_output_0", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "_speech_prompted_text_encoder_attention1_Constant_9_output_0",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0627451017498970f, .offset= 0}}},
                                 .rank= 1,
                                 .dimensions=dimensions__speech_prompted_text_encoder_attention1_Constant_9_output_0,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(_speech_prompted_text_encoder_attention1_Constant_9_output_0),
                                                .dataSize=BINLEN(_speech_prompted_text_encoder_attention1_Constant_9_output_0)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_Div(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_Div */
  Qnn_Param_t params__speech_prompted_text_encoder_attention1_Div[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 2}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention1_Div[] = {
    "_speech_prompted_text_encoder_attention1_MatMul_output_0",
    "_speech_prompted_text_encoder_attention1_Constant_9_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Div_output_0[] = {2, 1, 128, 50};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_Div[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Div_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.3177722096443176f, .offset= -31}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Div_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_Div", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention1_Div, // Node Params
                         1, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_Div, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_Div, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_Softmax(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_Softmax */
  Qnn_Param_t params__speech_prompted_text_encoder_attention1_Softmax[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="axis",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 3}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="beta",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 1.000000000000f}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention1_Softmax[] = {
    "_speech_prompted_text_encoder_attention1_Div_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Softmax_output_0[] = {2, 1, 128, 50};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_Softmax[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Softmax_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Softmax_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_Softmax", // Node Name
                         "qti.aisw", // Package Name
                         "Softmax", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention1_Softmax, // Node Params
                         2, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_Softmax, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_Softmax, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_Where(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_Where */
  const char*  inputs__speech_prompted_text_encoder_attention1_Where[] = {
    "_speech_prompted_text_encoder_attention2_Cast_output_0",
    "_speech_prompted_text_encoder_attention1_Constant_11_output_0",
    "_speech_prompted_text_encoder_attention1_Softmax_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Where_output_0[] = {2, 1, 128, 50};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_Where[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Where_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039214938879013f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Where_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_Where", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseSelect", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_Where, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_Where, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_MatMul_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_MatMul_1 */
  Qnn_Param_t params__speech_prompted_text_encoder_attention1_MatMul_1[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention1_MatMul_1[] = {
    "_speech_prompted_text_encoder_attention1_Where_output_0",
    "_speech_prompted_text_encoder_attention1_Concat_2_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_MatMul_1_output_0[] = {2, 1, 128, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_MatMul_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_MatMul_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0014291745610535f, .offset= -114}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_MatMul_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_MatMul_1", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention1_MatMul_1, // Node Params
                         2, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_MatMul_1, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_MatMul_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_Split_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_Split_3 */
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Split_3_split_index[] = {1};
  uint32_t _speech_prompted_text_encoder_attention1_Split_3_split_index[] = {1};
  Qnn_Param_t params__speech_prompted_text_encoder_attention1_Split_3[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="split_index",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Split_3_split_index",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Split_3_split_index,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_speech_prompted_text_encoder_attention1_Split_3_split_index,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="axis",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention1_Split_3[] = {
    "_speech_prompted_text_encoder_attention1_MatMul_1_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Split_3_output_0[] = {1, 1, 128, 128};
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Split_3_output_1[] = {1, 1, 128, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_Split_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Split_3_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0014291745610535f, .offset= -114}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Split_3_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}},
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Split_3_output_1",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0014291745610535f, .offset= -114}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Split_3_output_1,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_Split_3", // Node Name
                         "qti.aisw", // Package Name
                         "Split", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention1_Split_3, // Node Params
                         2, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_Split_3, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_Split_3, // Output Tensors 
                         2// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_Concat_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_Concat_3 */
  Qnn_Param_t params__speech_prompted_text_encoder_attention1_Concat_3[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="axis",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 3}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention1_Concat_3[] = {
    "_speech_prompted_text_encoder_attention1_Split_3_output_0",
    "_speech_prompted_text_encoder_attention1_Split_3_output_1"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Concat_3_output_0[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_Concat_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Concat_3_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0014291745610535f, .offset= -114}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Concat_3_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_Concat_3", // Node Name
                         "qti.aisw", // Package Name
                         "Concat", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention1_Concat_3, // Node Params
                         1, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_Concat_3, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_Concat_3, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_Squeeze(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_Squeeze */
  const char*  inputs__speech_prompted_text_encoder_attention1_Squeeze[] = {
    "_speech_prompted_text_encoder_attention1_Concat_3_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_out_fc_linear_MatMul_pre_reshape[] = {128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_Squeeze[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_out_fc_linear_MatMul_pre_reshape",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0014291745610535f, .offset= -114}}},
            .rank= 2,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_out_fc_linear_MatMul_pre_reshape,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_Squeeze", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_Squeeze, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_Squeeze, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_onnx__MatMul_3681(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_onnx__MatMul_3681[] = {256, 256};
  VALIDATE(model.addTensor("onnx__MatMul_3681", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "onnx__MatMul_3681",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0048964959569275f, .offset= -126}}},
                                 .rank= 2,
                                 .dimensions=dimensions_onnx__MatMul_3681,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(onnx__MatMul_3681),
                                                .dataSize=BINLEN(onnx__MatMul_3681)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_speech_prompted_text_encoder_attention1_out_fc_linear_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_speech_prompted_text_encoder_attention1_out_fc_linear_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_speech_prompted_text_encoder_attention1_out_fc_linear_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_speech_prompted_text_encoder_attention1_out_fc_linear_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0041595459915698f, .offset= -186}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_speech_prompted_text_encoder_attention1_out_fc_linear_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_speech_prompted_text_encoder_attention1_out_fc_linear_bias),
                                                .dataSize=BINLEN(tts_ttl_speech_prompted_text_encoder_attention1_out_fc_linear_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_out_fc_linear_MatMul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_out_fc_linear_MatMul */
  const char*  inputs__speech_prompted_text_encoder_attention1_out_fc_linear_MatMul[] = {
    "_speech_prompted_text_encoder_attention1_out_fc_linear_MatMul_pre_reshape",
    "onnx__MatMul_3681",
    "tts_ttl_speech_prompted_text_encoder_attention1_out_fc_linear_bias"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_out_fc_linear_Add_output_0_fc[] = {128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_out_fc_linear_MatMul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_out_fc_linear_Add_output_0_fc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0081858178600669f, .offset= -134}}},
            .rank= 2,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_out_fc_linear_Add_output_0_fc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_out_fc_linear_MatMul", // Node Name
                         "qti.aisw", // Package Name
                         "FullyConnected", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_out_fc_linear_MatMul, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_out_fc_linear_MatMul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_out_fc_linear_MatMul_post_reshape(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_out_fc_linear_MatMul_post_reshape */
  const char*  inputs__speech_prompted_text_encoder_attention1_out_fc_linear_MatMul_post_reshape[] = {
    "_speech_prompted_text_encoder_attention1_out_fc_linear_Add_output_0_fc"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_out_fc_linear_Add_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_out_fc_linear_MatMul_post_reshape[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_out_fc_linear_Add_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0081858178600669f, .offset= -134}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_out_fc_linear_Add_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_out_fc_linear_MatMul_post_reshape", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_out_fc_linear_MatMul_post_reshape, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_out_fc_linear_MatMul_post_reshape, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention1_Mul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention1_Mul */
  Qnn_Param_t params__speech_prompted_text_encoder_attention1_Mul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention1_Mul[] = {
    "_speech_prompted_text_encoder_attention1_out_fc_linear_Add_output_0",
    "text_mask"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention1_Mul_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention1_Mul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention1_Mul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0081858178600669f, .offset= -134}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_attention1_Mul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention1_Mul", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention1_Mul, // Node Params
                         1, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention1_Mul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention1_Mul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_Add(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_Add */
  Qnn_Param_t params__speech_prompted_text_encoder_Add[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_Add[] = {
    "_speech_prompted_text_encoder_attention1_Mul_output_0",
    "_speech_prompted_text_encoder_Transpose_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_Add_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_Add[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_Add_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.5070711374282837f, .offset= -85}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_Add_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_Add", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__speech_prompted_text_encoder_Add, // Node Params
                         1, // Num Node Params
                         inputs__speech_prompted_text_encoder_Add, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_Add, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_W_query_linear_MatMul_pre_reshape(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_W_query_linear_MatMul_pre_reshape */
  const char*  inputs__speech_prompted_text_encoder_attention2_W_query_linear_MatMul_pre_reshape[] = {
    "_speech_prompted_text_encoder_Add_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_W_query_linear_MatMul_pre_reshape[] = {128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_W_query_linear_MatMul_pre_reshape[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_W_query_linear_MatMul_pre_reshape",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.5070711374282837f, .offset= -85}}},
            .rank= 2,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_W_query_linear_MatMul_pre_reshape,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_W_query_linear_MatMul_pre_reshape", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_W_query_linear_MatMul_pre_reshape, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_W_query_linear_MatMul_pre_reshape, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_onnx__MatMul_3682(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_onnx__MatMul_3682[] = {256, 256};
  VALIDATE(model.addTensor("onnx__MatMul_3682", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "onnx__MatMul_3682",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0046901190653443f, .offset= -126}}},
                                 .rank= 2,
                                 .dimensions=dimensions_onnx__MatMul_3682,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(onnx__MatMul_3682),
                                                .dataSize=BINLEN(onnx__MatMul_3682)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_speech_prompted_text_encoder_attention2_W_query_linear_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_speech_prompted_text_encoder_attention2_W_query_linear_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_speech_prompted_text_encoder_attention2_W_query_linear_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_speech_prompted_text_encoder_attention2_W_query_linear_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0022320081479847f, .offset= -124}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_speech_prompted_text_encoder_attention2_W_query_linear_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_speech_prompted_text_encoder_attention2_W_query_linear_bias),
                                                .dataSize=BINLEN(tts_ttl_speech_prompted_text_encoder_attention2_W_query_linear_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_W_query_linear_MatMul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_W_query_linear_MatMul */
  const char*  inputs__speech_prompted_text_encoder_attention2_W_query_linear_MatMul[] = {
    "_speech_prompted_text_encoder_attention2_W_query_linear_MatMul_pre_reshape",
    "onnx__MatMul_3682",
    "tts_ttl_speech_prompted_text_encoder_attention2_W_query_linear_bias"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_W_query_linear_Add_output_0_fc[] = {128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_W_query_linear_MatMul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_W_query_linear_Add_output_0_fc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.2520286142826080f, .offset= -125}}},
            .rank= 2,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_W_query_linear_Add_output_0_fc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_W_query_linear_MatMul", // Node Name
                         "qti.aisw", // Package Name
                         "FullyConnected", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_W_query_linear_MatMul, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_W_query_linear_MatMul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_W_query_linear_MatMul_post_reshape(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_W_query_linear_MatMul_post_reshape */
  const char*  inputs__speech_prompted_text_encoder_attention2_W_query_linear_MatMul_post_reshape[] = {
    "_speech_prompted_text_encoder_attention2_W_query_linear_Add_output_0_fc"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_W_query_linear_Add_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_W_query_linear_MatMul_post_reshape[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_W_query_linear_Add_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.2520286142826080f, .offset= -125}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_W_query_linear_Add_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_W_query_linear_MatMul_post_reshape", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_W_query_linear_MatMul_post_reshape, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_W_query_linear_MatMul_post_reshape, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_Split(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_Split */
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Split_split_index[] = {1};
  uint32_t _speech_prompted_text_encoder_attention2_Split_split_index[] = {128};
  Qnn_Param_t params__speech_prompted_text_encoder_attention2_Split[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="split_index",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Split_split_index",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Split_split_index,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_speech_prompted_text_encoder_attention2_Split_split_index,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="axis",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 2}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention2_Split[] = {
    "_speech_prompted_text_encoder_attention2_W_query_linear_Add_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Split_output_0[] = {1, 128, 128};
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Split_output_1[] = {1, 128, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_Split[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Split_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.2520286142826080f, .offset= -125}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Split_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}},
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Split_output_1",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.2520286142826080f, .offset= -125}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Split_output_1,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_Split", // Node Name
                         "qti.aisw", // Package Name
                         "Split", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention2_Split, // Node Params
                         2, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_Split, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_Split, // Output Tensors 
                         2// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_Unsqueeze(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_Unsqueeze */
  const char*  inputs__speech_prompted_text_encoder_attention2_Unsqueeze[] = {
    "_speech_prompted_text_encoder_attention2_Split_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Unsqueeze_output_0[] = {1, 1, 128, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_Unsqueeze[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Unsqueeze_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.2520286142826080f, .offset= -125}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Unsqueeze_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_Unsqueeze", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_Unsqueeze, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_Unsqueeze, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_Unsqueeze_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_Unsqueeze_1 */
  const char*  inputs__speech_prompted_text_encoder_attention2_Unsqueeze_1[] = {
    "_speech_prompted_text_encoder_attention2_Split_output_1"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Unsqueeze_1_output_0[] = {1, 1, 128, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_Unsqueeze_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Unsqueeze_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.2520286142826080f, .offset= -125}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Unsqueeze_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_Unsqueeze_1", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_Unsqueeze_1, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_Unsqueeze_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_Concat(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_Concat */
  Qnn_Param_t params__speech_prompted_text_encoder_attention2_Concat[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="axis",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention2_Concat[] = {
    "_speech_prompted_text_encoder_attention2_Unsqueeze_output_0",
    "_speech_prompted_text_encoder_attention2_Unsqueeze_1_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Concat_output_0[] = {2, 1, 128, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_Concat[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Concat_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.2520286142826080f, .offset= -125}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Concat_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_Concat", // Node Name
                         "qti.aisw", // Package Name
                         "Concat", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention2_Concat, // Node Params
                         1, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_Concat, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_Concat, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor__speech_prompted_text_encoder_attention2_tanh_Tanh_output_0_nchw(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions__speech_prompted_text_encoder_attention2_tanh_Tanh_output_0_nchw[] = {2, 1, 128, 50};
  VALIDATE(model.addTensor("_speech_prompted_text_encoder_attention2_tanh_Tanh_output_0_nchw", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "_speech_prompted_text_encoder_attention2_tanh_Tanh_output_0_nchw",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0078420974314213f, .offset= -127}}},
                                 .rank= 4,
                                 .dimensions=dimensions__speech_prompted_text_encoder_attention2_tanh_Tanh_output_0_nchw,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(_speech_prompted_text_encoder_attention2_tanh_Tanh_output_0_nchw),
                                                .dataSize=BINLEN(_speech_prompted_text_encoder_attention2_tanh_Tanh_output_0_nchw)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_MatMul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_MatMul */
  Qnn_Param_t params__speech_prompted_text_encoder_attention2_MatMul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention2_MatMul[] = {
    "_speech_prompted_text_encoder_attention2_Concat_output_0",
    "_speech_prompted_text_encoder_attention2_tanh_Tanh_output_0_nchw"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_MatMul_output_0[] = {2, 1, 128, 50};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_MatMul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_MatMul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 3.3579561710357666f, .offset= -53}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_MatMul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_MatMul", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention2_MatMul, // Node Params
                         2, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_MatMul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_MatMul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_Div(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_Div */
  Qnn_Param_t params__speech_prompted_text_encoder_attention2_Div[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 2}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention2_Div[] = {
    "_speech_prompted_text_encoder_attention2_MatMul_output_0",
    "_speech_prompted_text_encoder_attention1_Constant_9_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Div_output_0[] = {2, 1, 128, 50};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_Div[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Div_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.2098722606897354f, .offset= -53}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Div_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_Div", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention2_Div, // Node Params
                         1, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_Div, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_Div, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_Softmax(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_Softmax */
  Qnn_Param_t params__speech_prompted_text_encoder_attention2_Softmax[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="axis",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 3}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="beta",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 1.000000000000f}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention2_Softmax[] = {
    "_speech_prompted_text_encoder_attention2_Div_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Softmax_output_0[] = {2, 1, 128, 50};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_Softmax[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Softmax_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0039062500000000f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Softmax_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_Softmax", // Node Name
                         "qti.aisw", // Package Name
                         "Softmax", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention2_Softmax, // Node Params
                         2, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_Softmax, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_Softmax, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_Where(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_Where */
  const char*  inputs__speech_prompted_text_encoder_attention2_Where[] = {
    "_speech_prompted_text_encoder_attention2_Cast_output_0",
    "_speech_prompted_text_encoder_attention1_Constant_11_output_0",
    "_speech_prompted_text_encoder_attention2_Softmax_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Where_output_0[] = {2, 1, 128, 50};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_Where[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Where_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0030484434682876f, .offset= 0}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Where_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_Where", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseSelect", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_Where, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_Where, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_MatMul_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_MatMul_1 */
  Qnn_Param_t params__speech_prompted_text_encoder_attention2_MatMul_1[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in0",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="transpose_in1",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_BOOL_8, {.bool8Value = 0}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention2_MatMul_1[] = {
    "_speech_prompted_text_encoder_attention2_Where_output_0",
    "_speech_prompted_text_encoder_attention2_Concat_2_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_MatMul_1_output_0[] = {2, 1, 128, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_MatMul_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_MatMul_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0043516969308257f, .offset= -148}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_MatMul_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_MatMul_1", // Node Name
                         "qti.aisw", // Package Name
                         "MatMul", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention2_MatMul_1, // Node Params
                         2, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_MatMul_1, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_MatMul_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_Split_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_Split_3 */
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Split_3_split_index[] = {1};
  uint32_t _speech_prompted_text_encoder_attention2_Split_3_split_index[] = {1};
  Qnn_Param_t params__speech_prompted_text_encoder_attention2_Split_3[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="split_index",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Split_3_split_index",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Split_3_split_index,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_speech_prompted_text_encoder_attention2_Split_3_split_index,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="axis",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention2_Split_3[] = {
    "_speech_prompted_text_encoder_attention2_MatMul_1_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Split_3_output_0[] = {1, 1, 128, 128};
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Split_3_output_1[] = {1, 1, 128, 128};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_Split_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Split_3_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0043516969308257f, .offset= -148}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Split_3_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}},
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Split_3_output_1",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0043516969308257f, .offset= -148}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Split_3_output_1,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_Split_3", // Node Name
                         "qti.aisw", // Package Name
                         "Split", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention2_Split_3, // Node Params
                         2, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_Split_3, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_Split_3, // Output Tensors 
                         2// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_Concat_3(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_Concat_3 */
  Qnn_Param_t params__speech_prompted_text_encoder_attention2_Concat_3[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="axis",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 3}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention2_Concat_3[] = {
    "_speech_prompted_text_encoder_attention2_Split_3_output_0",
    "_speech_prompted_text_encoder_attention2_Split_3_output_1"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Concat_3_output_0[] = {1, 1, 128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_Concat_3[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Concat_3_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0043516969308257f, .offset= -148}}},
            .rank= 4,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Concat_3_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_Concat_3", // Node Name
                         "qti.aisw", // Package Name
                         "Concat", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention2_Concat_3, // Node Params
                         1, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_Concat_3, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_Concat_3, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_Squeeze(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_Squeeze */
  const char*  inputs__speech_prompted_text_encoder_attention2_Squeeze[] = {
    "_speech_prompted_text_encoder_attention2_Concat_3_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_out_fc_linear_MatMul_pre_reshape[] = {128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_Squeeze[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_out_fc_linear_MatMul_pre_reshape",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0043516969308257f, .offset= -148}}},
            .rank= 2,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_out_fc_linear_MatMul_pre_reshape,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_Squeeze", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_Squeeze, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_Squeeze, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_onnx__MatMul_3685(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_onnx__MatMul_3685[] = {256, 256};
  VALIDATE(model.addTensor("onnx__MatMul_3685", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "onnx__MatMul_3685",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0054961494170129f, .offset= -132}}},
                                 .rank= 2,
                                 .dimensions=dimensions_onnx__MatMul_3685,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(onnx__MatMul_3685),
                                                .dataSize=BINLEN(onnx__MatMul_3685)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_speech_prompted_text_encoder_attention2_out_fc_linear_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_speech_prompted_text_encoder_attention2_out_fc_linear_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_speech_prompted_text_encoder_attention2_out_fc_linear_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_speech_prompted_text_encoder_attention2_out_fc_linear_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0027172458358109f, .offset= -90}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_speech_prompted_text_encoder_attention2_out_fc_linear_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_speech_prompted_text_encoder_attention2_out_fc_linear_bias),
                                                .dataSize=BINLEN(tts_ttl_speech_prompted_text_encoder_attention2_out_fc_linear_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_out_fc_linear_MatMul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_out_fc_linear_MatMul */
  const char*  inputs__speech_prompted_text_encoder_attention2_out_fc_linear_MatMul[] = {
    "_speech_prompted_text_encoder_attention2_out_fc_linear_MatMul_pre_reshape",
    "onnx__MatMul_3685",
    "tts_ttl_speech_prompted_text_encoder_attention2_out_fc_linear_bias"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_out_fc_linear_Add_output_0_fc[] = {128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_out_fc_linear_MatMul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_out_fc_linear_Add_output_0_fc",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0172315947711468f, .offset= -124}}},
            .rank= 2,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_out_fc_linear_Add_output_0_fc,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_out_fc_linear_MatMul", // Node Name
                         "qti.aisw", // Package Name
                         "FullyConnected", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_out_fc_linear_MatMul, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_out_fc_linear_MatMul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_out_fc_linear_MatMul_post_reshape(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_out_fc_linear_MatMul_post_reshape */
  const char*  inputs__speech_prompted_text_encoder_attention2_out_fc_linear_MatMul_post_reshape[] = {
    "_speech_prompted_text_encoder_attention2_out_fc_linear_Add_output_0_fc"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_out_fc_linear_Add_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_out_fc_linear_MatMul_post_reshape[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_out_fc_linear_Add_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0172315947711468f, .offset= -124}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_out_fc_linear_Add_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_out_fc_linear_MatMul_post_reshape", // Node Name
                         "qti.aisw", // Package Name
                         "Reshape", // Qnn Node Type
                         nullptr, // Node Params
                         0, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_out_fc_linear_MatMul_post_reshape, // Input Tensor Names
                         1, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_out_fc_linear_MatMul_post_reshape, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_attention2_Mul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_attention2_Mul */
  Qnn_Param_t params__speech_prompted_text_encoder_attention2_Mul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_attention2_Mul[] = {
    "_speech_prompted_text_encoder_attention2_out_fc_linear_Add_output_0",
    "text_mask"
  };
  uint32_t dimensions__speech_prompted_text_encoder_attention2_Mul_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_attention2_Mul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_attention2_Mul_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0172315947711468f, .offset= -124}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_attention2_Mul_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_attention2_Mul", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__speech_prompted_text_encoder_attention2_Mul, // Node Params
                         1, // Num Node Params
                         inputs__speech_prompted_text_encoder_attention2_Mul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_attention2_Mul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_Add_1(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_Add_1 */
  Qnn_Param_t params__speech_prompted_text_encoder_Add_1[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 0}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_Add_1[] = {
    "_speech_prompted_text_encoder_attention2_Mul_output_0",
    "_speech_prompted_text_encoder_Transpose_output_0"
  };
  uint32_t dimensions__speech_prompted_text_encoder_Add_1_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_Add_1[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_Add_1_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 1.5212787389755249f, .offset= -84}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_Add_1_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_Add_1", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__speech_prompted_text_encoder_Add_1, // Node Params
                         1, // Num Node Params
                         inputs__speech_prompted_text_encoder_Add_1, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_Add_1, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_speech_prompted_text_encoder_norm_norm_weight(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_speech_prompted_text_encoder_norm_norm_weight[] = {256};
  VALIDATE(model.addTensor("tts_ttl_speech_prompted_text_encoder_norm_norm_weight", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_speech_prompted_text_encoder_norm_norm_weight",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0055672922171652f, .offset= 0}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_speech_prompted_text_encoder_norm_norm_weight,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_speech_prompted_text_encoder_norm_norm_weight),
                                                .dataSize=BINLEN(tts_ttl_speech_prompted_text_encoder_norm_norm_weight)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addTensor_tts_ttl_speech_prompted_text_encoder_norm_norm_bias(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;
  uint32_t dimensions_tts_ttl_speech_prompted_text_encoder_norm_norm_bias[] = {256};
  VALIDATE(model.addTensor("tts_ttl_speech_prompted_text_encoder_norm_norm_bias", // Tensor Name
                           (Qnn_Tensor_t) {
                               .version= QNN_TENSOR_VERSION_2,
                               {.v2= {
                                 .id=0,
                                 .name= "tts_ttl_speech_prompted_text_encoder_norm_norm_bias",
                                 .type= QNN_TENSOR_TYPE_STATIC,
                                 .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
                                 .dataType= QNN_DATATYPE_UFIXED_POINT_8,
                                 .quantizeParams= { QNN_DEFINITION_DEFINED,
                                                    QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                                                    {.scaleOffsetEncoding= {.scale= 0.0028053347487003f, .offset= -100}}},
                                 .rank= 1,
                                 .dimensions=dimensions_tts_ttl_speech_prompted_text_encoder_norm_norm_bias,
                                 .memType= QNN_TENSORMEMTYPE_RAW,
                                 {.clientBuf= { .data=BINVARSTART(tts_ttl_speech_prompted_text_encoder_norm_norm_bias),
                                                .dataSize=BINLEN(tts_ttl_speech_prompted_text_encoder_norm_norm_bias)}},
                                 .isDynamicDimensions= nullptr,
                                 .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                                                  .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
                                 .isProduced= 0}}}
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_norm_norm_LayerNormalization(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_norm_norm_LayerNormalization */
  uint32_t dimensions__speech_prompted_text_encoder_norm_norm_LayerNormalization_axes[] = {1};
  uint32_t _speech_prompted_text_encoder_norm_norm_LayerNormalization_axes[] = {2};
  Qnn_Param_t params__speech_prompted_text_encoder_norm_norm_LayerNormalization[] = {
    {.paramType=QNN_PARAMTYPE_TENSOR,
     .name="axes",
     {.tensorParam=(Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_norm_norm_LayerNormalization_axes",
            .type= QNN_TENSOR_TYPE_STATIC,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UINT_32,
            .quantizeParams= { QNN_DEFINITION_UNDEFINED,
                               QNN_QUANTIZATION_ENCODING_UNDEFINED,
                               {.scaleOffsetEncoding= {.scale= 0.0000000000000000f, .offset= 0}}},
            .rank= 1,
            .dimensions=dimensions__speech_prompted_text_encoder_norm_norm_LayerNormalization_axes,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=(uint8_t*)_speech_prompted_text_encoder_norm_norm_LayerNormalization_axes,
                           .dataSize=4}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}}},
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="epsilon",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_FLOAT_32, {.floatValue = 0.000001000000f}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_norm_norm_LayerNormalization[] = {
    "_speech_prompted_text_encoder_Add_1_output_0",
    "tts_ttl_speech_prompted_text_encoder_norm_norm_weight",
    "tts_ttl_speech_prompted_text_encoder_norm_norm_bias"
  };
  uint32_t dimensions__speech_prompted_text_encoder_norm_Transpose_output_0[] = {1, 128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_norm_norm_LayerNormalization[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "_speech_prompted_text_encoder_norm_Transpose_output_0",
            .type= QNN_TENSOR_TYPE_NATIVE,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0295104887336493f, .offset= -95}}},
            .rank= 3,
            .dimensions=dimensions__speech_prompted_text_encoder_norm_Transpose_output_0,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_norm_norm_LayerNormalization", // Node Name
                         "qti.aisw", // Package Name
                         "LayerNorm", // Qnn Node Type
                         params__speech_prompted_text_encoder_norm_norm_LayerNormalization, // Node Params
                         2, // Num Node Params
                         inputs__speech_prompted_text_encoder_norm_norm_LayerNormalization, // Input Tensor Names
                         3, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_norm_norm_LayerNormalization, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

static ModelError_t addNode__speech_prompted_text_encoder_Mul(QnnModel& model){
  ModelError_t err = MODEL_NO_ERROR;

  /* ADDING NODE FOR _speech_prompted_text_encoder_Mul */
  Qnn_Param_t params__speech_prompted_text_encoder_Mul[] = {
    {.paramType=QNN_PARAMTYPE_SCALAR,
     .name="operation",
     {.scalarParam= (Qnn_Scalar_t) {QNN_DATATYPE_UINT_32, {.uint32Value = 13}}}}
  };
  const char*  inputs__speech_prompted_text_encoder_Mul[] = {
    "_speech_prompted_text_encoder_norm_Transpose_output_0",
    "text_mask"
  };
  uint32_t dimensions_text_emb[] = {1, 128, 256};
  Qnn_Tensor_t outputs__speech_prompted_text_encoder_Mul[] = {
    (Qnn_Tensor_t) {
          .version= QNN_TENSOR_VERSION_2,
          {.v2= {
            .id=0,
            .name= "text_emb",
            .type= QNN_TENSOR_TYPE_APP_READ,
            .dataFormat= QNN_TENSOR_DATA_FORMAT_DENSE,
            .dataType= QNN_DATATYPE_UFIXED_POINT_8,
            .quantizeParams= { QNN_DEFINITION_DEFINED,
                               QNN_QUANTIZATION_ENCODING_SCALE_OFFSET,
                               {.scaleOffsetEncoding= {.scale= 0.0295104887336493f, .offset= -95}}},
            .rank= 3,
            .dimensions=dimensions_text_emb,
            .memType= QNN_TENSORMEMTYPE_RAW,
            {.clientBuf= { .data=nullptr,
                           .dataSize=0}},
            .isDynamicDimensions= nullptr,
            .sparseParams= { QNN_SPARSE_LAYOUT_UNDEFINED,
                             .hybridCoo= {.numSpecifiedElements= 0, .numSparseDimensions= 0}},
            .isProduced= 0}}}
  };
  VALIDATE(model.addNode(QNN_OPCONFIG_VERSION_1, // Op_Config_t Version
                         "_speech_prompted_text_encoder_Mul", // Node Name
                         "qti.aisw", // Package Name
                         "ElementWiseBinary", // Qnn Node Type
                         params__speech_prompted_text_encoder_Mul, // Node Params
                         1, // Num Node Params
                         inputs__speech_prompted_text_encoder_Mul, // Input Tensor Names
                         2, // Num Input Tensor Names
                         outputs__speech_prompted_text_encoder_Mul, // Output Tensors 
                         1// Num Output Tensors 
  ), err);
  return err;
}

QNN_API
ModelError_t QnnModel_composeGraphs(Qnn_BackendHandle_t backendHandle,
                                    QNN_INTERFACE_VER_TYPE interface,
                                    Qnn_ContextHandle_t contextHandle,
                                    const GraphConfigInfo_t** graphsConfigInfo,
                                    const uint32_t numGraphsConfigInfo,
                                    GraphInfoPtr_t** graphsInfo,
                                    uint32_t* numGraphsInfo,
                                    bool debug,
                                    QnnLog_Callback_t logCallback,
                                    QnnLog_Level_t maxLogLevel) {

  ModelError_t err = MODEL_NO_ERROR;

  /* model/graph for text_encoder_htp*/
  QnnModel text_encoder_htp;
  const QnnGraph_Config_t** graphConfigs = nullptr;
  VALIDATE(getQnnGraphConfigFromInfo("text_encoder_htp", graphsConfigInfo, numGraphsConfigInfo, graphConfigs), err);
  VALIDATE(text_encoder_htp.initialize(backendHandle, interface, contextHandle, "text_encoder_htp", debug, DO_GRAPH_NODE_VALIDATIONS, graphConfigs), err);
  VALIDATE(addTensor_text_ids(text_encoder_htp), err);
  VALIDATE(addTensor_style_ttl(text_encoder_htp), err);
  VALIDATE(addTensor_text_mask(text_encoder_htp), err);
  VALIDATE(addNode_style_ttl_ncf(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_W_value_linear_MatMul_pre_reshape(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_W_value_linear_MatMul_pre_reshape(text_encoder_htp), err);
  VALIDATE(addNode_text_mask_ncf(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_text_embedder_char_embedder_weight(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_text_embedder_char_embedder_Gather(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_Unsqueeze(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_Unsqueeze_1(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_text_embedder_Transpose(text_encoder_htp), err);
  VALIDATE(addTensor_onnx__MatMul_3680(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_speech_prompted_text_encoder_attention1_W_value_linear_bias(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_W_value_linear_MatMul(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_W_value_linear_MatMul_post_reshape(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_Unsqueeze_6(text_encoder_htp), err);
  VALIDATE(addTensor_onnx__MatMul_3684(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_speech_prompted_text_encoder_attention2_W_value_linear_bias(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_W_value_linear_MatMul(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_W_value_linear_MatMul_post_reshape(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_Mul(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_text_embedder_Mul(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_text_embedder_Mul_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_Split_2(text_encoder_htp), err);
  VALIDATE(addTensor__speech_prompted_text_encoder_attention1_Constant_11_output_0(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_Equal(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_Split_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Equal(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_Mul(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_Unsqueeze_4(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_Unsqueeze_5(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_Unsqueeze_4(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_Unsqueeze_5(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_Concat_2(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_Concat_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_dwconv_Pad(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_dwconv_Pad_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_dwconv_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_0_dwconv_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_0_dwconv_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_dwconv_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_dwconv_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_dwconv_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_Mul_1(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_0_norm_norm_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_0_norm_norm_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_norm_norm_LayerNormalization(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_norm_Transpose_1_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_pwconv1_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_0_pwconv1_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_0_pwconv1_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_pwconv1_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_pwconv1_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__elementwiseneuron_4(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_pwconv2_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_0_pwconv2_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_0_pwconv2_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_pwconv2_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_pwconv2_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_pwconv2_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_0_gamma(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_Mul_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_Add(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_0_Mul_3(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_Mul(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_dwconv_Pad(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_dwconv_Pad_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_dwconv_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_1_dwconv_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_1_dwconv_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_dwconv_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_dwconv_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_dwconv_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_Mul_1(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_1_norm_norm_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_1_norm_norm_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_norm_norm_LayerNormalization(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_norm_Transpose_1_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_pwconv1_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_1_pwconv1_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_1_pwconv1_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_pwconv1_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_pwconv1_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__elementwiseneuron_6(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_pwconv2_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_1_pwconv2_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_1_pwconv2_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_pwconv2_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_pwconv2_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_pwconv2_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_1_gamma(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_Mul_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_Add(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_1_Mul_3(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_Mul(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_dwconv_Pad(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_dwconv_Pad_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_dwconv_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_2_dwconv_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_2_dwconv_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_dwconv_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_dwconv_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_dwconv_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_Mul_1(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_2_norm_norm_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_2_norm_norm_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_norm_norm_LayerNormalization(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_norm_Transpose_1_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_pwconv1_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_2_pwconv1_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_2_pwconv1_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_pwconv1_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_pwconv1_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__elementwiseneuron_8(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_pwconv2_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_2_pwconv2_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_2_pwconv2_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_pwconv2_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_pwconv2_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_pwconv2_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_2_gamma(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_Mul_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_Add(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_2_Mul_3(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_Mul(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_dwconv_Pad(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_dwconv_Pad_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_dwconv_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_3_dwconv_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_3_dwconv_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_dwconv_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_dwconv_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_dwconv_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_Mul_1(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_3_norm_norm_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_3_norm_norm_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_norm_norm_LayerNormalization(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_norm_Transpose_1_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_pwconv1_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_3_pwconv1_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_3_pwconv1_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_pwconv1_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_pwconv1_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__elementwiseneuron_10(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_pwconv2_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_3_pwconv2_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_3_pwconv2_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_pwconv2_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_pwconv2_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_pwconv2_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_3_gamma(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_Mul_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_Add(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_3_Mul_3(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_Mul(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_dwconv_Pad(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_dwconv_Pad_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_dwconv_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_4_dwconv_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_4_dwconv_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_dwconv_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_dwconv_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_dwconv_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_Mul_1(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_4_norm_norm_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_4_norm_norm_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_norm_norm_LayerNormalization(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_norm_Transpose_1_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_pwconv1_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_4_pwconv1_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_4_pwconv1_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_pwconv1_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_pwconv1_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__elementwiseneuron_12(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_pwconv2_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_4_pwconv2_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_4_pwconv2_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_pwconv2_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_pwconv2_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_pwconv2_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_4_gamma(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_Mul_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_Add(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_4_Mul_3(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_Mul(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_dwconv_Pad(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_dwconv_Pad_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_dwconv_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_5_dwconv_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_5_dwconv_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_dwconv_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_dwconv_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_dwconv_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_Mul_1(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_5_norm_norm_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_5_norm_norm_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_norm_norm_LayerNormalization(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_norm_Transpose_1_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_pwconv1_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_5_pwconv1_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_5_pwconv1_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_pwconv1_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_pwconv1_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__elementwiseneuron_14(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_pwconv2_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_5_pwconv2_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_5_pwconv2_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_pwconv2_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_pwconv2_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_pwconv2_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_convnext_convnext_5_gamma(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_Mul_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_Add(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_convnext_convnext_5_Mul_3(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_Mul_1(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_Mul_1_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_q_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_q_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_q_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_k_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_k_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_k_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_v_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_v_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_v_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Transpose(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Transpose_1(text_encoder_htp), err);
  VALIDATE(addTensor__text_encoder_attn_encoder_attn_layers_0_Constant_10_output_0(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Div(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_MatMul(text_encoder_htp), err);
  VALIDATE(addTensor__text_encoder_attn_encoder_attn_layers_0_Transpose_3_output_0_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_MatMul_1(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_MatMul_1_output_0_nhwc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Pad_1(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Pad_1_output_0_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Reshape_7(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Reshape_7_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Pad_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Pad_2_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Reshape_10(text_encoder_htp), err);
  VALIDATE(addNode_Slice_0(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Add_2(text_encoder_htp), err);
  VALIDATE(addTensor__text_encoder_attn_encoder_attn_layers_0_Constant_88_output_0(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Where(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Softmax(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Softmax_output_0_nhwc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_MatMul_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Pad_3(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Pad_3_output_0_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Reshape_13(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Reshape_13_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Pad_4(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Pad_4_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Reshape_16(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Slice_8(text_encoder_htp), err);
  VALIDATE(addTensor__text_encoder_attn_encoder_attn_layers_0_Unsqueeze_41_output_0_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_MatMul_3(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Add_4(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Transpose_9(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_Reshape_19(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_o_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_0_conv_o_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_0_conv_o_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_Add(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_1_0_norm_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_1_0_norm_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_norm_layers_1_0_norm_LayerNormalization(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_0_Mul(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_0_Mul_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_1_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_1_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_0_conv_1_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_0_Relu(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_0_Relu_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_0_Mul_1(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_0_Mul_1_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_2_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_0_conv_2_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_0_conv_2_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_0_Mul_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_Add_1(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_2_0_norm_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_2_0_norm_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_norm_layers_2_0_norm_LayerNormalization(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_norm_layers_2_0_Transpose_1_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_q_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_q_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_q_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_k_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_k_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_k_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_v_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_v_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_v_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Transpose(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Transpose_1(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Div(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_MatMul(text_encoder_htp), err);
  VALIDATE(addTensor__text_encoder_attn_encoder_attn_layers_1_Transpose_3_output_0_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_MatMul_1(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_MatMul_1_output_0_nhwc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Pad_1(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Pad_1_output_0_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Reshape_7(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Reshape_7_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Pad_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Pad_2_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Reshape_10(text_encoder_htp), err);
  VALIDATE(addNode_Slice_1(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Add_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Where(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Softmax(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Softmax_output_0_nhwc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_MatMul_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Pad_3(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Pad_3_output_0_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Reshape_13(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Reshape_13_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Pad_4(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Pad_4_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Reshape_16(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Slice_8(text_encoder_htp), err);
  VALIDATE(addTensor__text_encoder_attn_encoder_attn_layers_1_Unsqueeze_41_output_0_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_MatMul_3(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Add_4(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Transpose_9(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_Reshape_19(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_o_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_1_conv_o_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_1_conv_o_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_Add_2(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_1_1_norm_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_1_1_norm_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_norm_layers_1_1_norm_LayerNormalization(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_1_Mul(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_1_Mul_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_1_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_1_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_1_conv_1_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_1_Relu(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_1_Relu_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_1_Mul_1(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_1_Mul_1_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_2_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_1_conv_2_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_1_conv_2_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_1_Mul_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_Add_3(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_2_1_norm_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_2_1_norm_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_norm_layers_2_1_norm_LayerNormalization(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_norm_layers_2_1_Transpose_1_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_q_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_q_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_q_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_k_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_k_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_k_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_v_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_v_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_v_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Transpose(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Transpose_1(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Div(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_MatMul(text_encoder_htp), err);
  VALIDATE(addTensor__text_encoder_attn_encoder_attn_layers_2_Transpose_3_output_0_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_MatMul_1(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_MatMul_1_output_0_nhwc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Pad_1(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Pad_1_output_0_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Reshape_7(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Reshape_7_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Pad_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Pad_2_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Reshape_10(text_encoder_htp), err);
  VALIDATE(addNode_Slice_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Add_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Where(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Softmax(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Softmax_output_0_nhwc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_MatMul_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Pad_3(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Pad_3_output_0_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Reshape_13(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Reshape_13_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Pad_4(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Pad_4_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Reshape_16(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Slice_8(text_encoder_htp), err);
  VALIDATE(addTensor__text_encoder_attn_encoder_attn_layers_2_Unsqueeze_41_output_0_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_MatMul_3(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Add_4(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Transpose_9(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_Reshape_19(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_o_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_2_conv_o_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_2_conv_o_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_Add_4(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_1_2_norm_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_1_2_norm_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_norm_layers_1_2_norm_LayerNormalization(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_2_Mul(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_2_Mul_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_1_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_1_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_2_conv_1_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_2_Relu(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_2_Relu_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_2_Mul_1(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_2_Mul_1_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_2_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_2_conv_2_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_2_conv_2_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_2_Mul_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_Add_5(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_2_2_norm_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_2_2_norm_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_norm_layers_2_2_norm_LayerNormalization(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_norm_layers_2_2_Transpose_1_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_q_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_q_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_q_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_k_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_k_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_k_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_v_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_v_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_v_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Transpose(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Transpose_1(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Div(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_MatMul(text_encoder_htp), err);
  VALIDATE(addTensor__text_encoder_attn_encoder_attn_layers_3_Transpose_3_output_0_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_MatMul_1(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_MatMul_1_output_0_nhwc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Pad_1(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Pad_1_output_0_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Reshape_7(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Reshape_7_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Pad_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Pad_2_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Reshape_10(text_encoder_htp), err);
  VALIDATE(addNode_Slice_3(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Add_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Where(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Softmax(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Softmax_output_0_nhwc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_MatMul_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Pad_3(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Pad_3_output_0_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Reshape_13(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Reshape_13_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Pad_4(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Pad_4_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Reshape_16(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Slice_8(text_encoder_htp), err);
  VALIDATE(addTensor__text_encoder_attn_encoder_attn_layers_3_Unsqueeze_41_output_0_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_MatMul_3(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Add_4(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Transpose_9(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_Reshape_19(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_o_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_attn_layers_3_conv_o_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_attn_layers_3_conv_o_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_Add_6(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_1_3_norm_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_1_3_norm_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_norm_layers_1_3_norm_LayerNormalization(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_3_Mul(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_3_Mul_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_1_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_1_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_3_conv_1_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_3_Relu(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_3_Relu_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_3_Mul_1(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_3_Mul_1_output_0_ncf(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_reshape_to_2d_nhwc(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_2_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_ffn_layers_3_conv_2_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_2d(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate_nchw(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_intermediate(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_3_conv_2_Conv_output_0_nfc(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_ffn_layers_3_Mul_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_Add_7(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_2_3_norm_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_text_encoder_attn_encoder_norm_layers_2_3_norm_bias(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_norm_layers_2_3_norm_LayerNormalization(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_attn_encoder_Mul_2(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_Add(text_encoder_htp), err);
  VALIDATE(addNode__text_encoder_proj_out_Mul(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_W_query_linear_MatMul_pre_reshape(text_encoder_htp), err);
  VALIDATE(addTensor_onnx__MatMul_3678(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_speech_prompted_text_encoder_attention1_W_query_linear_bias(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_W_query_linear_MatMul(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_W_query_linear_MatMul_post_reshape(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_Split(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_Unsqueeze(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_Unsqueeze_1(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_Concat(text_encoder_htp), err);
  VALIDATE(addTensor__speech_prompted_text_encoder_attention1_tanh_Tanh_output_0_nchw(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_MatMul(text_encoder_htp), err);
  VALIDATE(addTensor__speech_prompted_text_encoder_attention1_Constant_9_output_0(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_Div(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_Softmax(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_Where(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_MatMul_1(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_Split_3(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_Concat_3(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_Squeeze(text_encoder_htp), err);
  VALIDATE(addTensor_onnx__MatMul_3681(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_speech_prompted_text_encoder_attention1_out_fc_linear_bias(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_out_fc_linear_MatMul(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_out_fc_linear_MatMul_post_reshape(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention1_Mul(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_Add(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_W_query_linear_MatMul_pre_reshape(text_encoder_htp), err);
  VALIDATE(addTensor_onnx__MatMul_3682(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_speech_prompted_text_encoder_attention2_W_query_linear_bias(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_W_query_linear_MatMul(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_W_query_linear_MatMul_post_reshape(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_Split(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_Unsqueeze(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_Unsqueeze_1(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_Concat(text_encoder_htp), err);
  VALIDATE(addTensor__speech_prompted_text_encoder_attention2_tanh_Tanh_output_0_nchw(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_MatMul(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_Div(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_Softmax(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_Where(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_MatMul_1(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_Split_3(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_Concat_3(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_Squeeze(text_encoder_htp), err);
  VALIDATE(addTensor_onnx__MatMul_3685(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_speech_prompted_text_encoder_attention2_out_fc_linear_bias(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_out_fc_linear_MatMul(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_out_fc_linear_MatMul_post_reshape(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_attention2_Mul(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_Add_1(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_speech_prompted_text_encoder_norm_norm_weight(text_encoder_htp), err);
  VALIDATE(addTensor_tts_ttl_speech_prompted_text_encoder_norm_norm_bias(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_norm_norm_LayerNormalization(text_encoder_htp), err);
  VALIDATE(addNode__speech_prompted_text_encoder_Mul(text_encoder_htp), err);

  // Add all models to array to get graphsInfo
  QnnModel* models [] = {&text_encoder_htp};
  uint32_t numModels = 1;

  // Populate the constructed graphs in provided output variables
  VALIDATE(getGraphInfoFromModels(*models, numModels, graphsInfo), err);
  *numGraphsInfo = numModels;

  return err;

} // PREPARE_GRAPHS

QNN_API
ModelError_t QnnModel_freeGraphsInfo(GraphInfoPtr_t** graphsInfo, uint32_t numGraphsInfo){
  return qnn_wrapper_api::freeGraphsInfo(graphsInfo, numGraphsInfo);
} // FREEGRAPHINFO

}